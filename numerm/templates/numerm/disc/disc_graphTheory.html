{% extends '../layout.html' %} {% load static %} {% block description %}
<meta name="description" content="Introduction to graph theory" />
{% endblock %} {% block title %}
<title>Graph Theory</title>
{% endblock %} {% block content %}
<h1>Graph Theory</h1>
<section id="introduction">
	<p>
		<span class="drop">G</span>raph theory is a tremendously important
		field in computer science. If we've ever wondered how Facebook can
		suggest friends so well (almost eerily well), it's because of graph
		theory. Managing traffic, creating family trees, scheduling events,
		tracing historical origins, the mess of yarn, photos, and notes on an
		investigator's board &mdash; that's graph theory.
	</p>
	<p>
		Here's a problem sociologists and media outlets like Buzzfeed seem to
		obsess over:
	</p>
	<figure>
		<div class="rule">
			<p>
				On average, who has more opposite-gender sexual partners &mdash;
				men or women?
			</p>
		</div>
	</figure>
	<p>
		To simplify the mathematics behind this problem (not to make a
		political statement), we'll suppose that there are only two genders:
		men and women. If we read through most of the literature, we'd find
		that the dominant conclusion is that men have more opposite-gender
		sexual partners than women. This is done through numerous, meticulous
		studies. Some go so far as to monitor subject surveys for years. And
		yet still, the question resurges every so often. As long as it sells,
		we suppose.
	</p>
	<p>
		Mathematically, however, the question is a non-starter. To see why, we
		begin by stating a few definitions in graph theory.
	</p>
</section>

<section id="forray">
	<h2>What is a graph?</h2>
	<p>Informally, a graph is just a bunch of dots and lines:</p>
	<figure>
		<img
			src="{% static 'images/graph1.svg' %}"
			alt="A graph with 5 notes and 8 edges"
			loading="lazy"
			width="100px"
			height="100px"
		/>
		<figcaption>A graph with 6 vertices and 5 edges.</figcaption>
	</figure>
	<p>
		A graph is an object consisting of two kinds of objects: vertices and
		edges. Each of the circles, or points, is called a
		<b>vertex</b>, or <b>node</b> (we will use the term vertex; plural
		<i>vertices</i>). Each of the lines connecting the circles is called an
		<b>edge</b>. The graph above is called a <b>simple graph</b>. We will
		elaborate further on what this distinction means in later sections. For
		now, we will say that a simple graph has the following constraints:
	</p>
	<dfn>
		<p>
			<small>Constraint</small> An edge connects <em>only</em> a
			<i>pair</i> of vertices. For example, in a simple graph, we cannot
			have an edge connecting ${v_4}$ to itself; i.e., a loop.
		</p>
		<p>
			<small>Constraint</small>
			We cannot we have more than one edge connect two vertices. I.e., two
			edges connecting ${v_3}$ and ${v_5.}$
		</p>
		<p>
			<small>Constraint</small>
			Edges have no direction; i.e., the fact that ${v_4}$ and ${v_1}$ are
			connected by the edge ${e_4}$ does not imply that the edge goes from
			${v_4}$ to ${v_1}$ or vice versa.
		</p>
	</dfn>
	<p>For example, the graphs below are <em>not</em> simple graphs:</p>
	<figure>
		<img
			src="{% static 'images/notSimple.svg' %}"
			alt="non-simple graph"
			loading="lazy"
			width="100px"
			height="100px"
		/>
	</figure>
	<p>
		First, for the graph to the left, the edge ${v_1}$ connects the same
		vertices as the edge ${v_2.}$ This violates
		<cite>Constraint 2.</cite> For the graph to the right, the edge ${v_6}$
		connects just one vertex. This violates <cite>Constraint 1.</cite>
	</p>
	<p>
		The graph below is also not a simple graph. It's an example of a
		<b>multigraph</b>.
	</p>
	<figure>
		<img
			src="{% static 'images/multiGraph.svg' %}"
			alt=""
			loading="lazy"
			width="100px"
			height="100px"
		/>
	</figure>
	<p>
		Simply put, a <i>multigraph</i> is a graph with at least one pair of
		edges connecting the same two vertices. If the graph contains a
		<b>loop</b> &mdash; an edge that connects a vertex to itself &mdash;
		then we have a <b>pseudograph</b>:
	</p>
	<figure>
		<img
			src="{% static 'images/pseudoGraph.svg' %}"
			alt=""
			loading="lazy"
			width="100px"
			height="100px"
		/>
	</figure>
	<p>
		A <i>pseudograph</i> is a graph that includes loops as well as edges
		connecting the same two vertices.
	</p>
	<p>
		Graphs can also have <i>direction.</i> Such a graph is called a
		<b>directed graph</b> &mdash; a graph where each edge is associated
		with a pair of vertices:
	</p>
	<figure>
		<img
			src="{% static 'images/digraph.svg' %}"
			alt=""
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>
		In the digraph above, we have the following edges: ${e_3 = (a, b),}$
		${e_2 = (b, c),}$ and ${e_1 = (c, d).}$ Below is a brief summary of
		various graphs:
	</p>
	<table class="alg">
		<thead>
			<th>Graph</th>
			<th>Directed edges?</th>
			<th>Multiple edges?</th>
			<th>Loops?</th>
		</thead>
		<tbody>
			<tr>
				<td>Simple graph</td>
				<td>No</td>
				<td>No</td>
				<td>No</td>
			</tr>
			<tr>
				<td>Multigraph</td>
				<td>No</td>
				<td>Yes</td>
				<td>No</td>
			</tr>
			<tr>
				<td>Pseudograph</td>
				<td>No</td>
				<td>Yes</td>
				<td>Yes</td>
			</tr>
			<tr>
				<td>Simple digraph</td>
				<td>Yes</td>
				<td>No</td>
				<td>No</td>
			</tr>
			<tr>
				<td>Multidigraph</td>
				<td>Yes</td>
				<td>Yes</td>
				<td>No</td>
			</tr>
			<tr>
				<td>Mixed graph</td>
				<td>Yes</td>
				<td>Yes</td>
				<td>Yes</td>
			</tr>
		</tbody>
	</table>
	<p>
		Any graph that is not a directed graph is called an
		<b>undirected graph</b>. For undirected graphs, there are additional
		pieces of terminology to be familiar with. We'll use the graph below
		for reference.
	</p>
	<figure>
		<img
			src="{% static 'images/undirected_graph.svg' %}"
			alt="undirected graph"
			loading="lazy"
			width="120px"
			height="120px"
		/>
		<figcaption>The Graph ${U_g}$</figcaption>
	</figure>
	<p>
		Vertices that are connected by an edge are said to be
		<b>neighbors</b> of, or <b>adjcaent to</b>, one another. For example,
		in the graph above, the vertex ${a}$ is a neighbor of ${b.}$
	</p>
	<p>
		The <b>neighborhood</b> of a particular vertex ${v}$ is the set of all
		vertices that are neighbors of ${v.}$ In our reference graph ${U_g,}$
		the neighborhood of ${c}$ is denoted:
	</p>
	<figure>$$ \mathcal{N}(c) = \{ a, b, d \} $$</figure>
	<p>
		Similarly, an edge that connects two vertices is said to be
		<b>incident</b> to both those vertices. In the graph above, the edge
		${e_4}$ is incident to the vertices ${c}$ and ${b.}$
	</p>
	<p>
		The <b>degree</b> of a vertex ${v}$ is the number of edges incident to
		${v.}$) For example, the degree of the vertex ${a}$ in the graph
		${U_g}$ has four edges connected to it (the loop counts twice), so we
		write:
	</p>
	<figure>$$ \text{deg}(a) = 4 $$</figure>
	<p>
		In ${U_g,}$ the vertex ${d}$ has no edges connected to it, so it has a
		degree of ${\text{deg}(d) = 0.}$ A vertex with a degree of zero is
		called an <b>isolated vertex</b> or an <b>isolated node</b>.
	</p>
	<p>
		Finally, the vertex ${g}$ is called a <b>pendant</b> &mdash; a vertex
		with only one neighbor.
	</p>
	<section id="handshaking_theorem">
		<h3>The Handshake Theorem</h3>
		<p>Consider the following problem:</p>
		<dfn>
			<small>Handshake Problem</small>
			<p>
				Suppose there are ${6}$ people in a room. Each person must shake
				hands with every other person. How many handshakes occur?
			</p>
		</dfn>
		<p>
			At first, this problem appears difficult. But if we visualize the
			problem with a graph, it's suddenly much more accessible:
		</p>
		<figure>
			<img
				src="{% static 'images/handshaking_theorem.svg' %}"
				alt="Handshaking theorem"
				loading="lazy"
				width="150px"
				height="150px"
			/>
		</figure>
		<p>
			Visualized as such, we just have to count the number of edges, with
			the constraint the we shouldn't count handshakes that have already
			occurred. Suppose we start the count with the vertex ${a.}$ Then
			${a}$ shakes hands with a total of ${5}$ people: ${b,}$ ${c,}$ ${d,}$
			${e,}$ and ${f.}$ If we then go to ${b,}$ we find that ${b}$ shook
			hands with ${4}$ people (in actuality, ${b}$ shook hands with ${5}$
			people, but since we already counted ${b}$ shaking hands with ${a,}$
			we don't count it again). With ${c}$ we have ${3}$ people, with ${d}$
			we have ${2}$ people, with ${e}$ ${1}$ person, and with ${f}$ zero.
		</p>
		<p>If we add all of the counted handshakes:</p>
		<figure>$$ 5 + 4 + 3 + 2 + 1 = 15 $$</figure>
		<p>
			Not difficult, but what if we had ${1000}$ people in the room? We
			wouldn't want to count the number of edges manually. Accordingly, we
			want a formula that answers the more general, mathematical question:
			Given a graph of ${n}$ vertices, each with a degree ${d,}$ how many
			edges are there?
		</p>
		<p>
			Well, let's consider our example with just ${6}$ people. If there are
			${6}$ people and each person must shake hands with another of the
			${6,}$ then: ${6 \times 5 = 30.}$ We know the answer is ${15.}$ Could
			a more general formula be:
		</p>
		<figure>$$ 2m = \sum\limits_{n \in V} \text{deg}(n) $$</figure>
		<p>
			It would fit our case. If ${2m = 30,}$ then ${m = 15,}$ where ${m}$
			is the number of edges. It turns out that this is, in fact, correct.
			Why? Because of the operation of <i>double counting</i>. Given an
			undirected graph with ${n}$ vertices, each edge contributes twice to
			the total degree count of all vertices. Accordingly, both sides of
			the equation must equal to twice the number of edges.
		</p>
		<p>As such, we have the following theorem:</p>
		<dfn>
			<small>Handshake Theorem</small>
			<p>
				Let ${G = (V, E)}$ be an undirected graph with ${m}$ edges. Then:
			</p>
			<figure>$$ 2m = \sum\limits_{v \in V} \text{deg}(v) $$</figure>
		</dfn>
	</section>

	<p>Having said all this, we now state our first definition formally:</p>
	<dfn class="rule">
		<small>Definition of a Graph</small>
		<p>
			A graph, denoted ${G,}$ is an non-empty ordered pair ${(V, E).}$
			I.e., ${G = (V, E).}$ The first element of the pair, ${V,}$ is the
			set of <i>vertices</i>, or <i>nodes</i>, of ${G.}$ The second element
			of the pair, ${E,}$ is the set of <i>edges</i> of ${G.}$ Each edge
			has 1 or 2 vertices associated with it, called the edge's
			<i>endpoints</i>. An edge <i>connects</i> its endpoints.
		</p>
	</dfn>
	<p>
		Note that in the definition above, we specified that the ordered pair
		must be non-empty. We place this condition to simplify many of the
		theorems we will explore. In later sections, we'll consider how the
		special case of the empty graph changes our theorems. For now, assume
		that all graphs are non-empty. That said, let's apply the definition
		above to another simple graph:
	</p>
	<figure>
		<img
			src="{% static 'images/graph2.svg' %}"
			alt="4 nodes, 4 edges"
			width="100px"
			height="100px"
			loading="lazy"
		/>
		<figcaption>Graph ${H}$</figcaption>
	</figure>
	<p>
		The graph above, ${H,}$ consists of 4 vertices and 4 edges. The
		vertices are denoted:
	</p>
	<figure>
		<div>
			<p>${V = \{ v_1, v_2, v_3, v_4 \}}$</p>
		</div>
	</figure>
	<p>And the edges:</p>
	<div>
		$$ \begin{aligned} E &= \{ e_1, e_2, e_3, e_4 \} \\[1em] &= \{ \{ v_1,
		v_2 \}, \{ v_2, v_3 \}, \{ v_3, v_4 \}, \{ v_4, v_1 \} \} \end{aligned}
		$$
	</div>
	<p>
		Now, just because the graph is non-empty does not imply that the graph
		must have edges. For our purposes, it's perfectly fine to have graphs
		with no edges. For example, here's a graph with no edges:
	</p>
	<figure>
		<img
			src="{% static 'images/no_edge_graph.svg' %}"
			alt="no edge graph"
			loading="lazy"
			width="100px"
			height="100px"
		/>
		<figcaption>The graph ${M}$</figcaption>
	</figure>
	<p>The graph above consists of vertices, but no edges:</p>
	<figure>
		<div>
			<p>${V = \{ v_1, v_2, v_3 \}}$</p>
			<p>${E = \varnothing}$</p>
		</div>
	</figure>
	<p>If there are edges, however, we have the following definition:</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition: Adjacent Nodes.</small> Two nodes ${v_i}$ and
				${v_j}$ are <b>adjacent</b> if ${\{ x_i, x_j \} \in E.}$
			</p>
		</div>
	</figure>
	<p>
		In other words, if the nodes ${v_i}$ and ${v_j}$ are connected with an
		edge, we say that ${v_i}$ and ${v_j}$ are adjacent. For example, these
		two nodes are adjacent:
	</p>
	<figure>
		<img
			src="{% static 'images/adjacent_nodes.svg' %}"
			alt="adjacent nodes"
			loading="lazy"
			width="120px"
			height="120px"
		/>
		<figcaption>
			Some nodes are adjacent, others are not. Notice that we can name
			nodes however way we'd like.
		</figcaption>
	</figure>
	<p>
		In the graph above, the nodes ${x_1}$ and ${x_2}$ are adjacent. The
		nodes ${x_2}$ and ${x_3}$ are adjacent, but ${x_1}$ and ${x_3}$ are
		not. Closely related to adjacency is
		<b>incidence</b>:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition: Incidence.</small> An edge ${e = \{ v_i, v_j
				\}}$ is <b>incident</b> to its <b>endpoints</b> ${v_i}$ and
				${v_j.}$
			</p>
		</div>
	</figure>
	<p>
		For example, in the graph below, the edge ${e_1}$ is incident to
		${n_1}$ and ${n_3:}$
	</p>
	<figure>
		<img
			src="{% static 'images/incidence.svg' %}"
			alt="incident nodes"
			loading="lazy"
			width="120px"
			height="120px"
		/>
		<figcaption>Incidence depends on the edge in consideration</figcaption>
	</figure>
	<p>
		With the definition of incidence, we can talk about the
		<b>degrees</b> of a node:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition: Degree of a Node.</small> The number of edges
				incident to a node is the <b>degree</b> of a node.
			</p>
		</div>
	</figure>
	<p>
		For example, the node ${p_6}$ in the graph below has a degree of ${5.}$
		All the other nodes have a degree of ${1.}$
	</p>
	<figure>
		<img
			src="{% static 'images/degree_of_a_node.svg' %}"
			alt="degree of a node"
			loading="lazy"
			width="120px"
			height="120px"
		/>
		<figcaption>A graph with different degrees.</figcaption>
	</figure>
	<p>
		Next, recall that we first stated that we will only consider simple
		graphs. The formal definition for a simple graph:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition.</small> A graph is <b>simple</b> if it has no
				loops or multiple edges.
			</p>
		</div>
	</figure>
	<p>
		Thus, the graphs below are not simple graphs. Graph ${A}$ contains a
		loop, and graph ${B}$ contains multiple edges:
	</p>
	<figure>
		<img
			src="{% static 'images/non_simple_graph.svg' %}"
			alt="non-simple graphs"
			loading="lazy"
			width="120px"
			height="120px"
		/>
		<figcaption>
			${A}$ contains a loop, and ${B}$ has multiple edges
		</figcaption>
	</figure>
	<p>
		A loop is simply an edge that connects a node to itself, and a multiple
		edge, also called a <b>multiedge</b>, is an edge that consists of edges
		that are really the same (connecting the same points).
	</p>
	<p>
		Returning to our Buzzfeed question, we can find an answer with the
		definitions we have so far. First, let's say the total population in
		the United States is ${V.}$ We'll think of this as the set of all
		nodes. In the United States, there are roughly ${300~000~000}$ people.
		Thus, ${n(V) \approx 300~000~000.}$ Within the set ${V,}$ we have two
		subsets: ${V_m}$ (the number of men) and ${V_w}$ (the number of women).
		There are roughly ${147~600~000}$ men. And the number of women is
		roughly ${152~400~000.}$ Thus, we have:
	</p>
	<figure>
		<div>
			<p>${n(V_m) \approx 147~600~000}$</p>
			<p>${n(V_w) \approx 152~400~000}$</p>
		</div>
	</figure>
	<p>
		Now, we don't know the size of the set ${E}$ (the set of all edges).
		But, if we represented each edge as a sexual relationship between a
		node in ${V_m}$ to a node in ${V_w,}$ the degree of each node is the
		number of sexual partners for that particular node. Thus, what we're
		really looking for is the ratio between the average degree for a node
		in ${V_m,}$ and the average degree for a node in ${V_w.}$ Let's denote
		the variables:
	</p>
	<figure>
		<div class="rule">
			<p>
				Let ${A_m}$ be the average number of opposite-gender partners for
				men.
			</p>
			<p>
				Let ${A_w}$ be the average number of opposite-gender partners for
				women.
			</p>
		</div>
	</figure>
	<p>The question then, is, what is the value of this expression:</p>
	<figure>
		<div>
			<p>${\dfrac{A_m}{A_w}}$</p>
		</div>
	</figure>
	<p>
		To find ${A_m,}$ we can just sum all of the degrees, and divide by the
		number of nodes:
	</p>
	<figure>
		<div>
			<p>
				${A_m = \dfrac{\sum\limits^{x \in V_m} \text{deg}(n)}{n(V_m)}}$
			</p>
		</div>
	</figure>
	<p>
		The sum in the expression is a bit too complicated to look at. Can we
		simplify it? Sure. Since there are only opposite gender partners, all
		of the edges appear once, and only once, when we're counting all of the
		degrees. Thus, summing all of the degrees is just summing all of the
		edges:
	</p>
	<figure>
		<div>
			<p>${A_m = \dfrac{n(E)}{n(V_m)}}$</p>
		</div>
	</figure>
	<p>The same analysis applies for computing ${A_w:}$</p>
	<figure>
		<div>
			<p>${A_w = \dfrac{n(E)}{n(V_w)}}$</p>
		</div>
	</figure>
	<p>Plugging these quantities into the original expression:</p>
	<figure>
		<div>
			$$ \begin{aligned} \dfrac{A_m}{A_w} &=
			\dfrac{\dfrac{n(E)}{n(V_m)}}{\dfrac{n(E)}{n(V_w)}} \\[2em] &=
			\dfrac{n(V_w)}{n(V_m)} \end{aligned} $$
		</div>
	</figure>
	<p>Now that's interesting. Using the population estimates, we have:</p>
	<figure>
		<div>
			$$ \begin{aligned} \dfrac{A_m}{A_w} &= \dfrac{n(V_w)}{n(V_m)} \\[1em]
			&\approx \dfrac{152~400~000}{147~600~000} \\[1em] &\approx 1.0325
			\end{aligned} $$
		</div>
	</figure>
	<p>
		Based on a purely mathematical analysis, men have roughly 3% more
		opposite sex partners then women. We didn't need any survey, years of
		research, or thousands of dollars in funding. Moreover, it has nothing
		to do with whether men are more promiscuous than women, or some theory
		of the modern patriarchy. It all came down to the simple fact that
		there are more women than men in the United States.
	</p>
	<p>
		Questions of this variety plague current literature. They appear in a
		variety of mutations: Why do minority students, on average, study more
		with non-minority students? Why are atheists, on average, more likely
		to marry non-atheists rather than atheists? Why are white men more
		likely to marry East Asian women?
	</p>
</section>

<section id="graph_theory_and_scheduling">
	<h2>Graph Theory & Scheduling</h2>
	<p>
		With the previous example, we used an edge to analyze the
		<b>affinity</b> between two nodes &mdash; the nodes have some sort of
		connection, or attraction, to one another. We can, however, also use
		graphs to analyze <b>aversion</b> between two nodes &mdash; the nodes
		cannot be near one another. Aversion is precisely what we use to solve
		scheduling problems. For example, consider the issue of scheduling
		final exams at a college. The goal is to ensure that no students take
		two exams at the same time (or to minimize the possibility of that
		event occurring). Suppose the college had five classes:
	</p>
	<ul>
		<li>BIO100 (denoted ${b}$), and</li>
		<li>CS100 (denoted ${c}$),</li>
		<li>HIST100 (denoted ${h}$).</li>
		<li>MATH100 (denoted ${m}$),</li>
		<li>PHYS100 (denoted ${p}$),</li>
	</ul>
	<p>Now let's say we have the following data:</p>
	<ul>
		<li>There are students enrolled in both BIO100 and CS100.</li>
		<li>There are students enrolled in both BIO100 and MATH100.</li>
		<li>There are students enrolled in both CS100 and PHYS100.</li>
		<li>There are students enrolled in both CS100 and MATH100.</li>
		<li>There are students enrolled in both PHYS100 and MATH100.</li>
		<li>There are students enrolled in both PHYS100 and HIST100.</li>
	</ul>
	<p>We can represent the data above with a graph:</p>
	<figure>
		<img
			src="{% static 'images/scheduling.svg' %}"
			alt="scheduling"
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>
		From the graph above, we can easily see where exams can't be scheduled.
		For example, with CS100, we cannot schedule an exam at the same time as
		BIO100, MATH100, or PHYS100. But, we can have the CS100 exam at the
		same time as HIST100.
	</p>
	<p>
		Now let's say we have the following time slots for the exam, all on a
		Wednesday:
	</p>
	<ul>
		<li>12:00 - 2:00pm, denoted ${c_1,}$</li>
		<li>2:00 - 4:00pm, denoted ${c_2,}$</li>
		<li>4:00 - 6:00pm, denoted ${c_3,}$</li>
		<li>6:00 - 8:00pm, denoted ${c_4,}$</li>
		<li>8:00 - 10:00pm, denoted ${c_5}$</li>
	</ul>
	<p>
		Our job is to ensure we don't use the late exam slots. The goal is to
		assign one of the time slots above such that nodes connected by an edge
		do not get the same time slot. This is called a
		<b>graph coloring problem</b>:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Problem: Graph Coloring.</small> Given a graph ${G}$ and
				${k}$ colors, assign a color to each node such that adjacent nodes
				get different colors.
			</p>
		</div>
	</figure>
	<p>
		The minimum number of colors we need is called the
		<b>chromatic number</b> of the graph:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition: Chromatic Number.</small> The minimum number of
				colors that solves a graph coloring problem is the
				<i>chromatic number</i> of the graph ${G,}$ denoted ${\Chi (G).}$
			</p>
		</div>
	</figure>
	<p>
		In our problem, a &#8220;color&#8221; is a time slot. Clearly, we can
		get away with ${5}$ colors:
	</p>
	<figure>
		<img
			src="{% static 'images/scheduling1.svg' %}"
			alt="scheduling"
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>
		But, we want to avoid the later time slots as much as we can. It looks
		like we can manage with ${4}$ colors:
	</p>
	<figure>
		<img
			src="{% static 'images/scheduling2.svg' %}"
			alt="scheduling"
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>How about ${3}$ colors? A little trickier, but yes, we can:</p>
	<figure>
		<img
			src="{% static 'images/scheduling3.svg' %}"
			alt="scheduling"
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>
		Now here's the real challenge: Can we do it in ${2?}$ Unfortunately,
		no. It cannot be done. This is because the nodes ${c,}$ ${b,}$ and
		${m}$ have edges connecting all through of them. Thus, we need, at a
		minimum, three colors. Thus, we can conclude that ${3}$ is the
		chromatic number. It's the best we can do.
	</p>
	<p>
		In general, solving graph coloring problems is unbelievably difficult.
		In fact, there is currently no known algorithm for finding chromatic
		numbers. The unusual characteristic of graph coloring problems is that
		they're very easy to verify solutions for, but it's tremendously
		difficult to find those solutions (essentially, trying an exponential
		number of possibilities).
	</p>
	<p>
		Graph coloring problems are members of a class of problems called
		<b>NP-complete problems</b>. There are roughly a thousand such
		problems, and they all have the characteristic of being easy to verify,
		but difficult to find, solutions for. Even more peculiar, solving just
		one of the NP complete problems solves the rest of the problems (or,
		alternatively, proving that no solution exists for just one problem
		proves that no solution exists for all of the problems). These problems
		are not purely academic. Software producers run into NP-complete
		problems repeatedly in development, and firms spend a significant
		amount of money searching for solutions or mitigating costs.
	</p>
	<section id="basic_coloring_algorithm">
		<h3>Basic Coloring Algorithm</h3>
		<p>
			Although there is no algorithm that completely solves a graph
			coloring problem, there are algorithms that can get us close. Here's
			a basic one:
		</p>
		<ol class="recipe">
			<li>Order the nodes ${v_1, v_2, \ldots, v_n.}$</li>
			<li>Order the colors ${c_1, c_2, \ldots, c_n.}$</li>
			<li>For ${i = 1, 2, \ldots, n:}$</li>
			<ol>
				<li>If ${v_i}$ has no adjacent nodes, assign the lowest color.</li>
				<li>Otherwise, if ${v_i}$ has adjacent nodes:</li>
				<ol>
					<li>
						Among the adjacent nodes, determine the lowest color assigned.
						Call it ${c_{\ell}.}$
					</li>
					<li>
						Among the adjacent nodes, determine the highest color assigned.
						Call it ${c_{h}.}$
					</li>
					<li>
						If there is a ${c_i < c_{\ell},}$ assign ${c_i}$ to ${v_i.}$
					</li>
					<li>
						If there is no color lower, assign the color ${c_{h + 1}}$ to
						${v_i.}$
					</li>
				</ol>
				<li>Increment ${i.}$</li>
				<li>If ${i \leq n,}$ return to step ${3.}$</li>
				<li>
					Otherwise, if ${i > n,}$ return the pairings of ${v_n}$ and
					${c_n.}$
				</li>
			</ol>
		</ol>
		<p>
			We call this algorithm the
			<b>basic coloring algorithm</b>. It's an example of a
			<b>greedy algorithm</b> &mdash; an algorith that attempts to
			accomplish the best result at each step, always moving forward. With
			greedy algorithms, there is no notion of &#8220;going back&#8221; and
			redoing a computation in light of new findings.
		</p>
		<p>
			Examining the basic coloring algorithm, we can likely tell it works
			well if all of the nodes have a low degree. For example, with the
			exam scheduling problem, the highest degree was three, and we got
			away with four colors. Better yet, we got away with three colors.
			Because of this result, we can suspect that if the maximum degree in
			the graph is some natural number ${d,}$ we would need, at most, one
			extra color. Let's state this suspicion as a hypothesis and determine
			if it's true or false via proof:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Hypothesis.</small>
					If every node in a graph ${G}$ has a degree less than or equal to
					${d,}$ then the basic coloring algorithm uses at most ${d + 1}$
					colors.
				</p>
			</div>
		</figure>
		<p>
			If our hunch is true, then we'd have an extremely useful insight: If
			the graph contains thousands, or even billions of nodes, and the
			maximum degree is three, we would only need four colors.
		</p>
		<p>
			To prove the proposition above, we will perform a proof-by-induction.
			As such, we need an inductive hypothesis. We could induct on ${d,}$
			but the problem with doing so is that it's not entirely clear how we
			would use ${d,}$ and how it relates to the number of nodes and edges.
			A better starting point is to consider ${n,}$ where ${n}$ is the
			number of graphs in the node. As such, our inductive hypothesis is a
			restatement of our original hypothesis:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Inductive Hypothesis.</small>
					If every node in an ${n}$-node graph ${G}$ has a degree less than
					or equal to ${d,}$ then the basic coloring algorithm uses at most
					${d + 1}$ colors.
				</p>
			</div>
		</figure>
		<p>
			We can now refer to our inductive hypothesis as ${P(n).}$ With
			graphs, it's almost always the case that we should start by consider
			${n,}$ where ${n}$ is the number of nodes. If that doesn't work, we
			should consider ${n(E)}$ where ${n(E)}$ is the number of edges. And
			only when these two approaches don't work do we consider ${d,}$ the
			degree of each node.
		</p>
		<p>
			Now we need a base case. Since we don't have any notion of graphs
			with no nodes, we consider the next simplest case: ${n = 1.}$ If ${n
			= 1}$ (a graph with only one node), then the number of edges is zero
			(since we don't allow loops). Thus, since ${d = 0,}$ we use at most
			${d + 1 = 0 + 1 = 1}$ colors. So we know our base case, ${P(1),}$ is
			true. For an ${n}$-node graph where ${n = 1,}$ the basic coloring
			algorithm uses at most ${d + 1}$ colors.
		</p>
		<p>
			Now we perform the inductive step: Assume ${P(n)}$ is true for the
			sake of induction &mdash; proving that ${P(n) \implies P(n + 1).}$
			With that assumption, we consider the ${P(n + 1)}$ proposition.
			${P(n) \implies P(n + 1)}$ is always true if ${P(n + 1)}$ cannot be
			false.
		</p>
		<p>
			With ${P(n + 1),}$ we're considering the graph with ${n + 1}$ nodes.
			Suppose the graph ${G = (V, E)}$ is any ${(n+1)}$-node graph. Suppose
			further that ${d}$ is the maximum degree in ${G.}$ Next, suppose the
			nodes are ordered (in any way):
		</p>
		<figure>
			<div>
				<p>${\lang v_1, v_2, \ldots, v_n, v_{n+1} \rang}$</p>
			</div>
		</figure>
		<p>
			Now we need to use our induction hypothesis. To do so, we we consider
			the nodes from ${v_1}$ through ${v_n,}$ ignoring ${v_{n+1}}$
			momentarily:
		</p>
		<figure>
			<div>
				<p>
					${\lang \underbrace{ v_1, v_2, \ldots,
					v_n,}_{\text{focus}}~v_{n+1} \rang}$
				</p>
			</div>
		</figure>
		<p>
			If we just focus on these nodes, we are really just considering an
			${n}$-node graph. We'll call this graph ${G'.}$
		</p>
		<figure>
			<div>
				<p>${G' = (V', E')}$</p>
			</div>
		</figure>
		<p>
			Consider ${G',}$ we observe that removing a node from the graph
			doesn't increase the
			<em>maximum</em> degree of ${G'.}$ Removing a node doesn't cause some
			node to have a greater degree. Which node has the highest degree
			might change, but the highest degree of ${G'}$ overall does not
			increase. It might decrease, but it does not increase. Thus, even if
			we remove a node from the graph ${G',}$ the maximum degree of ${G'}$
			remains ${d.}$ Thus, for the ${n}$-node graph, ${P(n)}$ is true
			because ${d}$ doesn't increase &mdash; given an ${n}$-node graph, the
			basic coloring algorithm, at most, uses ${d + 1}$ colors for ${v_1,
			v_2, \ldots, v_n.}$
		</p>
		<p>
			Now we consider the ${n+1}$-node graph. The node ${v_{n+1},}$ has at
			most ${d}$ neighbors.<sup></sup>
		</p>
		<div class="note">
			<p>A <b>neighbor</b> of a node ${v}$ is a node adjacent to ${v.}$</p>
		</div>
		<figure>
			<img
				src="{% static 'images/node_neighbors.svg' %}"
				alt="node neighbors"
				loading="lazy"
				width="120px"
				height="120px"
			/>
			<figcaption>${v_{n+1}}$ has ${\leq d}$ neighbors.</figcaption>
		</figure>
		<p>
			Given that ${v_{n+1}}$ has at most ${d}$ neighbors, what does this
			mean in terms of the colors we can use? Well, we know that it can't
			be any one of the colors assigned to the neighbors ${u_1, u_2,
			\ldots, u_d.}$ Thus, we can rule out ${d}$ colors. Given that we're
			working with ${d}$ colors, we have:
		</p>
		<figure>
			<div>
				<p>${(d + 1) - d = 1}$</p>
			</div>
		</figure>
		<p>
			color left to use safely. Thus, there is at least one color in the
			set of ${d + 1}$ colors unused by any neighbor. That color can be
			assigned to ${v_{n+1}.}$ It follows then that the basic algorithm
			uses, at most, ${d + 1}$ colors on some graph ${G,}$ which in turn
			proves that ${P(n+1)}$ is true. We've completed the induction:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Theorem.</small>
					If every node in an ${n}$-node graph ${G}$ has a degree less than
					or equal to ${d,}$ then the basic coloring algorithm uses at most
					${d + 1}$ colors.
				</p>
			</div>
		</figure>
		<p>
			Importantly, the theorem above only provides an upper bound. It says
			nothing about whether we can get away with less than ${d + 1.}$ In
			fact, the most obvious example of a graph where we can do better than
			${d + 1}$ is a <b>star graph</b>:
		</p>
		<figure>
			<img
				src="{% static 'images/star_graph.svg' %}"
				alt="star graph"
				loading="lazy"
				width="80px"
				height="80px"
			/>
		</figure>
		<p>A more complicated example:</p>
		<figure>
			<img
				src="{% static 'images/bipartite-graph-1.svg' %}"
				alt="bipartite graph"
				loading="lazy"
				width="130px"
				height="130px"
			/>
		</figure>
		<p>
			Notice that red node connects to each yellow node other than the node
			directly across from it. Because of this property, we can get away
			with two colors, red and yellow. This only works, however, if we used
			the right ordering:
		</p>
		<figure>
			<img
				src="{% static 'images/bipartite-graph-2.svg' %}"
				alt="bipartite graph"
				loading="lazy"
				width="130px"
				height="130px"
			/>
		</figure>
		<p>Had we used another ordering, we'd be in trouble:</p>
		<figure>
			<img
				src="{% static 'images/bipartite-graph-2.svg' %}"
				alt="bipartite graph"
				loading="lazy"
				width="130px"
				height="130px"
			/>
		</figure>
		<p>
			The graphs above are called <b>bipartite graphs</b>. The formal
			definition:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition: Bipartite Graph.</small> A graph ${G = (V,
					E)}$ is a bipartite graph iff the vertices ${V}$ can be
					partitioned (i.e., split) into two sets, ${V_\ell}$ (the left
					set) and ${V_r}$ (the right set), so that all the edges connect a
					node in ${V_\ell}$ to a node in ${V_r.}$
				</p>
			</div>
		</figure>
	</section>
</section>

<section id="matching">
	<h2>Matching</h2>
	<p>
		In human society, there are numerous relations concern
		<i>attraction</i>. By attraction, we mean objects that share some
		common bond. For example, a man and a woman might share the bond of
		marriage, just as two women would. In the United States, recent medical
		school graduates look for residences &mdash; a bond between the
		freshly-minted doctor and a hospital. The same doctors have taught us
		that heart disease is the U.S.'s greatest killer, through evidence of a
		common bond &mdash; a person and a cause of death.
	</p>
	<p>
		In mathematics, we call these bonds <b>matchings</b>, and algorithms
		for solving their associated problems are called
		<b>matching algorithms</b>. These algorithms pervade huge swathes of
		modern life. Indeed, we are just beginning to see generations of humans
		resulting from the application of these algorithms. There are now
		children whose parents met through Tinder, Grindr, Her, Scissr, Bumble,
		Hinge, and OkCupid, to name a few. Regardless of user base, all of
		these platforms only work because of some matching algorithm.
	</p>
	<p>
		The matching algorithm's goal is to find the maximum number of matches.
		To understand how this is accomplished, we begin with the formal
		definition of a matching:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition: Matching.</small> Given a graph ${G,}$ with
				nodes ${V}$ and edges ${E,}$ a matching is a subgraph of ${G}$
				&mdash; a subset of ${V}$ and ${E}$ &mdash; where every node has
				degree 1.
			</p>
		</div>
	</figure>
	<p>
		Matchings are also called <b>independent edge sets</b> &mdash; a set of
		edges where no two edges are adjacent. This is similar to the
		<b>independent node set</b> &mdash; a set of nodes where no two nodes
		are adjacent. For example, consider the following graph:
	</p>
	<figure>
		<img
			src="{% static 'images/independent_sets.svg' %}"
			alt="independent sets"
			loading="lazy"
			height="220px"
			width="220px"
		/>
	</figure>
	<p>
		The graph above contains the independent vertex set ${\{ v_1, v_4, v_6
		\}.}$ None of these vertices are adjacent to one another. The
		independent edge set &mdash; a matching &mdash; is a subgraph of the
		graph above where no two edges are adjacent. And when are no two edges
		adjacent? When the two edges
		<em>do not share</em> a common endpoint. Thus, in the graph above, one
		matching is ${\{ v_1-v_2, v_5-v_6 \}.}$
	</p>
	<p>Here's another example:</p>
	<figure>
		<img
			src="{% static 'images/matching1.svg' %}"
			alt="Matchings"
			loading="lazy"
			width="150px"
			height="150px"
		/>
	</figure>
	<p>
		Here, one matching is ${\{ n_1-n_6, n_2-n_5. \}}$ There are two
		elements in this matching, so we say that this matching has a size of
		${2.}$ Is there a bigger matching? Sure: ${\{n_1-n_7, n_2-n_6,
		n_3-n_5\}.}$ This is a matching of size ${3.}$ Can we get a matching of
		size ${4?}$ It looks like we can't. There are only ${8}$ nodes, so to
		have ${4}$ matches, we'd have to have all ${8}$ nodes involved in the
		matching. Thus, ${n_7}$ and ${n_8}$ would have to be involved in the
		matching, but both of them can only be paired with ${n_1.}$ Thus, with
		this graph, ${3}$ is the best we can do.
	</p>
	<p>
		Given some graph ${G,}$ if we manage to get all of ${G}$'s node in a
		matching, then we have a <b>perfect matching</b>. Formally:
	</p>
	<figure>
		<div class="rule">
			<p>
				<small>Definition.</small> Given a graph ${G,}$ matching is
				<i>perfect</i> iff it has a size ${\dfrac{n(V)}{2},}$ where ${V}$
				is the set of all vertices of ${G.}$
			</p>
		</div>
	</figure>
	<p>Consider the following graph:</p>
	<figure>
		<img
			src="{% static 'images/perfect_match1.svg' %}"
			alt="Possible perfect match"
			loading="lazy"
			width="120px"
			height="120px"
		/>
	</figure>
	<p>Here, we see that we have a perfect matching:</p>
	<figure>
		$$ M = \left\{ \begin{aligned} a_1 - b_1, \\ a_2 - b_3, \\ a_3 - b_2,
		\\ a_4 - b_4 \end{aligned} \right\} $$
	</figure>
	<p>
		There are ${8}$ vertices total, and the matching above has the size:
	</p>
	<figure>
		<div>
			<p>${n(M) = \dfrac{n(V)}{2} = \dfrac{8}{2} = 4.}$</p>
		</div>
	</figure>

	<section id="weighted_edges">
		<h3>Weighted Graphs</h3>
		<p>
			Let's a bit more nuance to our graphs. When we're working with
			matches, it's often the case that some matches weigh more than
			others. For example, the horse breeder pairing male horses to female
			horses might find that certain male horses would better paired with
			certain female horses. Those desirable pairings, in a sense, weigh
			more than others. In graph theory, we quantify this notion of
			desirability through <b>weighted edges</b>. For example, the edges in
			the graph below have varying edges.
		</p>
		<figure>
			<img
				src="{% static 'images/weighted_edges1.svg' %}"
				alt="weighted edges"
				loading="lazy"
				width="140px"
				height="140px"
			/>
		</figure>
		<p>
			Examining the graph above, heaviest edges are ${a_1-b_2}$ and
			${a_4-b_4.}$ The lightest edge is ${a_1-b_1.}$ Generally, when we
			work with weighted edges, a lower weight corresponds to a more
			desirable match, and a heavier weight corresponds to less desirable
			match.<sup></sup> Using this abstraction, we can state propositions
			like:
		</p>
		<div class="note">
			<p>
				Problems involving weighted matchings typically only arise with
				perfect matchings.
			</p>
		</div>
		<figure>
			<div>
				<ul>
					<li>
						${a_4}$ and ${b_1}$ have a better chance of staying in a
						relationship than ${a_4}$ and ${b_4.}$
					</li>
					<li>
						It makes no difference if ${a_2}$ dates ${b_3}$ or ${b_4.}$
					</li>
					<li>${a_1}$ really should date ${b_1.}$</li>
				</ul>
			</div>
		</figure>
		<p>
			Given that each edge in the graph has a weight, the graph as a whole
			has a weight. Formally:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition.</small> The weight of a matching ${M,}$
					denoted ${\mathcal{W}(M),}$ is the sum of the weights on the
					edges of ${M.}$
				</p>
			</div>
		</figure>
		<p>
			Furthermore, since the graph has subgraphs comprising matchings, each
			of those matchings have a weight. With weighted matching problems,
			the goal is usually to find a matching with the smallest possible
			weight. Formally:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition.</small> A <i>minimum weight matching</i> for a
					graph ${G}$ is a perfect matching for ${G}$ with the minimum
					weight over all perfect matchings.
				</p>
			</div>
		</figure>
		<p>
			Note how the definition constrains the notion of a minimum weight
			matching to perfect matchings. This constraint exists because without
			it, we would always have minimum weight matchings &mdash; just pull
			out ignore some or all of the nodes.
		</p>
		<p>For example, consider the following graph:</p>
		<figure>
			<img
				src="{% static 'images/weighted_edges2.svg' %}"
				alt="weighted edges"
				loading="lazy"
				width="100px"
				height="100px"
			/>
			<figcaption>A weighted graph with perfect matchings.</figcaption>
		</figure>
		<p>
			What's the weight of the minimum weight matching for the graph above?
			By our definition, its ${20.}$ The prefect matchings are ${(B-J)}$
			and ${(C-A).}$ Both of these matchings have a weight of ${10.}$
		</p>
		<p>
			A more interesting form of weight matching is
			<b>preference matching</b>. The idea is simple: Suppose each of the
			nodes in Figure 9 are individuals with preferences for mates. We
			represent these preferences by labelling each of the edges:
		</p>
		<figure>
			<img
				src="{% static 'images/weighted_edges3.svg' %}"
				alt="weighted edges"
				loading="lazy"
				width="100px"
				height="100px"
			/>
			<figcaption>A prefered graph.</figcaption>
		</figure>
		<p>
			With preference graphs, we encapsulate a variety of propositions. For
			example, ${B}$ prefers ${A}$ first, and ${J}$ second. ${A}$ prefers
			${B}$ first and ${C}$ second. ${B}$ prefers ${J}$ second, but ${J}$
			prefers ${B}$ first, and so on.
		</p>
		<p>
			Now, what happens if we placed ${B,}$ ${J,}$ ${C,}$ and ${A}$ on a
			desert island, with ${C}$ married to ${A}$ and ${B}$ married to
			${J?}$ Well, we'd have a problem. ${B}$ and ${A}$ have the hots for
			each other, with ${C}$ left to his unrequited love for ${A.}$ In
			mathematics, we say that ${A}$ and ${B}$ are a
			<b>rogue couple</b>.
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition.</small> Given a matching ${M,}$ ${x}$ and
					${y}$ form a <i>rouge couple</i> if they prefer each other, over
					their mates in ${M.}$
				</p>
			</div>
		</figure>
		<p>
			Rogue couples create instability in the matchings. In mathematics, we
			define <b>stability</b> as follows:
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition.</small> A matching is <i>stable</i> if the
					matching ${M}$ contains no rogue couples.
				</p>
			</div>
		</figure>
		<p>
			For many graph problems, the goal is to find a stable perfect
			matching. For our desert island couples, the stable perfect matching
			is ${B-A,}$ ${J-C.}$ Note that this has nothing to do with
			<q>happiness.</q> Clearly ${C}$ and ${J}$ are unhappy. But, it's
			stable because ${A}$ and ${B}$ are staying together.
		</p>
		<p>
			Can we always find a stable perfect matching?<sup></sup> It turns out
			that if we allow members of the same sex to like one another, it is
			impossible to always have stable perfect matchings. However, if only
			members of the opposite sex liked one another, then it is possible to
			always find stable perfect matchings.
		</p>
		<div class="note">
			<p>Are we pessimists to say no? Optimists to say yes?</p>
		</div>
		<p>To illustrate, consider the following graph:</p>
		<figure>
			<img
				src="{% static 'images/weighted_edges4.svg' %}"
				alt="weighted edges"
				loading="lazy"
				width="200px"
				height="200px"
			/>
			<figcaption>A love triangle.</figcaption>
		</figure>
		<p>
			Above, we have a love triangle between the males ${L,}$ ${M,}$ and
			${N.}$ ${N}$ has the hots for ${L,}$ ${L}$ has the hots for ${M,}$
			and ${M}$ has the hots for ${N.}$ And then there's ${E.}$ Assume that
			${E}$'s preferences are irrelevant &mdash; none of the other three
			men have the hots for him.
		</p>
		<p>
			Here's a claim: There is no stable matching ${M}$ for the graph
			above. To prove this proposition, we use proof-by-contradiction.
			First, we assume there is a stable matching ${M.}$
		</p>
		<p>
			Now, if there's a stable matching, then ${E}$ must be matched with
			one of ${L,}$ ${M,}$ or ${N.}$ Without loss of generality,<sup
			></sup> suppose ${E}$ is matched with ${L.}$ If ${E}$ is matched with
			${L,}$ then ${N}$ is matched with ${M.}$ Between ${L}$ and ${M,}$
			${N}$ prefers ${L.}$ And between ${E}$ and ${N,}$ ${L}$ prefers
			${N.}$ Thus, ${L}$ and ${N}$ prefer each other to their mates. Thus,
			we have a <i>rogue couple</i>.
		</p>
		<div class="note">
			<p>
				This is another way of saying, <q>by symmetry.</q> In our case,
				this means <q>No matter who ${E}$ is matched with.</q> Note that we
				must always be careful about using this phrase. There are
				situations where making a particular choice <i>does</i> lead to a
				loss of generality.
			</p>
		</div>
		<p>
			Given that there is a rogue couple, the matching ${M}$ is
			<em>not</em> stable. This contradicts our original assumption &mdash;
			that there is a stable matching ${M.}$ Thus, the negation of our
			original assumption must be true: There is no stable matching ${M}$
			for the graph above.
		</p>
	</section>

	<section id="stable_marriage">
		<h3>The Stable Marriage Problem</h3>
		<p>
			If, however, we restricted matchings to only be between men and
			women, we would always find a stable matching. This proposition is
			presented in the
			<b>stable marriage problem</b>.
		</p>
		<figure>
			<div class="rule">
				<p>
					<small>Definition: Stable Marriage Problem.</small>
					Suppose the following: There are ${N}$ men and ${N}$ women. Each
					man has his own ranked preference list of all the women, and each
					woman has her own ranked preference list of all the men. Both
					lists are complete, and there are no ties. Is there a perfect
					matching without rogue couples?
				</p>
			</div>
		</figure>
		<p>
			Suppose the following preferences in the table below. Each number in
			the man column is a unique male individual, and each letter in the
			woman column is a unique female individual. The preferences are then
			provided, in order from most preferred to least preferred. The man's
			preferences are immediately to the right, and the woman's preferences
			immediately to the left.
		</p>
		<figure>
			<div>
				<table class="alg">
					<thead>
						<th>Man</th>
						<th>Preference</th>
						<th>Preference</th>
						<th>Woman</th>
					</thead>
					<tbody>
						<tr>
							<td>1</td>
							<td>C, B, E, A, D</td>
							<td>3, 5, 2, 1, 4</td>
							<td>A</td>
						</tr>
						<tr>
							<td>2</td>
							<td>A, B, E, C, D</td>
							<td>5, 2, 1, 4, 3</td>
							<td>B</td>
						</tr>
						<tr>
							<td>3</td>
							<td>D, C, B, A, E</td>
							<td>4, 3, 5, 1, 2</td>
							<td>C</td>
						</tr>
						<tr>
							<td>4</td>
							<td>A, C, D, B, E</td>
							<td>1, 2, 3, 4, 5</td>
							<td>D</td>
						</tr>
						<tr>
							<td>5</td>
							<td>A, B, D, E, C</td>
							<td>2, 3, 4, 1, 5</td>
							<td>E</td>
						</tr>
					</tbody>
				</table>
			</div>
		</figure>
		<p>
			What algorithm can we use to determine if there's a stable matching
			here? We could use a <i>greedy</i> approach &mdash; just go down the
			table, giving each man their best available choice:
		</p>
		<figure>
			<div>
				<table class="alg">
					<thead>
						<th>Man</th>
						<th>Preference</th>
						<th>Preference</th>
						<th>Woman</th>
					</thead>
					<tbody>
						<tr>
							<td>1</td>
							<td>
								<span class="c Green">C</span> <span class="c">B</span>
								<span class="c">E</span> <span class="c">A</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">3</span> <span class="c">5</span>
								<span class="c Grey">2</span> <span class="c">1</span>
								<span class="c">4</span>
							</td>
							<td>A</td>
						</tr>
						<tr>
							<td>2</td>
							<td>
								<span class="c Green">A</span> <span class="c">B</span>
								<span class="c">E</span> <span class="c">C</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">5</span> <span class="c">2</span>
								<span class="c">1</span> <span class="c Yellow">4</span>
								<span class="c">3</span>
							</td>
							<td>B</td>
						</tr>
						<tr>
							<td>3</td>
							<td>
								<span class="c Green">D</span> <span class="c">C</span>
								<span class="c">B</span> <span class="c">A</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c">4</span> <span class="c">3</span>
								<span class="c">5</span> <span class="c Yellow">1</span>
								<span class="c">2</span>
							</td>
							<td>C</td>
						</tr>
						<tr>
							<td>4</td>
							<td>
								<span class="c">A</span> <span class="c">C</span>
								<span class="c">D</span> <span class="c Yellow">B</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c">1</span> <span class="c">2</span>
								<span class="c Grey">3</span> <span class="c">4</span>
								<span class="c">5</span>
							</td>
							<td>D</td>
						</tr>
						<tr>
							<td>5</td>
							<td>
								<span class="c">A</span> <span class="c">B</span>
								<span class="c">D</span> <span class="c Yellow">E</span>
								<span class="c">C</span>
							</td>
							<td>
								<span class="c">2</span> <span class="c">3</span>
								<span class="c">4</span> <span class="c">1</span>
								<span class="c Orange">5</span>
							</td>
							<td>E</td>
						</tr>
					</tbody>
				</table>
			</div>
		</figure>
		<p>
			Are there any rogue couples using the greedy approach? Yes. If we
			look at Man 4, he prefers C over B, and C has 4 as her first
			preference. Moreover, Man 5 prefers A over E, and A prefers 5 over 2.
		</p>
		<figure>
			<div>
				<table class="alg">
					<thead>
						<th>Man</th>
						<th>Preference</th>
						<th>Preference</th>
						<th>Woman</th>
					</thead>
					<tbody>
						<tr>
							<td>1</td>
							<td>
								<span class="c Green">C</span> <span class="c">B</span>
								<span class="c">E</span> <span class="c">A</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">3</span> <span class="c Black">5</span>
								<span class="c Grey">2</span> <span class="c">1</span>
								<span class="c">4</span>
							</td>
							<td>A</td>
						</tr>
						<tr>
							<td>2</td>
							<td>
								<span class="c Green">A</span> <span class="c">B</span>
								<span class="c">E</span> <span class="c">C</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">5</span> <span class="c">2</span>
								<span class="c">1</span> <span class="c Yellow">4</span>
								<span class="c">3</span>
							</td>
							<td>B</td>
						</tr>
						<tr>
							<td>3</td>
							<td>
								<span class="c Green">D</span> <span class="c">C</span>
								<span class="c">B</span> <span class="c">A</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c Black">4</span> <span class="c">3</span>
								<span class="c">5</span> <span class="c Yellow">1</span>
								<span class="c">2</span>
							</td>
							<td>C</td>
						</tr>
						<tr>
							<td>4</td>
							<td>
								<span class="c">A</span> <span class="c Black">C</span>
								<span class="c">D</span> <span class="c Yellow">B</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c">1</span> <span class="c">2</span>
								<span class="c Grey">3</span> <span class="c">4</span>
								<span class="c">5</span>
							</td>
							<td>D</td>
						</tr>
						<tr>
							<td>5</td>
							<td>
								<span class="c Black">A</span> <span class="c">B</span>
								<span class="c">D</span> <span class="c Yellow">E</span>
								<span class="c">C</span>
							</td>
							<td>
								<span class="c">2</span> <span class="c">3</span>
								<span class="c">4</span> <span class="c">1</span>
								<span class="c Orange">5</span>
							</td>
							<td>E</td>
						</tr>
					</tbody>
				</table>
			</div>
		</figure>
		<p>
			Our greedy algorithm failed. There is, however, another algorithm we
			can use &mdash; the <i>mating algorithm</i>.
		</p>
	</section>

	<section id="mating_algorithm">
		<h3>The Mating Algorithm</h3>
		<p>
			One way to find a stable matching is through the
			<b>mating algorithm</b>. The algorithm goes as follows:
		</p>
		<ol>
			<li>
				There are ${a_1, a_2, \ldots, a_w}$ women and ${b_1, b_2, \ldots,
				b_m}$ men.
			</li>
			<li>
				Each man has a list of all the women ( a total of ${w}$ entries)
				ranked from the man's most favorite to least favorite.
			</li>
			<li>
				Ever <em>morning</em>, each man looks at the top of his list, goes
				in front of that woman's house, and serenades her, stereo overhead.
			</li>
			<ul>
				<li>
					If the man has no women on his list, he stays home and listens to
					the stereo alone.
				</li>
			</ul>
			<li>
				Every <em>afternoon</em>, if a woman has one or more suitors
				serenading her, the woman says to her favorite among the suitors:
				<q>Come back tomorrow.</q> To the others, the woman says:
				<q>Be gone!</q>
			</li>
			<ul>
				<li>
					Ever <em>evening</em>: If a man is told <q>Be gone!</q>, the man
					crosses that woman's name off the list. Otherwise, the man
					prepares a his playlist for the next day.
				</li>
			</ul>
			<li>
				Once all of the women has at most one suitor, the ritual ends, each
				woman married to her suitor.
			</li>
		</ol>
		<p>
			Just to see that this works, let's apply the algorithm. Suppose the
			women are ${A, B, C, D, E,}$ and the men are ${1,2,3,4,5.}$ Using our
			last example, the preferences are as follows:
		</p>
		<figure>
			<div>
				<table class="alg">
					<thead>
						<th>Man</th>
						<th>Preference</th>
						<th>Preference</th>
						<th>Woman</th>
					</thead>
					<tbody>
						<tr>
							<td>1</td>
							<td>C, B, E, A, D</td>
							<td>3, 5, 2, 1, 4</td>
							<td>A</td>
						</tr>
						<tr>
							<td>2</td>
							<td>A, B, E, C, D</td>
							<td>5, 2, 1, 4, 3</td>
							<td>B</td>
						</tr>
						<tr>
							<td>3</td>
							<td>D, C, B, A, E</td>
							<td>4, 3, 5, 1, 2</td>
							<td>C</td>
						</tr>
						<tr>
							<td>4</td>
							<td>A, C, D, B, E</td>
							<td>1, 2, 3, 4, 5</td>
							<td>D</td>
						</tr>
						<tr>
							<td>5</td>
							<td>A, B, D, E, C</td>
							<td>2, 3, 4, 1, 5</td>
							<td>E</td>
						</tr>
					</tbody>
				</table>
			</div>
		</figure>
		<p>
			Now suppose that the mating ritual runs for four days. In the table
			below, the <i>Day</i> columns indicate which men appear at the
			woman's home:
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c">2</span>
							<span class="c">4</span>
							<span class="c">5</span>
						</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c">1</span></td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c">3</span></td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			On day ${1,}$ woman ${A}$ has multiple suitors &mdash; ${2, 4, 5.}$
			Of these three men, she prefers ${5}$ most, so she tells ${5,}$
			<q>Come back tomorrow,</q> and the rest, <q>Be gone.</q> On the men's
			side of things, ${2}$ and ${4}$ cross ${A}$ off their list:
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c">5</span>
						</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c">1</span></td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c">3</span></td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>

			<table class="alg">
				<thead>
					<th>Man</th>
					<th>Preference</th>
					<th>Preference</th>
					<th>Woman</th>
				</thead>
				<tbody>
					<tr>
						<td>1</td>
						<td>C, B, E, A, D</td>
						<td>3, 5, 2, 1, 4</td>
						<td>A</td>
					</tr>
					<tr>
						<td>2</td>
						<td><del>A</del>, B, E, C, D</td>
						<td>5, 2, 1, 4, 3</td>
						<td>B</td>
					</tr>
					<tr>
						<td>3</td>
						<td>D, C, B, A, E</td>
						<td>4, 3, 5, 1, 2</td>
						<td>C</td>
					</tr>
					<tr>
						<td>4</td>
						<td><del>A</del>, C, D, B, E</td>
						<td>1, 2, 3, 4, 5</td>
						<td>D</td>
					</tr>
					<tr>
						<td>5</td>
						<td>A, B, D, E, C</td>
						<td>2, 3, 4, 1, 5</td>
						<td>E</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			For ${C}$ and ${D,}$ they each only had one suitor, so these men
			remained for the next day. This finishes day ${1}$, so we go on to
			day ${2.}$ On day ${2,}$ Man ${2}$ tries his luck with ${B,}$ and
			${4}$ tries his luck with ${C.}$
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c cancel">5</span>
						</td>
						<td><span class="c">5</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td><span class="c">2</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c cancel">1</span></td>
						<td><span class="c">1</span> <span class="c">4</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c">3</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Now ${C}$ is getting attention. Between ${1}$ and ${4,}$ ${C}$
			prefers ${4,}$ so she tells ${1}$ to beat it. ${1}$ goes home and
			tearfully crosses ${C}$ off his list:
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c cancel">5</span>
						</td>
						<td><span class="c">5</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td><span class="c">2</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c cancel">1</span></td>
						<td>
							<span class="c cancel">1</span> <span class="c">4</span>
						</td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c">3</span></td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>

			<table class="alg">
				<thead>
					<th>Man</th>
					<th>Preference</th>
					<th>Preference</th>
					<th>Woman</th>
				</thead>
				<tbody>
					<tr>
						<td>1</td>
						<td><del>C</del>, B, E, A, D</td>
						<td>3, 5, 2, 1, 4</td>
						<td>A</td>
					</tr>
					<tr>
						<td>2</td>
						<td><del>A</del>, B, E, C, D</td>
						<td>5, 2, 1, 4, 3</td>
						<td>B</td>
					</tr>
					<tr>
						<td>3</td>
						<td>D, C, B, A, E</td>
						<td>4, 3, 5, 1, 2</td>
						<td>C</td>
					</tr>
					<tr>
						<td>4</td>
						<td><del>A</del>, C, D, B, E</td>
						<td>1, 2, 3, 4, 5</td>
						<td>D</td>
					</tr>
					<tr>
						<td>5</td>
						<td>A, B, D, E, C</td>
						<td>2, 3, 4, 1, 5</td>
						<td>E</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Spirits high, ${1}$ wakes up on day ${3}$ and goes to the next woman
			on his list &mdash; ${B.}$
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c cancel">5</span>
						</td>
						<td><span class="c cancel">5</span></td>
						<td><span class="c">5</span></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td><span class="c cancel">2</span></td>
						<td><span class="c">2</span> <span class="c">1</span></td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c cancel">1</span></td>
						<td>
							<span class="c cancel">1</span>
							<span class="c cancel">4</span>
						</td>
						<td><span class="c">4</span></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c">3</span></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Unfortunately for ${1,}$ between him and ${2,}$ ${B}$ prefers ${2.}$
			Once again he's told to get lost, and another name is crossed off his
			list:
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c cancel">5</span>
						</td>
						<td><span class="c cancel">5</span></td>
						<td><span class="c">5</span></td>
						<td></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td><span class="c cancel">2</span></td>
						<td>
							<span class="c">2</span> <span class="c cancel">1</span>
						</td>
						<td></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c cancel">1</span></td>
						<td>
							<span class="c cancel">1</span>
							<span class="c cancel">4</span>
						</td>
						<td><span class="c">4</span></td>
						<td></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c">3</span></td>
						<td></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td></td>
						<td></td>
					</tr>
				</tbody>
			</table>

			<table class="alg">
				<thead>
					<th>Man</th>
					<th>Preference</th>
					<th>Preference</th>
					<th>Woman</th>
				</thead>
				<tbody>
					<tr>
						<td>1</td>
						<td><del>C</del>, <del>B</del>, E, A, D</td>
						<td>3, 5, 2, 1, 4</td>
						<td>A</td>
					</tr>
					<tr>
						<td>2</td>
						<td><del>A</del>, B, E, C, D</td>
						<td>5, 2, 1, 4, 3</td>
						<td>B</td>
					</tr>
					<tr>
						<td>3</td>
						<td>D, C, B, A, E</td>
						<td>4, 3, 5, 1, 2</td>
						<td>C</td>
					</tr>
					<tr>
						<td>4</td>
						<td><del>A</del>, C, D, B, E</td>
						<td>1, 2, 3, 4, 5</td>
						<td>D</td>
					</tr>
					<tr>
						<td>5</td>
						<td>A, B, D, E, C</td>
						<td>2, 3, 4, 1, 5</td>
						<td>E</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			On the fourth day, ${1}$ looked at this list and saw ${E.}$
			<q>Let this be the one,</q> ${1}$ prayed. And by fortune's hand:
		</p>
		<figure>
			<table class="alg">
				<thead>
					<th>Woman</th>
					<th>Day 1</th>
					<th>Day 2</th>
					<th>Day 3</th>
					<th>Day 4</th>
				</thead>
				<tbody>
					<tr>
						<td>A</td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">4</span>
							<span class="c cancel">5</span>
						</td>
						<td><span class="c cancel">5</span></td>
						<td><span class="c cancel">5</span></td>
						<td><span class="c">5</span></td>
					</tr>
					<tr>
						<td>B</td>
						<td>${\varnothing}$</td>
						<td><span class="c cancel">2</span></td>
						<td>
							<span class="c cancel">2</span>
							<span class="c cancel">1</span>
						</td>
						<td><span class="c">2</span></td>
					</tr>
					<tr>
						<td>C</td>
						<td><span class="c cancel">1</span></td>
						<td>
							<span class="c cancel">1</span>
							<span class="c cancel">4</span>
						</td>
						<td><span class="c cancel">4</span></td>
						<td><span class="c">4</span></td>
					</tr>
					<tr>
						<td>D</td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c cancel">3</span></td>
						<td><span class="c">3</span></td>
					</tr>
					<tr>
						<td>E</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td>${\varnothing}$</td>
						<td><span class="c">1</span></td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			${1}$ found love with ${E,}$ who had been waiting patiently for a
			suitor. Looking at the resulting matchings:
		</p>
		<figure>
			<div>
				<table class="alg">
					<thead>
						<th>Man</th>
						<th>Preference</th>
						<th>Preference</th>
						<th>Woman</th>
					</thead>
					<tbody>
						<tr>
							<td>1</td>
							<td>
								<span class="c">C</span> <span class="c">B</span>
								<span class="c Grey">E</span> <span class="c">A</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">3</span> <span class="c Blue">5</span>
								<span class="c">2</span> <span class="c">1</span>
								<span class="c">4</span>
							</td>
							<td>A</td>
						</tr>
						<tr>
							<td>2</td>
							<td>
								<span class="c">A</span> <span class="c Blue">B</span>
								<span class="c">E</span> <span class="c">C</span>
								<span class="c">D</span>
							</td>
							<td>
								<span class="c">5</span> <span class="c Blue">2</span>
								<span class="c">1</span> <span class="c">4</span>
								<span class="c">3</span>
							</td>
							<td>B</td>
						</tr>
						<tr>
							<td>3</td>
							<td>
								<span class="c Green">D</span> <span class="c">C</span>
								<span class="c">B</span> <span class="c">A</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c Green">4</span> <span class="c">3</span>
								<span class="c">5</span> <span class="c">1</span>
								<span class="c">2</span>
							</td>
							<td>C</td>
						</tr>
						<tr>
							<td>4</td>
							<td>
								<span class="c">A</span> <span class="c Blue">C</span>
								<span class="c">D</span> <span class="c">B</span>
								<span class="c">E</span>
							</td>
							<td>
								<span class="c">1</span> <span class="c">2</span>
								<span class="c Grey">3</span> <span class="c">4</span>
								<span class="c">5</span>
							</td>
							<td>D</td>
						</tr>
						<tr>
							<td>5</td>
							<td>
								<span class="c Green">A</span> <span class="c">B</span>
								<span class="c">D</span> <span class="c">E</span>
								<span class="c">C</span>
							</td>
							<td>
								<span class="c">2</span> <span class="c">3</span>
								<span class="c">4</span> <span class="c Yellow">1</span>
								<span class="c">5</span>
							</td>
							<td>E</td>
						</tr>
					</tbody>
				</table>
			</div>
		</figure>
		<p>
			Let's see if there are any rogue couples. To do so, we can just look
			at the table above. Looking at either the men or the women, if
			there's a non-colored circle before a colored circle, then there's a
			rogue couple risk. If a non-colored circle comes before the colored
			circle in the other side's preference list, then there is a rogue
			couple. For example, for Man ${1,}$ the women ${C}$ and ${B}$ are
			preferred over the match, ${E.}$ But if we look at ${C}$ and ${B}$'s
			preferences, ${1}$ does not rank higher than the selections.
			Conducting this test, there are no rogue couples. Hence, we've found
			a stable matching.
		</p>
		<p>
			Question: Does this algorithm always find a stable matching? Well,
			let's determine it via proof.
		</p>
		<p>
			The first step to proving this mating algorithm always finds a stable
			matching is to prove the following:
		</p>
		<dfn>
			<small>Proposition 1.</small>
			<p>The algorithm terminates.</p>
		</dfn>
		<p>
			After proving the algorithm terminates, we also want to prove that
			everyone gets married:
		</p>
		<dfn>
			<small>Proposition 2.</small>
			<p>The algorithm yields a perfect maching.</p>
		</dfn>
		<p>We also want to prove that there are no rogue couples:</p>
		<dfn>
			<small>Proposition 3.</small>
			<p>The algorithm's returned matching contains no rogue couples.</p>
		</dfn>
		<p>Let's first prove Proposition 1.</p>
		<math-proof>
			<small>Proof (by contradiction).</small>
			<div>
				<p>
					Suppose there are ${n}$ men and ${n}$ women. Since each man has a
					list ranking each of the women, each of the ${n}$ men have a list
					with ${n}$ names. As such, there are a total of ${n^2}$ list
					entries.
				</p>
				<p>
					Next, suppose the mating algorithm terminates in no less than
					${n^2 + 1}$ days. If the algorithm does not terminate on a
					particular day, then at least one woman had to choose a suitor
					and reject ${n \geq 1}$ men. This further implies that, if the
					algorithm does not terminate, then at least one man had to cross
					off at least one woman's name from their list.
				</p>
				<p>
					It follows then that if the mating algorithm does not terminate
					in ${n^2 + 1}$ days &mdash; as we supposed earlier &mdash; then
					there must have been ${n^2 + 1}$ cross-offs, across all of the
					lists. But, given that there are only ${n^2}$ list entries, and
					no woman gets added to a list, there cannot be ${n^2 + 1}$
					cross-offs. There must be less than ${n^2 + 1}$ crossoffs.
				</p>
				<p>
					The mating algorithm terminates in less than ${n^2 + 1}$
					executions. ${\blacksquare}$
				</p>
			</div>
		</math-proof>
		<p>
			So, we know that the mating algorithm terminates. The next
			proposition to determine: The mating algorithm always yields stable
			matchings &mdash; i.e., no rogue couples. To do so, we use an
			invariant:
		</p>
		<dfn>
			<span class="topic">Invariant 1.</span>
			<p>
				Let ${P}$ be: If a woman ${W}$ rejected a man ${M,}$ then ${M}$ has
				a suitor who she prefers to ${B.}$
			</p>
		</dfn>
		<p>
			To use this invariant, we must prove it is an invariant. To do this,
			we must prove the lemma:
		</p>
		<dfn>
			<span class="topic">Lemma 1.</span>
			<p>${P}$ is an invariant for the mating algorithm.</p>
		</dfn>
		<p>
			The lemma's proof is a proof by induction, and here, we're inducting
			on time. The base case then, is, Day ${0.}$ Question: Is
			<strong>Invariant 1</strong> true for the base case? Well, yes, but
			in a strange way. It's <i>vacuously true</i>. Since no rejection is
			ever made on Day ${0,}$ the sufficient condition in
			<strong>Invariant 1</strong> is false, so
			<strong>Invariant 1</strong> is true. Thus, we know that ${P(0)}$ is
			true.
		</p>
		<p>Now we perform the inductive step:</p>
		<dfn>
			<span class="topic">Inductive Assumption.</span>
			<p>Assume ${P}$ holds at the end of Day ${d.}$</p>
		</dfn>
		<p>
			With the <strong>Inductive Assumption</strong> in place, we want to
			prove that ${P}$ holds for Day ${d + 1.}$ If it's true up to Day
			${d,}$ why is it true up to Day ${d+1?}$ Well, there are two cases:
		</p>
		<div class="split">
			<dfn>
				<span class="topic">Case 1.</span>
				<p>A woman ${W}$ rejects a man ${M}$ <em>on</em> day ${d+1.}$</p>
			</dfn>
			<dfn>
				<span class="topic">Case 2.</span>
				<p>A woman ${W}$ rejects a man ${M}$ <em>before</em> ${d+1.}$</p>
			</dfn>
		</div>
		<p>
			Let's consider <strong>Case 1</strong>. If a woman ${W}$ rejects a
			man ${M}$ on day ${d+1,}$ then there was a man ${N}$ that ${W}$
			preferred over ${M.}$ This implies that ${P}$ is true on day ${d+1.}$
			Similarly for <strong>Case 2</strong>, if a woman ${W}$ rejected a
			man ${M}$ before day ${d+1,}$ then it must be true that there was a
			man ${N}$ that ${W}$ preferred over ${M.}$
		</p>
		<p>
			Because ${P}$ is true in both cases, we know that ${P}$ is true on
			day ${d:}$ ${W}$ had a better suitor on day ${d.}$ Now the question
			is, does ${P}$ hold for day ${d+1?}$ Well, this also consists of just
			two cases: Either ${W}$ has the same suitor on day ${d+1}$ or a
			better suitor comes along. This implies that ${P}$ is true on day
			${d+1.}$
		</p>
		<p>
			That takes care of our invariant. <strong>Invariant 1</strong> is, in
			fact, an invariant of the mating algorithm. Now we can consider
			<strong>Proposition 2</strong>: The mating algorithm yields a perfect
			matching. To prove this, we use contradiction.
		</p>
		<dfn>
			<span class="topic">Assumption 1.</span>
			<p>
				Assume that the mating algorithm does not yield a perfect matching
				(i.e., not everyone is married).
			</p>
		</dfn>
		<p>
			This means that there is some man ${M}$ that is not paired with some
			woman ${W.}$ If this is true, then ${M}$ was rejected by every woman
			${W.}$ This in turn means that every woman ${W}$ has some man ${N}$
			who is a better suitor than ${M.}$ But this cannot be true. If every
			woman had some man who was a better suitor than ${M,}$ then every man
			and woman should be married. Because there are an equal amount of men
			and women, it cannot be the case that ${M}$ is left unmarried.
		</p>
		<p>
			Now we must prove <strong>Proposition 3</strong>: The mating
			algorithm produces a stable matching. First, supoose man ${M_1}$ and
			${W_1}$ are any <i>pair</i> that are not married. If ${M_1}$ and
			${W_1}$ are not married, then there are two cases for why ${M_1}$ and
			${W_1}$ are not married:
		</p>
		<div class="split">
			<p>
				<span class="topic">Case 1.</span>
				${W_1}$ rejected ${M_1.}$ If ${W_1}$ rejected ${M_1,}$ then ${W_1}$
				has another suitor she prefers. This means that ${W_1}$ marries
				someone she prefers over ${M_1,}$ by
				<strong>Lemma 1</strong>. But if ${W_1}$ marries someone she
				prefers over ${M_1,}$ then it cannot be true that ${M_1}$ and
				${W_1}$ are a rogue couple. Therefore, there are no rogue couples
				in <strong>Case 1.</strong>
			</p>
			<p>
				<span class="topic">Case 2.</span>${W_1}$ never rejected ${M_1.}$
				If ${W_1}$ never rejected ${M_1,}$ then ${M_1}$ never serenaded
				${W_1,}$ since ${W_1}$ can only reject a suitor if the suitor
				serenaded her. And if ${M_1}$ never serenaded ${W_1,}$ then ${M_1}$
				was married before he reached ${W_1}$'s name on his list. Hence,
				${M_1}$ married a woman he preferred over ${W_1.}$ Therefore, there
				are no rogue couples in <strong>Case 2.</strong>
			</p>
		</div>
		<p>
			The cases above are the only two cases for rogue couples to occur.
			And given that no rogue couples occur in those cases, we know the
			mating algorithm produces a stable matching.
		</p>
	</section>
</section>

<section id="special_graphs">
	<h2>Special Simple Graphs</h2>
	<p>
		Certain kinds of simple graphs have special properties and appear
		frequently enough to merit their own names. These graphs are presented
		below.
	</p>
	<section id="complete_graphs">
		<h3>Complete Graphs</h3>
		<p>
			A <b>complete graph</b> is a simple graph that contains exactly one
			edge between each pair of distinct vertices. Given a complete graph
			of ${n}$ vertices, we denote the graph by writing ${K_n.}$ Below are
			the complete graphs of ${K_1,}$ ${K_2,}$ ${K_3,}$ ${K_4,}$ ${K_5,}$
			and ${K_6.}$
		</p>
		<figure>
			<img
				src="{% static 'images/complete_graphs.svg' %}"
				alt="complete graphs"
				loading="lazy"
				width="300px"
			/>
		</figure>
	</section>

	<section id="cycles">
		<h3>Cycles</h3>
		<p>
			A <b>cycle</b> is a graph with ${n \geq 3}$ vertices ${v_1, v_2, v_3,
			\ldots, v_n,}$ and edges ${\{ v_1, v_2 \},}$ ${\{ v_2, v_3 \},}$
			${\ldots}$ ${\{ v_{n-1}, v_n \},}$ and ${\{ v_n, v_1 \}.}$ Given a
			graph of ${n \geq 3}$ vertices, if the graph constitutes a cycle, we
			write ${C_n.}$ Below are some examples of cycles:
		</p>
		<figure>
			<img
				src="{% static 'images/cycle_graph.svg' %}"
				alt="complete graphs"
				loading="lazy"
				width="300px"
			/>
		</figure>
	</section>

	<section id="wheels">
		<h3>Wheels</h3>
		<p>
			A <b>wheel</b> is a cycle with a special modification: We add an
			additional vertex, called the <b>universal vertex</b>, upon which all
			the other vertices connect by edge. Given a graph with ${n \geq 3}$
			nodes, if the graph constitutes a wheel, we denote the graph as
			${W_n.}$
		</p>
		<figure>
			<img
				src="{% static 'images/wheel_graph.svg' %}"
				alt="complete graphs"
				loading="lazy"
				width="300px"
			/>
		</figure>
	</section>
</section>

<section id="bipartite_graphs">
	<h3>Bipartite Graphs</h3>
	<p>
		A <b>bipartite graph</b> is a graph whose vertex set can be divided
		into disjoint subsets ${A}$ and ${B,}$ such that each ${v \in A}$ is
		adjacent to a ${v \in B,}$ and each ${v \in B}$ is adjacent to a ${v
		\in A.}$ A common way to think about bipartite graphs is to imagine a
		game whose competitors are teams of father and son. One set of vertices
		consists of fathers (call it ${F}$), and another set of vertices
		consists of sons (call it ${S}$). Each father ${F}$ is then connected
		to their son in ${S}$ and each son in ${S}$ is connected to their
		father in ${F.}$
	</p>
	<figure>
		<img
			src="{% static 'images/bipartite_graph.svg' %}"
			alt="Bipartite graph"
			loading="lazy"
			height="150px"
		/>
	</figure>
</section>

<section id="digraphs">
	<h2>Directed Graphs</h2>
	<p>
		Next, le'ts go over a few terms related to directed graphs. We'll the
		graph below, Graph ${G_d,}$ for reference.
	</p>
	<figure>
		<img
			src="{% static 'images/directed_graph1.svg' %}"
			alt="A directed graph"
			loading="lazy"
			width="150px"
			height="150px"
		/>
	</figure>
	<p>
		Directed graphs still use standard terms like <q>vertices</q> and
		<q>edges.</q> The difference, however, is that we now care about
		<i>order</i>. With the undirected graph, if the vertices ${a}$ and
		${b}$ are connected by an edge, then the edge ${(a, b)}$ is the same as
		the edge ${(b,a).}$ This may or may not be the case for the undirected
		graph. It could very well be the case that the edge ${(a,b)}$ is
		<em>not</em> the same as ${(b,a).}$
	</p>
	<p>
		For example, in ${G_d,}$ the vertices ${w}$ and ${x}$ are connected by
		the edge ${(w, x).}$ The order here matters: Because of the arrow along
		the edge, the edge is ${(w,x),}$ not ${(x,w).}$ Specifically, when we
		see the edge ${(w, x)}$ on a digraph, we read it as one or the other of
		the following:
	</p>
	<ol>
		<li>
			<q>${w}$ is <i>adjacent to</i> ${x,}$</q>&ThickSpace; or
		</li>
		<li>
			<q>${x}$ is <i>adjacent from</i> ${w.}$</q>
		</li>
	</ol>
	<p>
		Focusing still on the edge ${(w,x),}$ the vertex ${w}$ is called the
		<b>initial vertex</b> or <b>tail</b>, and the vertex ${x}$ is called
		the <b>terminal vertex</b>, <b>end vertex</b>, or <b>head</b>.
	</p>
	<p>
		Digraph vertices have two kinds of degrees: the <b>indegree</b> and the
		<b>outdegree</b>. Suppose we had some vertex ${n}$ in a digraph. The
		<i>indegree</i> of ${n}$ is the number of edges <i>coming into</i> the
		vertex ${n.}$ We denote the indegree of ${n}$ by writing:
	</p>
	<figure>$$ \text{deg}^-(n) $$</figure>
	<p>
		The <i>outdegree</i> of ${n}$ is the number of edges
		<i>going out</i> of ${n.}$ We denote the outdegree of ${n}$ by writing:
	</p>
	<figure>$$ \text{deg}^+(n) $$</figure>
	<p>
		Digraphs have a very special property establishing a relationship among
		its edges:
	</p>
	<dfn>
		<small>Degree-sum Formula</small>
		<p>Given a directed graph ${G_d = (V, E),}$ the following is true:</p>
		$$ \sum\limits_{v \in V} \text{deg}^-(v) = \sum\limits_{v \in V}
		\text{deg}^+(v) = n(E) $$
	</dfn>
	<p>
		The degree-sum formula tells us that the sum of all the in-degrees is
		equal to the sum of all the out-degrees, which is equal to the number
		of edges in the given digraph.
	</p>
</section>

<section id="connectivity">
	<h2>Connectivity</h2>
	<p>
		Many problems are best solved by thinking of them in terms of
		<b>connectivity</b> &mdash; how various objects in the problem are
		related to one another. To understand how to perform these models, we
		begin by defining a few terms.
	</p>
	<p>
		Consider the graph below. Suppose each of the vertices represents a
		house, and each edge is a road.
	</p>
	<figure>
		<img
			src="{% static 'images/walk1.svg' %}"
			alt="walk"
			loading="lazy"
			width="150px"
		/>
	</figure>
	<p>
		Suppose our friend Shimura asks,
		<q>How do I get from house ${a}$ to house ${b}$?</q> Using the graph
		above, we can specify the edges:
		<q>Oh, just take ${e_3,}$ then ${e_5,}$ then ${e_7.}$</q> What we just
		did there is specify a <b>walk</b>.
	</p>
	<dfn>
		<small>Definition: Walk</small>
		<p>
			A <i>walk</i> is a finite sequence of linked edges. The walk begins
			at an <i>initial vertex</i> and ends at a <i>final vertex</i>. The
			<i>length</i> of the walk is the total number of times each edge in
			the walk is traversed.
		</p>
	</dfn>
	<p>
		Following the definition above, there are numerous possible walks we
		could've given Shimura:
	</p>
	<div class="compare">
		$$ \begin{aligned} &(e_3, e_5, e_7) \\ &(e_2, e_7) \\ &(e_1, e_8) \\
		&(e_3, e_5, e_6, e_8) \end{aligned} $$ $$ \begin{aligned} &(e_3, e_5,
		e_6, e_8) \\ &(e_2, e_5, e_4, e_8) \\ &(e_2, e_5, e_3, e_2, e_7) \\
		&(e_2, e_6, e_8) \end{aligned} $$
	</div>
	<p>
		If we wanted Shimura to get a good look at the neighborhood or the
		fastest way to get to ${f,}$ we would've given him a <b>trail</b>.
	</p>
	<dfn>
		<small>Definition: Trail</small>
		<p>
			A <i>trail</i> is a walk where
			<i>all of the edges are distinct</i> (i.e., no repeated edges).
			Vertices may be visited multiple times, but once an edge has been
			used it cannot be used again.
		</p>
	</dfn>
	<p>For example, the following are all trails from ${a}$ to ${f:}$</p>
	<div class="compare">
		$$ \begin{aligned} &(e_{10}, e_{8}) \\ &(e_2, e_7) \\ &(e_3, e_4, e_8)
		\\ \end{aligned}$$ $$ \begin{aligned} &(e_3, e_5, e_7) \\ &(e_2, e_5,
		e_4, e_8) \\ &(e_1, e_{10}, e_2, e_7)\end{aligned} $$
	</div>
	<p>
		If we wanted Shimura to see as many different houses as possible, we
		would've given him a <b>path</b>:
	</p>
	<dfn>
		<small>Definition: Path</small>
		<p>A <i>path</i> is a walk where <i>all vertices are distinct</i>.</p>
	</dfn>
	<p>Below are all examples of paths:</p>
	<div class="compare">
		$$ \begin{aligned} &(e_3, e_4, e_8) \\ &(e_2, e_7) \\ &(e_1, e_8)
		\end{aligned} $$ $$ \begin{aligned} &(e_{10}, e_8) \\ &(e_3, e_5, e_7)
		\\ &(e_2, e_5, e_4, e_8) \end{aligned} $$
	</div>
	<p>
		If there's a path between every pair of vertices in a graph, we say
		that the graph is <b>connected</b>.
	</p>
	<dfn>
		<small>Definition: Connected Graph</small>
		<p>
			A graph is <i>connected</i> if and only if there is a path between
			each pair of vertices in the graph. I.e., if, and only if, every
			vertex in the graph is connected to every other vertex in the graph,
			then the graph is connected.
		</p>
	</dfn>
	<p>
		Note that from the definitions, all paths and trails are walks, all
		paths are trails, but not all trails are paths, nor are all walks paths
		or trails. For example, the walk ${(e_1, e_{10}, e_1)}$ is neither a
		path nor a trail. The walk ${(e_1, e_{10})}$ is a trail, but it is not
		a path.
	</p>
	<p>
		If we start at one house and end up at the same house, we've performed
		a <b>closed walk</b>. For example, the walk:
	</p>
	<figure>$$ (c, e_{10}, a, e_1, c, e_{10}, a, e_1, c) $$</figure>
	<p>is a closed walk. We start at ${c}$ and end up at ${c.}$</p>
	<dfn>
		<small>Definition: Closed Walk</small>
		<p>
			A <i>closed walk</i> is a walk whose initial vertex is also its final
			vertex.
		</p>
	</dfn>
	<p>
		Suppose we go on a walk with Shimura, starting at our house ${a,}$
		walking different roads, before returning home. One way possible walk
		would be:
	</p>
	<figure>
		$$ (a, e_1, c, e_{10}, a, e_3, b, e_4, c, e_8, f, e_7, d, e_2, a) $$
	</figure>
	<p>
		Because all of the edges are different, this is <i>closed trail</i>. We
		call such a trail a <b>circuit</b>.
	</p>
	<dfn>
		<small>Definition: Circuit</small>
		<p>
			A <i>circuit</i> is a trail whose initial vertex is also its final
			vertex.
		</p>
	</dfn>
	<p>
		Before we go on our circuit with Shimura, he asks,
		<q
			>Could we set up our walk so I can see different houses along the
			way?</q
		>
		Being a good friend, we set up our walk as:
	</p>
	<figure>$$ (a, e_3, b, e_4, c, e_8, f, e_7, d, e_2, a) $$</figure>
	<p>
		Notice that this is a circuit. It's a trail because all of the edges
		are different, and it's a circuit because the initial vertex is the
		final vertex. It also has an additional property: the only repeated
		vertex is the initial and final vertex, ${a.}$ We call such a walk a
		<b>cycle</b>.
	</p>
	<dfn>
		<small>Definition: Cycle</small>
		<p>
			A <i>cycle</i> is a circuit with only one repeated vertex, which is
			both the initial and final vertex.
		</p>
	</dfn>

	<section id="eulerian_graphs">
		<h3>Eulerian Graphs</h3>
		<p>
			One of the most difficult exams in the world is the licensing exam
			for London's Black cab drivers. Test takers are expected to know the
			labyrinthine city's ${25~000}$ strees and all businesses or landmarks
			along them. Suppose we're coming up with a test for some small part
			of the city that looks like the following:
		</p>
		<figure>
			<img
				src="{% static 'images/eulerianWalk1.svg' %}"
				alt="walk"
				loading="lazy"
				height="200px"
			/>
		</figure>
		<p>
			Suppose we're told to come up with a walk that visits every edge
			exactly once. Such a walk might be:
		</p>
		$$ (a, e_1, b, e_9, f, e_7, b, e_2, c, e_6, d, e_8, c, e_3, d, e_4, f,
		e_5, g) $$
		<p>
			Notice that all of the edges are different, and we visit every edge
			exactly once. Because all of the edges are different, this is a
			trail. And because of the additional property that we visit every
			edge in the graph exactly once, we call it an <b>Eulerian trail</b>.
		</p>
		<dfn>
			<small>Definition: Eulerian Trail</small>
			<p>
				An <i>Eulerian trail</i> is a trail which uses every edge in the
				graph exactly once. I.e., a walk where:
			</p>
			<ul>
				<li>Every edge in the graph is visited, and</li>
				<li>every edge is visited exactly once.</li>
			</ul>
			<p>
				If such a trail exists, the graph is said to be <b>traversible</b>.
			</p>
		</dfn>
		<p>Now suppose we're given another map:</p>
		<figure>
			<img
				src="{% static 'images/eulerianCircuit.svg' %}"
				alt="walk"
				loading="lazy"
				height="100px"
			/>
		</figure>
		<p>
			This time we're told to come up with walk where we visit every edge
			exactly once, and return to our starting point. So we concoct this
			walk:
		</p>
		<figure>
			$$ (a, e_1, f, e_2, d, e_3, c, e_4, f, e_5, b, e_6, a) $$
		</figure>
		<p>
			Here, we see that every edge is different, every edge is visited, and
			both the initial vertex and the final vertex are the same. This is
			called an <b>Eulerian circuit</b>.
		</p>
		<dfn>
			<small>Definition: Eulerian Circuit</small>
			<p>
				An <i>Eulerian circuit</i> is an Eulerian trail which is a circuit.
				I.e., a walk where:
			</p>
			<ul>
				<li>Every edge in the graph is visited,</li>
				<li>every edge is visited exactly once, and</li>
				<li>the initial vertex is the final vertex.</li>
			</ul>
		</dfn>
		<p>If we had the same instructions for this map:</p>
		<figure>
			<img
				src="{% static 'images/eulerianCycle.svg' %}"
				alt="walk"
				loading="lazy"
				height="100px"
			/>
		</figure>
		<p>We would construct the walk:</p>
		<figure>
			$$ (a, e_1, b, e_2, c, e_3, d, e_4, f, e_5, g, e_6, a) $$
		</figure>
		<p>
			Here, all of the edges are distinct, and the only repeated vertex is
			${a,}$ which is both the initial and final vertex. Such a path is
			called an <b>Eulerian cycle</b>.
		</p>
		<dfn>
			<small>Definition: Eulerian Cycle</small>
			<p>
				An <i>Eulerian cycle</i> is an Eulerian circuit with only one
				repeated vertex. I.e., a walk where:
			</p>
			<ul>
				<li>Every edge in the graph is visited,</li>
				<li>every edge is visited exactly once,</li>
				<li>
					there is exactly one repeated vertex, which is both the initial
					vertex and final vertex.
				</li>
			</ul>
		</dfn>
		<p>Finally, if we had the following graph:</p>
		<figure>
			<img
				src="{% static 'images/eulerianPath.svg' %}"
				alt="walk"
				loading="lazy"
				height="100px"
			/>
		</figure>
		<p>
			visiting every edge in the graph, every edge exactly once, and ending
			on different points, we get an <b>Eulerian path</b>. In this case,
			the walk ${(a, e_1, b, e_2, c).}$
		</p>
		<dfn>
			<small>Definition: Eulerian path</small>
			<p>An Eulerian path is a walk where:</p>
			<ul>
				<li>Every edge in the graph is visited,</li>
				<li>every edge in the graph is visited exatly once, and</li>
				<li>all vertices in the walk are distinct.</li>
			</ul>
		</dfn>
		<section id="bridges_of_konigsburg">
			<h4>Bridges of Konigsburg</h4>
			<p>
				A famous problem in graph theory &mdash; arguably the one that
				really started the field as we know it today &mdash; is the
				<cite>Seven Bridges of Konigsburg</cite>.
			</p>
			<dfn>
				<small>Problem: Seven Bridges of Konigsburg</small>
				<div class="split">
					<p>
						Is there a walk that uses each of the edges in graph ${K}$
						once, and only once?
					</p>
					<figure>
						<img
							src="{% static 'images/konigsbergBridges.svg' %}"
							alt="walk"
							loading="lazy"
							height="100px"
						/>
						<figcaption>Graph ${K}$</figcaption>
					</figure>
				</div>
			</dfn>
			<p>
				Euler famously proved no, there is no walk that visits each of the
				edges in such a graph exactly once. To see why, we need a litle
				more terminology.
			</p>
			<p>
				First, we say that a vertex is an <b>odd vertex</b> if it has an
				odd number of edges connected to it (i.e., a vertex whose degree is
				an odd number). In contrast, we say that a vertex is an
				<b>even vertex</b> if it has an even number of edges connected to
				it (i.e., a vertex whose degree is an even number).
			</p>
			<figure>
				<img
					src="{% static 'images/oddEvenVertex.svg' %}"
					alt="walk"
					loading="lazy"
					height="100px"
				/>
			</figure>
			<p>
				To visit every edge in ${K}$ exactly once, we're essentially asked
				to determine if the graph is Eulerian. A graph is Eulerian if, and
				only if, it contains an Eulerian circuit. For a graph to contain an
				Eulerian circuit, each edge must be visited exactly once. And for
				each edge to be visited exactly once, each vertex must be reached
				by an edge and left by another edge which is not a loop. Thus, if a
				graph contains an odd vertex ${v_o,}$ then at least one edge from
				${v_o}$ is unvisited, and the graph is not Eulerian.
			</p>
			<p>This leads to <cite>euler's graph theorem</cite>:</p>
			<dfn>
				<small>Euler's Graph Theorem</small>
				<p>
					If a connected graph contains <i>any</i> vertices of odd degree,
					then the graph is not Eulerian.
				</p>
			</dfn>
			<p>
				Euler also proved the more difficult version of the theorem, the
				converse:
			</p>
			<dfn>
				<small>Euler's Graph Theorem: Converse</small>
				<p>
					A connected graph is Eulerian if and only if all of its vertices
					are even.
				</p>
			</dfn>
		</section>
	</section>

	<section id="hamiltonian_graphs">
		<h3>Hamiltonian Graphs</h3>
		<p>
			Where Eulerian graphs are primarily concerned with edges,
			<b>Hamiltonian graphs</b> are primarily concerned with vertices.
		</p>
		<dfn>
			<small>Hamiltonian Graph</small>
			<p>
				A graph is <i>Hamiltonian</i> if, and only if, there exists a cycle
				that passes through every vertex on the graph. Such a cyle is
				called a <b>Hamiltonian cycle</b>.
			</p>
		</dfn>
		<p>
			In other words, we have a Hamiltonian graph if and only if the graph
			contains a walk that:
		</p>
		<ol>
			<li>visits every vertex in the graph,</li>
			<li>has no repeated edges, and</li>
			<li>the walk's initial vertex is also its final vertex.</li>
		</ol>
		<p>For example, below is a Hamiltonian graph:</p>
		<figure>
			<img
				src="{% static 'images/hamiltonianGraph.svg' %}"
				alt="hamiltonian graph"
				loading="lazy"
				height="100px"
			/>
		</figure>
		<p>In this case, we have the Hamiltonian cycles:</p>
		<figure>
			$$ \begin{aligned} &(a, e_1, b, e_2, c, e_3, d, e_4, f, e_5, a) \\
			&(d, e_3, c, e_2, b, e_1, a, e_5, f, e_4) \end{aligned} $$
		</figure>
		<p>
			Notice the difference between the Hamiltonian graph and the Eulerian
			graph. With the Hamiltonian graph, we don't have to use every edge.
			As long as no edges are repeated, every vertex is visited, and we end
			where we start, we have a Hamiltonian graph.
		</p>
		<p>
			If we have a graph with a path that goes through every vertex exactly
			once, then we have a <b>Hamiltonian path</b>. A graph with a
			Hamiltonian path is said to be a <b>semi-Hamiltonian graph</b>. For
			example, the graph below contains a Hamiltonian path:
		</p>
		<figure>
			<img
				src="{% static 'images/hamiltonian_path.svg' %}"
				alt="hamiltonian graph"
				loading="lazy"
				height="100px"
			/>
		</figure>
		<figcaption>${(a, e_1, b, e_2, c, e_3, d, e_4, f)}$</figcaption>
		<p>
			Earlier, we saw that there's an easy trick to ruling out the
			possibility of a graph being Eulerian &mdash; if any vertex is an odd
			vertex, it is not Eulerian. There is no such trick with Hamiltonian
			graphs. In fact, determining whether Hamiltonian paths or cycles
			exist is known as the
			<cite>hamiltonian path problem</cite>, and it is NP-complete.
		</p>
		<p>
			There are, however, a few sufficient conditions that we can rely on.
			In other words, if the propositions below are true for a given graph
			${G,}$ then we can conclude that ${G}$ is Hamiltonian.
		</p>
	</section>
</section>
{% endblock %}
