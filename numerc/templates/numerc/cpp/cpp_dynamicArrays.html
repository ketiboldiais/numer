{% extends '../layout.html' %} {% load static %} {% block description %}
<meta name="description" content="Notes on algorithms for arrays." />
{% endblock %} {% block title %}
<title>Array Algorithms</title>
{% endblock %} {% block content %}

<h1>Arrays</h1>
<section id="intro">
	<p>
		<span class="drop">T</span>he first set of abstract data types we
		explore is the <span class="term">sequence</span>. Sequences allow us
		to store ${n}$ things in a specific order. Those things could be
		strings, integers, floating point values, or even other abstract data
		type objects.
	</p>
	<div id="array0"></div>
	<p>
		There are two kinds of array data structures: <b>static arrays</b> and
		<b>dynamic arrays</b>. Static arrays are arrays of fixed size, while
		dynamic arrays can lengthen and shorten at their ends. Because of this
		difference, what ADT we can represent with an array differs, depending
		on the kind of array we're using.
	</p>
	<figure>
		<!-- prettier-ignore -->
		<div class="mermaid">
      flowchart TB
        A[arrays] --> B[static arrays];
        A[arrays] --> C[dynamic arrays];
        B[static arrays] --> D[sequences];
        B[static arrays] --> E[sequences];
        C[dynamic arrays] --> F[vectors];
    </div>
	</figure>
	<p>
		The sequence data type consists of two subtypes: (a) the
		<span class="term">sequence</span><sup></sup> and (b) the
		<span class="term">list</span>.<sup></sup>
		The sequence type is a sequence with a fixed size. I.e., the number of
		elements in the sequence does not change. The list type is a sequence
		with a dynamic size; the sequence can grow or shrink through the
		insertion, shifting, or removing of elements in the sequence.
	</p>
	<div class="note">
		<p>
			The sequence is also called a
			<i>static sequence</i>.
		</p>
	</div>
	<div class="note">
		<p>
			The list data type is also called a
			<i>vector</i> or <i>dynamic sequence</i>.
		</p>
	</div>
	<p>The table below presents a cost-benefit analysis of static arrays.</p>

	<table id="cba1">
		<td>
			<section>
				<p>
					<b>Quick access.</b> Because array's have a fixed size, accessing
					the array's elements takes constant time &mdash; ${O(1).}$ This
					is, in fact, the greatest selling point for static arrays.
				</p>
				<p>
					Say we have some array <var>arr</var>. To access some element
					<var>arr[i]</var>, we only perform <em>one</em> memory access to
					read or write the data. This is not the case for the dynamic
					array. With dynamic arrays, we have to perform one memory access
					to read the array's reference, then a second memory access for
					the array element itself.
				</p>
			</section>
		</td>
		<td>
			<section>
				<p>
					<b>Rigidity.</b> Once an array is initialized, they have a fixed
					length that cannot be changed. For example, when we write:
				</p>
				<pre class="language-cpp"><code>
          int main() {
            int arr[] = {1,5,4,3,2};
            int arr_size = sizeof(arr)/sizeof(int);
            console.log(arr_size);
          }
        </code></pre>
				<pre class="language-bash"><code>
          5
        </code></pre>
				<p>
					The output <var>5</var> is the size of <var>arr</var>, and it
					will remain <var>5</var> so long as <var>arr</var> exists.
				</p>
			</section>
			<section>
				<p>
					<b>Passing by reference.</b> Depending on what we're using the
					array for, passing-by-reference can be a cost to ease of use. For
					example, consider a function that takes an array as a parameter.
					When we pass the array argument for that parameter, it's not the
					actual array that's passed &mdash; it's the address to the first
					element of that array.
				</p>
				<p>
					Because an address is passed, if we want to iterate over the
					array inside the function, we must provide the array's length.
				</p>
			</section>
		</td>
	</table>
</section>

<section id="array_basic_operations">
	<h2>Sequence ADT</h2>
	<p>The sequence ADT has the following API:</p>

	<table class="api uml">
		<thead>
			<th>Name</th>
			<th>Description</th>
			<th>Time Complexity</th>
		</thead>
		<tbody>
			<tr>
				<td colspan="3" class="blue">Properties</td>
			</tr>
			<tr>
				<td>_array:[T]</td>
				<td>
					The static array that store's objects of type <var>T</var>.
				</td>
				<td></td>
			</tr>
			<tr>
				<td>_size:size_t</td>
				<td>
					The maximum amount of elements that can be placed in the
					sequence.
				</td>
				<td></td>
			</tr>
			<tr>
				<td>_length:size_t</td>
				<td>The current amount of elements in the sequence.</td>
				<td></td>
			</tr>
			<tr>
				<td colspan="3" class="green">Methods</td>
			</tr>
			<tr>
				<td>Create() ⟹ Sequence</td>
				<td>Creates a new instance of the sequence.</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>Insert(index:size_t, element:T) ⟹ void</td>
				<td>
					Inserts a new element of type <var>T</var> in the sequence at the
					sequence's position <var>index</var>.
				</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>Append(element:T) ⟹ T</td>
				<td>
					Inserts an <var>element</var> at the end of the sequence. If
					<var>element</var> replaces an element, the replaced element is
					returned. Otherwise, <var>element</var> is returned.
				</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>Prepend(element:T)</td>
				<td>
					Inserts an <var>element</var> at the beginning of the sequence.
					If <var>element</var> replaces an element, the replaced element
					is returned. Otherwise, <var>element</var> is returned.
				</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>Delete(index:size_t) ⟹ T</td>
				<td>
					Deletes the element at the position <var>index</var> in the
					sequence.
				</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>Find(index:size_t) ⟹ T</td>
				<td>
					Returns the element at position <var>index</var> in the sequence.
				</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>Search(element:T) ⟹ bool</td>
				<td>
					Returns <var>true</var> if the sequence contains
					<var>element</var>, otherwise <var>false</var>.
				</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n),}$ ${O(\lg n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>IsEmpty() ⟹ bool</td>
				<td>
					Returns <var>true</var> if the sequence contains no elements,
					otherwise <var>false</var>.
				</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>IsFull() ⟹ bool</td>
				<td>
					Returns <var>true</var> if the sequence's <var>_size</var> is
					equal to its <var>_length</var>, otherwise <var>false</var>.
				</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>length() ⟹ size_t</td>
				<td>Returns the sequence's current <var>_length</var>.</td>
				<td>${O(1)}$</td>
			</tr>
			<tr>
				<td>print() ⟹ void</td>
				<td>Prints the sequence to the console.</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>reverse() => void</td>
				<td>Reverses the sequence's elements.</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>shift(direction:Direction) ⟹ void</td>
				<td>Shifts the elements.</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
			<tr>
				<td>rotate(direction:Direction) ⟹ void</td>
				<td>Rotates the elements.</td>
				<td>
					<table>
						<tr>
							<td>bc</td>
							<td>${O(1)}$</td>
						</tr>
						<tr>
							<td>ac</td>
							<td>${O(n)}$</td>
						</tr>
						<tr>
							<td>wc</td>
							<td>${O(n)}$</td>
						</tr>
					</table>
				</td>
			</tr>
		</tbody>
	</table>
	<section id="auxiliary_functions">
		<h3>Auxiliary Functions</h3>

		<p>
			Implementing our sequence ADT as a class, there are a few auxiliary
			functions that we will use as helpers for more complex procedures.
			These helper functions are explained below.
		</p>

		<section id="array_constructor">
			<h4>Sequence Constructor</h4>
			<p>
				To construct a sequence, we must create an array. There are two
				ways to create arrays: dynamically or statically. Let's consider
				the dynamic approach. The first step is to declare a pointer. For
				now, let's stick to
				<var>int</var> type data:
			</p>
			<ol class="alg">
				<li>int* arr;</li>
			</ol>
			<p>Next, we dynamically allocate memory:</p>
			<ol class="alg">
				<li>int* arr = new int[size];</li>
			</ol>
			<p>
				Now, in some languages like C++, we want more genericism. This
				means using a <b>template</b>:
			</p>
			<ol class="alg">
				<li>template&lt;class ${t}$&gt;</li>
				<li>int* arr = new int[size];</li>
			</ol>
			<p>
				By using a template, we can create more general arrays, rather than
				using a specific data type like <var>int</var>:
			</p>
			<ol class="alg">
				<li>template&lt;class ${t}$&gt;</li>
			</ol>
			<p>
				By writing the code above, we've now created a
				<b>generic array</b> &mdash; an array whose type is determined at
				<i>runtime</i>.
			</p>
			<p>
				Now, because the array has no members upon allocation, we say that
				the array has a length of ${0}$ initially:
			</p>
			<ol class="alg">
				<li>template&lt;class ${t}$&gt;</li>
				<li>${t}$* arr = new ${t}$[size];</li>
				<li>arr.length = 0;</li>
			</ol>
		</section>

		<section id="array_destructor">
			<h4>Sequence Destructor</h4>
			<p>
				Alongside the sequence's constructor, we also want a destructor.
				This serves as a way of cleaning up whatever memory we've allocated
				for our sequence.
			</p>
		</section>

		<section id="is_full">
			<h4>Full-capacity Tester</h4>
			<p>
				Given that arrays have a fixed size, our sequence ADT should also
				include a
				<b>capacity tester</b>. This returns <var>true</var> if we've
				reached the maximum possible size for the array, and
				<var>false</var> otherwise. We'll call this function
				<var>isFull()</var>.
			</p>
		</section>

		<section id="is_empty">
			<h4>Empty Tester</h4>
			<p>
				Similar to <var>isFull()</var>, it's also helpful to know if the
				array is empty. We'll call this function <var>isEmpty()</var>. The
				function returns <var>true</var> if the array is empty; otherwise
				<var>false</var>.
			</p>
		</section>

		<section id="get_size">
			<h4>Size Getter</h4>
			<p>
				Related to the full-capacity tester, we'll want a function that
				returns the size of the array. Note that this is separate from the
				<i>length</i> property, discussed below. We'll call size getter
				<var>sizeOf()</var>. This will return the <i>maximum size</i> of
				the array.
			</p>
		</section>

		<section id="get_length">
			<h4>Length Getter</h4>
			<p>
				The length of an array is distinguised from its size. In this case,
				an array's <i>length</i> corresponds to the current number of
				elements in the array. In these materials, <var>size</var> does not
				always equal <var>length</var>. To illustrate, an array of
				<var>size = 4</var> results in the following:
			</p>
			<div id="length_getter_1"></div>
			<p>
				This array has a size of four, but a length of ${0}$ &mdash; there
				are no elements in the array. If, however, we initialized some of
				the spaces:
			</p>
			<div id="length_getter_2"></div>
			<p>
				Now we have an array of size ${4}$ with a length of ${3.}$ The size
				of an array is static, but the length may increase or decrease.
			</p>
		</section>

		<section id="print_an_array">
			<h4>Print</h4>
			<p>
				First, the <var>print()</var> operation. To print a sequence, we
				must iterate over each of the sequence's element, displaying each
				element to the console (i.e., with something lik <var>cout</var> or
				<var>printf</var>). Because we're iterating over each element, the
				<var>print()</var> operation has a time complexity of ${O(n)}$
				given the ${n-}$sequence. This is linear time.
			</p>
		</section>

		<section id="appending_an_element">
			<h4>Appending</h4>
			<p>
				Second, the
				<var>append(${x}$)</var> operation, where ${x}$ is an element. To
				append an element ${x,}$ we insert the element ${x}$ at the very
				end of the sequence. In other words, &#8220;Insert this element
				${x}$ at the first instance of free space.&#8221; Thus, given an
				array of length 10 and size 5, <var>append(${x}$)</var> inserts the
				element ${x}$ at ${i = 6.}$ For <var>append(${x}$)</var>, we can
				think of this as performing three distinct operations &mdash;
				accessing the array at ${i = \textit{length},}$ assigning the
				element ${x}$ to that particular index, and updating the
				${\textit{length}}$ property. Hence, ${O(3).}$ Applying complexity
				analysis, this is really ${f(n) = 3.}$ Rewriting this as ${f(n) =
				3n^0,}$ we have ${O(n^0),}$ which reduces to ${O(1).}$ I.e.,
				constant time.
			</p>
		</section>

		<section id="inserting_an_element">
			<h4>Inserting</h4>
			<p>
				With the
				<var>insert(${i}$, ${x}$)</var> operation, we're inserting an
				element ${x}$ at the index ${i.}$ For example, suppose we have the
				sequence ${(0, 1, 2, 3, 4, \_, \_, \_).}$ This is a sequence of
				size 8, with length 5. If we write <var>insert(${2}$, ${9}$)</var>,
				we would have the sequence ${(0, 9, 1, 2, 3, 4, \_, \_).}$ Notice
				that this causes a shift. To perform this shift, have to use a
				loop. In pseudocode:
			</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
            insert(index, x) {
              for (i = length; i > index, i--) {
                A[i] = A[i - 1];
              }
              A[index] = x;
              length++;
            }
          </code></pre>
				</div>
			</figure>
			<p>
				The operation of inserting an element into a sequence provides an
				opportunity to examine the different forms of complexity analysis.
				If we insert the element at the very end of the sequence &mdash;
				<var>insert(${length}$, ${x}$)</var> &mdash; no shifting occurs.
				Accordingly, this operation has a time complexity of order
				${O(1),}$ constant time. However, if we insert the element at the
				very beginning &mdash; <var>insert(${0}$, ${x}$)</var> &mdash; then
				we must shift <span class="underlineText">all</span> the elements.
				Given a sequence of length ${n,}$ this operation would require
				iterating over all ${n}$ elements. This operation's time complexity
				is of order ${O(n).}$
			</p>
			<p>
				Examining these possibilities, we have a best-case scenario and a
				worst-case scenario. The best-case scenario is ${\Omega(1),}$
				constant time, which occurs only if we insert at the very end. The
				worst-case scenario is ${O(n),}$ linear time, which occurs if we
				insert at the origin, ${i = 0.}$
			</p>
		</section>

		<section id="deleting_an_element">
			<h4>Deletion</h4>
			<p>
				The operation
				<var>deleteElementAt(${i}$)</var> deletes, or removes, an element
				at the index ${i.}$ Suppose we have the array ${(1, 5, 8, 3, 2, \_,
				\_, \_).}$ In this example, there are three cases for deletion:
				<var>deleteElementAt(${0}$)</var>,
				<var>deleteElementAt(${\textit{length}}$)</var>, and
				<var>deleteElementAt(${n}$)</var>, where ${0 < n <
				\textit{length}.}$ The two problematic cases are the first and the
				third. They are problematic because if we delete an element other
				than the last, then we would have gaps in the array:
			</p>
			<figure class="math-display">
				<div>
					<p>
						<var>deleteElementAt(0)</var> ${ \implies (\_, 5, 8, 3, 2, \_,
						\_, \_)}$
					</p>
					<p>
						<var>deleteElementAt(3)</var> ${ \implies (0, 5, 8, \_, 2, \_,
						\_, \_)}$
					</p>
				</div>
			</figure>
			<p>
				These gaps lead to all sorts of problems, particularly with respect
				to iteration. One way to avoid these problems is to manually check
				if a given index has an element. This is not a good approach. The
				better approach is to get right to the root of the problem &mdash;
				&#8220;holes&#8221; in the array. We can prevent these holes by
				shifting elements to the right whenever one of the two cases above
				occurs. Thus:
			</p>
			<figure class="math-display">
				<div>
					<p>
						<var>deleteElementAt(3)</var> ${ \implies (0, 5, 8, \_, 2, \_,
						\_, \_) \implies (0, 5, 8, 2, \_, \_, \_, \_)}$
					</p>
				</div>
			</figure>
			<p>
				To understand how to perform this shifting, we consider the example
				<var>deleteElementAt(3)</var>. Here, ${i = 3.}$ So, we start by
				removing the element at ${i = 3,}$ then shift the element at ${i +
				1}$ to ${i = 3.}$ This creates a hole at ${i = 4,}$ so we set ${i =
				4,}$ then shift the element at ${i + 1}$ to ${i = 4.}$ This creates
				a hole at ${i = 5,}$ so we shift the element at ${i + 1}$ to ${i =
				6,}$ and so on, up until we reach the value of ${i =
				\textit{length} - 1}$ (the second to last element). In pseudocode:
			</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
            deleteElementAt(index):
              element = A[index];
              for (i = index; i < array.length - 1; i++):
                A[i] = A[i + 1];
              length--;
          </code></pre>
				</div>
			</figure>
			<p>
				The time complexity for this algorithm depends on the value of
				<var>index</var>. If <var>index = length</var>, then no shifting
				occurs, in which case we only have to perform two operations:
				Initializing <var>element</var> and decrementing <var>length</var>.
				This yields a complexity of ${O(2),}$ or simply ${O(1)}$ &mdash;
				constant time.
			</p>
			<p>
				If, however, <var>index = 0</var>, then we have to perform ${n}$
				shifts. This yields ${O(n + 2),}$ or ${O(n).}$ This is linear time.
				Accordingly, deleting an element from a array, in the best case
				scenario, is ${\Omega(1),}$ and in the worst case scenario,
				${O(n).}$
			</p>
		</section>

		<p>
			Putting all of the properties above together, we have the following
			class in pseudocode:
		</p>

		<ol class="alg">
			<li>class Array:</li>
			<ol>
				<li>private:</li>
				<ol>
					<li>int *array;</li>
					<li>int size;</li>
					<li>int length;</li>
				</ol>
				<li>public:</li>
				<ol>
					<li>Array(int arraySize = 10)</li>
					<li>~Array()</li>
					<li>bool isFull();</li>
					<li>bool isEmpty();</li>
					<li>int sizeOf();</li>
					<li>int length();</li>
					<li>void append();</li>
					<li>void insertAt();</li>
					<li>void deleteAt();</li>
				</ol>
			</ol>
		</ol>

		<div class="demo">
			<button>C++</button>
			<div class="implementation">
				<p>Here is an implementation of the classes above:</p>
				<pre class="language-c"><code>
          #include &lt;iostream&gt;

          class Array {
            int *array;
            int size;
            int arrayLength;
            public:
              Array(int arraySize = 10);
              ~Array();
              bool isFull();
              bool isEmpty();
              int sizeOf();
              int length();
              void append(int e);
              void insert(int val, int index);
              void deleteElementAt(int index);
              void print();
          };
          
          Array :: Array(int arraySize) {
            size = arraySize;
            array = new int[arraySize];
            arrayLength = 0;
          }
          
          Array :: ~Array() {
            delete [] array;
          }
          
          bool Array :: isFull() {
            if (arrayLength == size - 1) {
              return true;
            } else {
              return false;
            }
          }
          
          bool Array :: isEmpty() {
            if (arrayLength == 0) {
              return true;
            } else {
              return false;
            }
          }
          
          int Array :: sizeOf() {
            return size;
          }
          
          int Array :: length() {
            return arrayLength;
          }
          
          void Array :: append(int e) {
            if (!isFull()) {
              array[arrayLength] = e;
              arrayLength++;
            } else {
              std::cout << "Array is full.\n";
            }
          }
          
          void Array :: insert(int val, int index) {
            if (index < size) {
              for (int i = arrayLength; i > index;) {
                array[i] = array[i - 1];
              }
              array[index] = val;
              arrayLength++;
            } else {
              std::cout << "Invalid index.\n";
            }
          }
          
          void Array :: deleteElementAt(int index) {
            for (int i = index; i < arrayLength - 1; i++) {
              array[i] = array[i+1];
            }
            arrayLength--;
          }
          
          void Array :: print() {
            std::cout << "[ ";
            for (int i = 0; i < arrayLength; i++) {
              std::cout << array[i] << " ";
            }
            std::cout << "]\n";
          }
          
          int main() {
            Array arr = Array(5);
            for (int i = 0; i < 4; i++) {
              arr.append(i);
            }
            arr.print();
            arr.deleteElementAt(2);
            arr.print();
            return 0;
          }
        </code></pre>
			</div>
		</div>
	</section>

	<section id="getting">
		<p>
			<span class="topic">Accessing an Array Element.</span> In the API
			above, we specified an operation called <var>get(${i}$)</var>, where
			${i}$ is an index. This operation returns the array's element at
			index ${i.}$
		</p>
		<p>
			Really, there are only two operations we must perform for
			<var>get(${i}$)</var>: First, we must ensure the index argument ${i}$
			is an integer not less than 0. It wouldn't make sense to pass an
			${i}$ of 2.178 or an ${i}$ of -1. Second, we must ensure the index is
			less than <var>length</var>. If the ${i > \texttt{length},}$ then we
			risk (a) getting some garbage value or (b) receiving an out-of-bounds
			error. The implementation:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
          get(int index) {
            if ( (index >= 0) ∧ (index < length) ) {
              ⟹ return A[index];
            } 
          }
        </code></pre>
			</div>
		</figure>
		<p>
			Because only two operations are required for
			<var>get(${i}$)</var>, the <var>get(${i}$)</var> operator has a time
			complexity of ${O(1)}$ &mdash; constant time.
		</p>
	</section>

	<section id="setting">
		<p>
			<span class="topic">Replacing an Array Element.</span> The
			<var>set(${x}$, ${i}$)</var> operation will set the element ${x}$ and
			the index ${i.}$ Effectively, this will replace the element ${y}$
			occupying the index ${i.}$ Like the <var>get(${i}$)</var> operator,
			we must ensure that the index passed is an integer and that ${i <
			\texttt{length}.}$ In pseudocode:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
          get(int x, int index) {
            if ( (index >= 0) ∧ (index < length) ) {
              ⟹ A[index] = x;
            } 
          }
        </code></pre>
			</div>
		</figure>
		<p>
			Once more, because there are really only two operations performed
			(ensuring the requirements are met and assignment), replacing an
			element in an array has running time of ${O(1)}$ &mdash; constant
			time.
		</p>
	</section>
</section>

<section id="searching_an_array">
	<h2>Searching an Array</h2>
	<p>
		Searching for a particular element ${x}$ in a array depends on the
		search algorithm employed. There are two algorithms available: (1)
		<i>linear search</i> and (2) <i>binary search</i>. We consider linear
		search first.
	</p>

	<section id="linear_search">
		<h3>Linear Search</h3>
		<p>
			Under
			<span class="term">linear search</span>, we iterate over each of the
			array's elements, checking if the element matches our query. Say we
			had the following array:
		</p>
		<figure class="math-display">
			<div>
				<p>${A = (8, 9, 4, 7, 6, 5, 10, 2, 11)}$</p>
			</div>
		</figure>
		<p>
			With the linear search approach, we go through each of the elements
			of ${A,}$ checking if the element matches the key. Suppose the key is
			the integer ${5.}$ We start with ${A[0],}$ and ask, &#8220;${A[0] =
			5?}$&#8221; False. So we continue to ${A[1].}$ Again we ask,
			&#8220;${A[1] = 5?}$&#8221; False again. So we go to ${A[2].}$ We
			continue all the way up to ${A[5],}$ wherein ${A[5] = 5}$ is true.
			Because our key was found, we say that the search was
			<i>successful.</i>
		</p>
		<p>
			Now, what if the key was the integer ${22?}$ In that case, we go all
			the way up to ${A[\textit{length}],}$ or ${A[8],}$ to determine that
			${22}$ is not in the array. This is an example of an
			<i>unsuccessful search</i>.
		</p>
		<p>
			Implementing linear search is straightforward. We are simply
			traversing the array. We start with ${A[0],}$ then continue to the
			last element of the list, ${A[\textit{length}].}$
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
        arrayLinearSearch(x) {
          for (i = 0; i < length; i++) {
            if (key == A[i]){
              return i;
            }
          }
          return -1;
        }
      </code></pre>
			</div>
		</figure>
		<p>
			What is the time complexity for linear search? Well, in the
			worst-case scenario, the array does not contain our key. In which
			case we would have to perform the comparison operation
			<var>key == A[i]</var> on all the array's elements. Thus, given an
			${n-}$array not containing our key, we have time complexity of order
			${O(n).}$ This is linear time.
		</p>
		<p>
			In the best-case scenario, ${A[0]}$ is our key, in which case only
			one comparision operation is performed. Accordingly, in the best-case
			scenario, linear search has a time complexity of order ${\Omega(1)}$
			&mdash; constant time.
		</p>
		<p>
			What about the average-case scenario? To determine the average-case
			scenario, we ask, how many comparisons are needed to determine
			whether ${i = 1}$ matches our key? We must perform 1 comparison. We
			again ask, how many comparisons are needed to determine whether the
			element at ${i = 2}$ matches our key? We must perform 2 comparisons.
			We ask the same question for ${i = 3,}$ ${i = 4,}$ ${i = 5,}$ and so
			on. The sum of comparisons is the sum of arithmetic sequence of the
			positive integers:
		</p>
		<figure class="math-display">
			<div>
				<p>${1 + 2 + 3 + \ldots + n = \dfrac{n(n + 1)}{2}}$</p>
			</div>
		</figure>
		<p>
			Thus, the total amount of time for all possible cases is
			${\dfrac{n(n+1)}{2}.}$ Dividing this by the total number of cases,
			${n,}$ provides us with the average case:
		</p>
		<figure class="math-display">
			<div>
				$$ \begin{aligned} \dfrac{ \dfrac{n(n + 1)}{2} }{n} &= \dfrac{
				\dfrac{\cancel{n}(n + 1)}{2} }{\cancel{n}} \\[1.2em] &= \dfrac{n +
				1}{2} \end{aligned} $$
			</div>
		</figure>
		<p>
			Hence, in the average-case scenario, linear search has a complexity
			of ${\Theta\left(\dfrac{n+1}{2}\right).}$ Or, asymptotically,
			${\Theta(n).}$ Notice that both the average-case runtime and the
			worst-case runtime are the same. With linear search, we're almost
			always running on linear time. We can, however, optimize the linear
			search algorithm.
		</p>
		<p>
			<span class="topic">Transposition.</span> The first method to
			improving linear search is with
			<span class="term">transposition</span>. The idea behind
			transposition is best understood via analogy. Suppose you're
			conducting research, and you know there's a particular book relevant
			to a topic. You proceed to the shelf and retrieve the book. Instead
			of returning the book to the original place, you might leave the book
			on a particular table, or place it somewhere closer to your work
			space. Why? Because there's a high likelihood of you needing to use
			the same book again.
		</p>
		<p>
			This same idea extends to linear search. In search for some key
			${k,}$ there's a likelihood of searching for ${k}$ again, so we bring
			it closer to ${i = 0.}$ For example, say we have the array:
		</p>
		<figure class="math-display">
			<div>
				<p>${T = (8, 9, 4, 6, 7, 3, 2, 11)}$</p>
			</div>
		</figure>
		<p>
			and our key is ${6.}$ A linear search for 6 returns a successful
			search, so we swap 6 and 4 (swap ${T[3]}$ and ${T[2]}$):
		</p>
		<figure class="math-display">
			<div>
				<p>${T = (8, 9, 6, 4, 7, 3, 2, 11)}$</p>
			</div>
		</figure>
		<p>Search for 3 again, and we swap ${T[1]}$ and ${T[2]}$:</p>
		<figure class="math-display">
			<div>
				<p>${T = (8, 6, 9, 4, 7, 3, 2, 11)}$</p>
			</div>
		</figure>
		<p>Search 3 one more time, and we swap ${T[1]}$ and ${T[0]}$:</p>
		<figure class="math-display">
			<div>
				<p>${T = (6, 8, 9, 4, 7, 3, 2, 11)}$</p>
			</div>
		</figure>
		<p>
			Notice that 6 is now at the head of the array. Now whenever we search
			for ${6,}$ we have a runtime of ${O(1)}$ &mdash; constant time. Of
			course, 6 will only get to the array's head if we search for it
			enough times.
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
        arrayLinearSearch(x) {
          for (i = 0; i < length; i++) {
            if (key == T[i]){
              swap(T[i], T[i-1])
              return i - 1;
            }
          }
          return -1;
        }
      </code></pre>
			</div>
		</figure>
		<p>
			<span class="topic">Move-to-head.</span> With transposition, we do
			not reach ${O(1)}$ unless we search for the key ${k}$ ${n}$ times,
			where ${n}$ is the index of ${k.}$ This means that the key ${k}$ can
			take a fair amount of time to get to the list's head. Moreover, if
			${k}$ is not searched, it slowly moves towards the tail-end. To get
			to the head faster, we can use the
			<span class="term">move-to-head</span> approach. With move-to-head,
			after a successful search, we immediately place the key at ${i = 0.}$
		</p>
		<figure class="math-display">
			<div>
				<ol class="numd">
					<li>${T = (8, 9, 4, 6, 7, 3, 2, 11)}$</li>
					<li><var>arrayLinearSearch${(6)}$</var></li>
					<li>${T = (6, 9, 4, 8, 7, 3, 2, 11)}$</li>
				</ol>
			</div>
		</figure>
		<p>In pseudocode:</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
          arrayLinearSearch(x) {
            for (i = 0; i < length; i++) {
              if (key == T[i]){
                swap(T[i], T[0])
                return 0;
              }
            }
            return -1;
          }
        </code></pre>
			</div>
		</figure>
	</section>

	<section id="binary_search">
		<h3>Binary Search</h3>
		<p>
			The <span class="term">binary search</span> algorithm is correct only
			if the array is <span class="underlineText">sorted</span>. There are
			a whole host of sorting algorithms, so we will cover them in a
			separate section. For now, suppose we have the following sorted
			array:
		</p>
		<div id="binary_search_1"></div>
		<p>
			Suppose our key is ${k = 18.}$ We see that 18 is at index ${i = 4.}$
			With linear search, we must perform 5 comparisions before ${k}$ is
			found. Let's see how binary search compares.
		</p>
		<p>
			First, with binary search, we need three variables: ${\ell,}$ ${h,}$
			and ${M.}$ These variables represent three variants: ${\ell}$
			represents the lower bound (an index), ${h}$ represents the upper
			bound (also an index), and ${M}$ represents the index exactly between
			${\ell}$ and ${h.}$ Accordingly, the value of ${M}$ is given by:
		</p>
		<figure class="math-display">
			<div>
				<p>${M = \lfloor \dfrac{\ell + h}{2} \rfloor}$</p>
			</div>
		</figure>
		<p>
			This simply the arithmetic mean, but we will floor the result to
			account for the possibility of an odd number of elements in the
			array. For example, if the array has 5 elements, then ${\ell = 0,}$
			and ${h = 5.}$ Calculating ${M:}$ ${(0 + 5) / 2 = 2.5.}$ Obviously an
			index cannot be ${2.5,}$ so we floor the result: ${M \equiv i = 2.}$
		</p>
		<p>
			That said, let's trace our program. We know ${k = 18.}$ So, we first
			initialize ${\ell}$ and ${h:}$
		</p>
		<figure class="math-display">
			<div>
				<p>${\ell = 0}$</p>
				<p>${h = 14}$</p>
			</div>
		</figure>
		<p>Then we compute ${M:}$</p>
		<figure class="math-display">
			<div>
				<p>${M = \dfrac{0 + 14}{2} = 7}$</p>
			</div>
		</figure>
		<p>
			Thus, ${M}$ is ${i = 7.}$ We then ask, is ${T[7] = k?}$ If yes, the
			search is successful, and we return the index 7. Otherwise, we ask,
			is ${T[7] < k}$ or is ${T[7] > k?}$ Here, ${T[7] < k.}$ Because
			${T[7] < k,}$ ${k}$ must be on the left-hand side of the array. I.e.,
			${\ell \leq k < M.}$ Why can we conclude this? Because the array
			${T}$ is sorted. If ${T[7] > k,}$ then ${k}$ must be on the
			right-hand side (${M < k \leq h}$).
		</p>
		<p>
			In this case, since ${T[7] < k,}$ ${\ell}$ remains as ${i = 0,}$ but
			we change ${h}$ to ${i = 6.}$ Now we're working the left-hand side,
			which is ${T[0] < k \leq T[6].}$ Now we have a new mean: ${(0 + 6) /
			2 = 3.}$ Thus, now the middle element is ${T[3] = 15.}$ We again ask,
			is ${k = T[3]?}$ No. Is ${k < T[3]}$ or is ${k > T[3]?}$ Here, ${18 >
			15,}$ so we're looking at the right-hand side of the array.
		</p>
		<p>
			Because ${T[M] > k,}$ we again change the lower bounds and upper
			bounds. ${\ell = 4,}$ and ${h = 4.}$ The mean is now ${M = (4 + 4) /
			2 = 4.}$ Thus, the middle element is now ${T[4] = 18.}$ We now ask,
			is ${k = T[4]?}$ Yes. We have found our key. Notice that we found our
			key in a total of 4 comparisons, compared to 5 comparisons with
			linear search.
		</p>
		<p>
			Let's try another key. ${k = 34.}$ We set the upper bounds and lower
			bounds. ${\ell = 0}$ and ${h = 14.}$ Then we compute the mean index.
			${(0 + 14) / 2 = 7.}$ Again we have ${T[7] = 27.}$ Is ${T[M] = k?}$
			No. Is ${T[M] > k}$ or is ${T[M] < k?}$ ${27 < 34.}$ Thus, we're now
			restricting our search to the right-hand side.
		</p>
		<p>
			We change the upper and lower bounds. ${\ell = M + 1 = 7 + 1 = 8.}$
			And ${h = 14.}$ Then compute the mean index: ${(8 + 14) / 2 = 11.}$
			Thus, the middle element is ${T[M] = T[11] = 37.}$ Is ${T[M] = k?}$
			No. Is ${T[M] > k}$ or ${T[M] < k?}$ ${37 > 34,}$ so we're looking at
			the left-hand side.
		</p>
		<p>
			We again change the upper and lower bounds. ${\ell = 8}$ and ${h = 11
			- 1 = 10.}$ Computing the mean: ${(10 + 8) / 2 = 9.}$ Is ${(T[9] =
			33) = 34?}$ No. Is ${33 > 34}$ or is ${33 < 34?}$ ${34}$ is less than
			${33.}$ So, the number is on the right-hand side. Once more we modify
			the upper and lower bounds.
		</p>
		<p>
			${\ell = M + 1 = 9 + 1 = 10,}$ and ${h = 10.}$ We compute the mean:
			${(10 + 10) / 2 = 10.}$ Is ${T[10] = 34?}$ Yes. We've found our key
			in 4 comparisons. Compare that with linear search, which would have
			taken 10 comparisions.
		</p>
		<p>
			Let's try another key, ${k = 25.}$ Set the upper and lower bounds:
			${\ell = 0}$ and ${h = 14.}$ Compute the mean: ${M = (0 + 14) = 7.}$
			Compare ${T[7]}$ to ${k.}$ ${k}$ is not equal to ${T[7].}$ ${k <
			T[M],}$ so we're looking at the left-hand side.
		</p>
		<p>
			Change the upper and lower bounds. ${\ell = 0,}$ and ${h = 7 - 1 =
			6.}$ Compute the mean: ${M = (0 + 6)/2 = 3.}$ ${T[3]}$ is not equal
			to ${k.}$ Because ${k > T[M],}$ we're looking at the right-hand side.
			So we change the upper and lower bounds.
		</p>
		<p>
			${\ell = 3 + 1 = 4,}$ and ${h = 6.}$ We compute the mean: ${(4 + 6) /
			2 = 5.}$ The middle element is ${T[5].}$ ${T[5]}$ is not equal to
			${25,}$ ${k > T[5].}$ So again we're looking at the left-hand side.
			Once more we modify the lower and upper bounds.
		</p>
		<p>
			${\ell = 5 + 1 = 6,}$ and ${h = 6.}$ The mean: ${(6 + 6) / 2 = 6.}$
			${T[6]}$ is not equal to ${25.}$ ${25 > T[6],}$ so we modify the
			upper and lower bounds.
		</p>
		<p>
			${\ell = 6 + 1 = 7,}$ and ${h = 6.}$ This is where we stop. The
			moment ${\ell > h,}$ we've arrived at an unsuccessful search, so we
			return ${-1.}$ Notice that it took 4 comparisons to reach an
			unsuccessful search, compared to the 15 comparisions it would've
			taken with linear search.
		</p>
		<p>Implementing binay search in pseudocode:</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
          BinarySearch(k, low, high) {
            while (low <= high) {
              middle = floor((low + high) / 2);
              if (k == T[mean]) {
                return mean;
              }
              else if (k < T[mean]) {
                high = mean - 1;
              }
              else {
                low = mean + 1;
              }
            }
            return -1;
          }
        </code></pre>
			</div>
		</figure>
		<p>
			Alternatively, we can implement the binary search algorithm with tail
			recursion:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
          BinarySearch(k, low, high) {
            if (low <= high) {
              mean = floor((low + high) / 2);
              if (k == T[mean]) {
                return mean;
              }
              else if (key < T[mean]) {
                return BinarySearch(low, mean - 1, key);
              }
              else {
                return BinarySearch(mean + 1, high, key);
              }
            }
            return -1;
          }
        </code></pre>
			</div>
		</figure>
		<p>
			To understand the time complexity for binary search, the crucial
			point is that we're cutting the array in half each time. However,
			before any of that splitting, we checked if the middle element is in
			fact the key. Accordingly, in the best-case scenario, binary search
			has a time complexity of ${\Omega(1)}$ &mdash; constant time.
		</p>
		<p>
			However, if the middle element was not the key, then we proceed to
			checking if the left- or right-hand side contained the key. Suppose
			it's the left-hand side. If it's the left-hand side, then ${\ell =
			0}$ and ${h = 6,}$ yielding ${M = 3.}$ If it's on the right-hand
			side, then ${\ell = 8}$ and ${h = 14,}$ yielding ${M = 11.}$ This is
			halving the array and restricting our search to just the relevant
			half. If the middle element in either half is the key, then we've
			found our key in 2 comparisons.
		</p>
		<p>
			If neither of the halves contains the middle element, then we again
			perform the split. For the left-hand side of the left-hand side,
			${\ell = 0}$ and ${h = 2,}$ yielding ${M = 1.}$ If it's the
			right-hand side of the left-hand side, then ${\ell = 4}$ and ${h =
			6,}$ yielding ${M = 5.}$ For the left-hand side of the right-hand
			side, we have ${\ell = 8}$ and ${h = 10,}$ yielding ${M = 9.}$ For
			the right-hand side of the right-hand side, we have ${\ell = 12}$ and
			${h = 14,}$ yielding ${M = 13.}$ In this case, the key can be found
			in 3 comparisons. Visualizing the tree:
		</p>
		<figure>
			<img
				src="{% static 'images/binary_search_tree.svg' %}"
				alt="The binary search tree's middle element computations"
				loading="lazy"
			/>
		</figure>
		<p>
			Splitting further, the key can be found in 4 comparisions, then 5,
			then 6, and so on. Modelling binary search as a tree, the height of
			the tree is ${\lceil\log_{2}(n + 1)\rceil,}$ where ${n}$ is the
			number of elements in the array. Why ${\log_{2}(n + 1)?}$ Because the
			tree's height is directly proportional to the number of times we
			divide ${n}$ by 2 such that we only have a remainder of 1. And as we
			know from mathematics, the answer to &#8220;How many times can I
			divide ${n}$ by 2 to reach a remainder of 1?&#8221; is a logarithm of
			base 2. Successive multiplication yields a power, and successive
			division yields a logarithm. Thus, in terms of asymptotic analysis,
			the binary search algorithm has a runtime of order ${O(\lg n)}$
			&mdash; logarithmic time.
		</p>
		<p>
			What about the average-case? For the average-case, we're asking for
			the total time for all the possible cases, divided by the number of
			cases. Revisiting the tree diagram above, we see that at the first
			level, there is only 1 case, with only 1 comparison. Let ${c}$ be the
			number of cases:
		</p>
		<figure class="math-display">
			<div>
				<p>${c = 1}$</p>
			</div>
		</figure>
		<p>
			On the second level, there are 2 cases, each requiring 1 comparison:
		</p>
		<figure class="math-display">
			<div>
				<p>${c = 1 + (1 \cdot 2)}$</p>
			</div>
		</figure>
		<p>
			On the third level, there are 4 cases, each requiring 2 comparisons:
		</p>
		<figure class="math-display">
			<div>
				<p>${c = 1 + (1 \cdot 2) + (2 \cdot 4)}$</p>
			</div>
		</figure>
		<p>
			On the fourth level, there are 8 cases, each requiring 3 comparisons:
		</p>
		<figure class="math-display">
			<div>
				<p>${c = 1 + (1 \cdot 2) + (2 \cdot 4) + (3 \cdot 8)}$</p>
			</div>
		</figure>
		<p>We can see pattern in this series:</p>
		<figure class="math-display">
			<div>
				<p>${c = 1 + (1 \cdot 2^1) + (2 \cdot 2^2) + (3 \cdot 2^3)}$</p>
			</div>
		</figure>
		<p>We can then express this pattern as:</p>
		<figure class="math-display">
			<div>
				<p>${\sum\limits_{i = 1}^{3} i \cdot 2^i}$</p>
			</div>
		</figure>
		<p>
			That 3 is intresting &mdash; it's the tree's height. Accordingly, our
			series can be generalized as:
		</p>
		<figure class="math-display">
			<div>
				<p>
					${\sum\limits_{i = 1}^{\log n} i \cdot 2^i = \log n \cdot 2^{\log
					n}}$
				</p>
			</div>
		</figure>
		<p>
			But, we must divide this sum by ${n,}$ the number of elements (and by
			implication, the number of possible cases):
		</p>
		<figure class="math-display">
			<div>
				<p>${\dfrac{\log n \cdot 2^{\log n}}{n} = \log n}$</p>
			</div>
		</figure>
		<p>
			Hence, the average-case running time is ${\Theta(\log n)}$ An
			algorithm's average-case, however, may be different depending on the
			conditions. For example, with respect to binary search, there's an
			average-case running time for a successful search, and an
			average-case running time for an unsuccessful search.
		</p>
		<p>
			A successful search occurs if the element is found. In the tree
			diagram above, the number of possible cases for a successful search
			is equivalent to the number of internal nodes (i.e., all of the nodes
			other than the nodes on the fifth level). If we examine the tree
			closely, the number of edges from the root to a given node represents
			the number of comparisons needed to reach the given node. For
			example, to find the ${k = 8,}$ binary-search requires 3 comparisons.
			Accordingly, the number of comparisons to reach a given node
			containing ${k}$ is ${e + 1,}$ where ${e}$ is the number of edges
			leading to the node from the root (we add ${1}$ because a comparison
			must be performed for the root).
		</p>
		<p>
			The number of possible cases for an unsuccesful search, in contrast,
			is found from the number of nodes on the fifth level. These are
			called
			<span class="term">external nodes</span>. It is on these external
			nodes that binary search terminates. Like the successful search, the
			number of comparisons needed to reach an unsuccessful search is the
			number of edges leading to an external node plus 1.
		</p>
		<p>
			With these basic facts, suppose that ${I}$ represents the sum of all
			the paths leading to internal nodes and ${E}$ represents the sum of
			the paths leading to external nodes. It follows then that:
		</p>
		<figure class="math-display">
			<div>
				<p>${E = I + 2n,}$ where ${n}$ is the number of internal nodes</p>
			</div>
		</figure>
		<p>
			Why ${+ 2n?}$ Because each of the internal nodes have 2 children
			(since the binary search algorithm works by successively dividing the
			problem by 2). For example, here's a simple binary tree:
		</p>
		<figure>
			<img
				src="{% static 'images/internal_v_external_nodes.svg' %}"
				alt="Internal versus external nodes"
				loading="lazy"
				class="sixty-p"
			/>
		</figure>
		<p>
			Notice that ${n = 3.}$ Thus, ${2n = 6.}$ Then, notice that ${I = 2.}$
			Hence, ${E = 2 + 6 = 8.}$ Indeed, there are 8 paths from the root to
			the external nodes.
		</p>
		<p>
			Alongside the facts above, we also know that the number of external
			nodes is the number of internal does plus 1: ${e = n + 1,}$ where
			${e}$ is the number of external nodes, and ${n}$ is the number of
			internal nodes. Knowing all of this, the average-case runtime for a
			successful search on an ${n}$ element array is the sum of the paths
			to internal nodes divided by the number of nodes (the sum of all
			possible cases divided by the number of cases) plus 1 (including the
			comparison for the root node):
		</p>
		<figure class="math-display">
			<div class="rule">
				<p>
					${\Omega\left(1 + \dfrac{I}{n}\right)}$, where ${I}$ is the sum
					of all paths to internal nodes and ${n}$ is the number of nodes.
				</p>
			</div>
		</figure>
		<p>
			Similarly, the average-case runtime for an unsuccesful search is:
		</p>
		<figure class="math-display">
			<div class="rule">
				<p>
					${\Omega\left( \dfrac{E}{n + 1} \right),}$ where ${E}$ is the sum
					of all paths to external nodes and ${n}$ is the number of nodes
				</p>
			</div>
		</figure>
		<p>
			Note that the sum of all paths to external nodes is roughly the
			height of the tree &mdash; ${n \log n.}$ Accordingly we can
			generalize the average-case runtime for an unsuccessful search as:
		</p>
		<figure class="math-display">
			<div class="rule">
				<p>${\Omega\left( \dfrac{n \log n}{n + 1} \right)}$</p>
			</div>
		</figure>
		<p>Generalizing even further:</p>
		<figure class="math-display">
			<div class="rule">
				<p>${\Omega(\log n)}$</p>
			</div>
		</figure>
		<p>
			Using what we know about ${E,}$ we can use substitution to find a
			more generalized version of the average-case runtime for a successful
			search. Where ${A_s(n)}$ is the average-case runtime for a successful
			search:
		</p>
		<figure class="math-display">
			<div>
				$$ \begin{aligned} A_s(n) &= 1 + \dfrac{I}{n} \\[1em] &= 1 +
				\dfrac{E - 2n}{n} \\[1em] &= 1 + \dfrac{E}{n} - 2 \\[1em] &= 1 +
				\dfrac{n \log n}{n} - 2 \\[1em] &= 1 + \log n + 2 \end{aligned} $$
			</div>
		</figure>
		<p>
			Applying asymptotic analysis, the average-case runtime for a
			successful search is:
		</p>
		<figure class="math-display">
			<div>
				<p>${\Omega (\log n)}$</p>
			</div>
		</figure>
		<div class="demo">
			<button>Java</button>
			<div class="implementation">
				<p>Below is an implementation in Java.</p>
				<pre class="language-java"><code>
          public static int binarySearch(int[] a, int key) {
            int lo = 0;
            int hi = a.length - 1;
            while (lo <= hi) {
              int mid = lo + ((hi-lo) / 2);
              if (key &lt; a[mid]) hi = mid - 1;
              else if (key &gt; a[mid]) lo = mid + 1;
              else return mid;
            }
          }
        </code></pre>
			</div>
		</div>
	</section>
</section>

<section id="maximum">
	<h2>Maximum Finder</h2>
	<p>
		Finding the maximum element in a given array is an instance of a
		<span class="term">peak finding</span> problem. For example, suppose we
		had the following array:
	</p>
	<div id="max_finder_1"></div>
	<p>
		The <i>peak</i>, or <i>maximum</i>, in the array above is the element
		${15.}$ We will see in later sections that peak finding extends to many
		other problem domains. For now, we focus on the array data structure.
	</p>
	<p>
		How do we find the maximum element? It depends on whether the array's
		elements are sorted. Yet another example of why sorting algorithms are
		so important. For unsorted lists, we have no recourse other than to
		check each of the elements one by one. To do so, we first suppose that
		the maximum is the first element in the array &mdash; ${max = u_0 =
		8.}$ We then compare ${u_0}$ with ${u_1.}$ If ${u_1 > u_0,}$ then ${max
		= u_1.}$ Otherwise, we compare ${u_0}$ with ${u_2.}$ If ${max = u_1,}$
		then we compare ${u_1}$ with ${u_2.}$ If ${u_2 > u_1,}$ then ${max =
		u_2.}$ Otherwise, we compare ${u_2}$ with ${u_3.}$ We keep doing so
		until we reach the very last element. In pseudocode:
	</p>
	<figure class="math-display">
		<div>
			<pre class="language-pseudo"><code>
        max() {
          max = u[0];
          for (int i = 1; i < length; i++) {
            if (u[i] > max) {
              max = u[i];
            }
          }
          return max;
        }
      </code></pre>
		</div>
	</figure>
	<p>
		With this approach, we're effectively performing an instance of a
		linear search. We must traverse the entire array, checking each element
		(starting with the second element) all the way up to the last. Counting
		the number of operations, we have:
	</p>
	<figure class="math-display">
		<div>
			<pre class="language-pseudo"><code>
        max() {
          max = u[0]; <span class="redText">&larr; 1 operation</span>
          for (int i = 1; i < length; i++) { <span class="redText">&larr; n operations</span>
            if (u[i] > max) { <span class="redText">&larr; n - 1 operations</span>
              max = u[i];
            }
          }
          return max; <span class="redText">&larr; 1 operation</span>
        }
      </code></pre>
		</div>
	</figure>
	<p>
		Thus, there are a total of ${1 + 1 + n + (n - 1)}$ operations, or ${2n
		+ 1.}$ Accordingly, because the time function is ${f(n) = 2n + 1,}$ the
		above approach has a time complexity of ${O(n)}$ &mdash; linear time.
	</p>
	<p>
		On the other hand, if the list is sorted, then the last element is the
		maximum.
	</p>
</section>

<section id="finding_minimum">
	<h2>Minimum Finder</h2>
	<p>
		The
		<var>min()</var> operator returns the minimum element in the array.
		Finding a minimum is an instance of a
		<span class="term">valley-finding problem</span>. We can think of it as
		the inverse of finding a maximum. Like peak-finding, how efficiently we
		can find a minimum depends on whether the array's elements are sorted.
		If the elements are unsorted, then we have no recourse other than to
		use a linear search approach.
	</p>
	<p>Suppose we had the same array from the previous section:</p>
	<div id="min_finder_1"></div>
	<p>
		The valley here is the element ${u_7 = 2.}$ To find this element, we
		start by assuming the first element, ${u_0,}$ is the minimum. We then
		check if ${u_1 < u_0.}$ If it is, then the minimum is ${u_1,}$ and we
		compare that to ${u_2.}$ If it isn't, then the minimum remains ${u_0,}$
		and we compare it against ${u_2.}$ We repeat this process all the way
		up to the last element. In pseudocode:
	</p>
	<ol class="alg">
		<li>min():</li>
		<ol>
			<li>min = u[0] ${\text{1 operation}}$</li>
			<li>for (i = 1; i < length; i++): ${n \text{ operations} }$</li>
			<ol>
				<li>if (u[i] < min): ${n - 1 \text{ operations}}$</li>
				<ol>
					<li>min = u[i]</li>
				</ol>
			</ol>
			<li>return min ${\text{1 operation}}$</li>
		</ol>
	</ol>

	<p>
		Examining the operation count above, we again see that the running time
		function is ${f(n) = 1 + n + (n - 1) + 1 = 2n + 1.}$ Accordingly, this
		approach also has a time complexity of ${O(n)}$ &mdash; linear time.
	</p>
</section>

<section id="summing_elements">
	<h2>Summing Elements</h2>
	<p>
		The
		<var>sum()</var> operator will return the sum of all the elements in
		the array. Summing the elements of an array requires traversing the
		entire element, adding each element to some variable ${t}$ representing
		the sum. In pseudocode:
	</p>

	<ol class="alg">
		<li>sum():</li>
		<ol>
			<li>total = 0; ${\text{1 operation}}$</li>
			<li>for (i = 0; i < length; i++): ${n + 1 \text{ operations}}$</li>
			<ol>
				<li>total += array[i] ${n \text{ operations}}$</li>
			</ol>
		</ol>
		<li>return total ${\text{1 operation}}$</li>
	</ol>

	<p>
		From the operation count above, we see that this approach has a running
		time function of ${f(n) = 2n + 3.}$ Accordingly, this algorithm has a
		time complexity of ${O(n),}$ which is linear time.
	</p>
	<p>Alternatively, we can apply a recursive implementation:</p>

	<ol class="alg">
		<li>sum(array):</li>
		<ol>
			<li>if (array.length - 1 > 0):</li>
			<ol>
				<li>return 0;</li>
			</ol>
			<li>else:</li>
			<ol>
				<li>return sum(A, array.length - 1) + A[array.length]</li>
			</ol>
		</ol>
	</ol>

	<p>
		The recursive implementation also has a time complexity of ${O(n).}$
		The difference, however, is that each recursive call will result in a
		new stack generation, leading to a space complexity of ${O(n).}$ This
		is in contrast to the iterative approach, which has a space complexity
		of ${O(1).}$
	</p>
</section>

<section id="averaging">
	<h2>Arithmetic Mean</h2>
	<p>
		A useful operator to have when working with arrays is returning the
		<i>arithmetic mean</i>. This is done with the
		<var>ArithmeticMean()</var> operator. The implementation is
		straightforward. We simply compute the sum of all the elements, and
		divide it by the number of elements.
	</p>

	<ol class="alg">
		<li>average():</li>
		<ol>
			<li>total = 0; ${\text{1 operation}}$</li>
			<li>for (i = 0; i < length; i++): ${n + 1 \text{ operations}}$</li>
			<ol>
				<li>total += array[i] ${n \text{ operations}}$</li>
			</ol>
		</ol>
		<li>return total / length ${\text{2 operations}}$</li>
	</ol>

	<p>
		As we can see, the time complexity is no different, save for the extra
		operation in the last line of dividing by the length. Accordingly, this
		approach has a time complexity of ${O(n)}$ &mdash; linear time.
	</p>
</section>

<section id="reversing">
	<h2>Reversing the Elements of an Array</h2>
	<p>
		The
		<var>reverse()</var> operator performs exactly what it sounds like: It
		reverses all the original elements of the array. For example, given the
		array:
	</p>
	<div id="reverse_array_elements1"></div>
	<p><var>reverse()</var> returns the array:</p>
	<div id="reversed_array_elements1"></div>
	<p>
		To reverse an array, there are two methods we can use: (1)
		<i>reversing in place</i> and (2) using an <i>auxiliary array</i>. We
		first consider the latter.
	</p>

	<section id="auxiliary_array">
		<p>
			<span class="topic">Reversing with an Auxiliary Array.</span> With
			the auxiliary array approach, we use an additional array to place the
			reversed elements. The idea is straightforward: We start at the last
			element of the array and traverse to the first element, copying each
			element to the auxiliary array. After copying all of the elements
			into the auxiliary array, we then replace the corresponding elements
			in the original array with the elements in the auxiliary array.
		</p>
		<p>Implementing this approach in pseudocode:</p>

		<ol class="alg">
			<li>reverse():</li>
			<ol>
				<li>for (i = length - 1, j = 0; i >= 0; i--, j++):</li>
				<ol>
					<li>auxiliaryArr[j] = originalArr[i];</li>
				</ol>
				<li>for (i = 0; i < lenght; i++):</li>
				<ol>
					<li>originalArr[i] = auxiliaryArr[j];</li>
				</ol>
			</ol>
		</ol>

		<p>
			What is this approach's time complexity? Copying the elements from
			the original array to the auxiliary array takes ${n}$ operations,
			since we must traverse through ${n}$ elements. Then, copying the
			elements from the auxiliary array back to the original array takes
			${n}$ operations, again because we must traverse through ${n}$
			elements. Accordingly, this approach has a time function of roughly
			${f(n) = 2n.}$ Asymptotically, the approach has a time complexity of
			order ${O(n)}$ &mdash; linear time.
		</p>
	</section>

	<section id="reversing_in_place">
		<p>
			<span class="topic">Reversing in Place.</span> With the
			reverse-in-place approach, we swap the first and the last elements,
			then the second and the second to last, then the third and the third
			to last, and so on. This is done by assigning two indexing variables:
			${i}$ to track indices offsetting from and including the first
			element, and ${j}$ to track indices offsetting from and including the
			last element. We continue the process until either ${i}$ and ${j}$
			have arrived at the same index, or when ${i > j.}$ The
			implementation:
		</p>

		<ol class="alg">
			<li>reverse():</li>
			<ol>
				<li>for (i = 0, j = length - 1; i < j; i++, j--):</li>
				<ol>
					<li>temp = A[i];</li>
					<li>A[i] = A[j];</li>
					<li>A[j] = temp;</li>
				</ol>
			</ol>
		</ol>

		<p>
			With the implementation above, we can see that this approach also
			requires traversing through the array's ${n}$ elements. Accordingly,
			this approach, too, has a running time of ${O(n);}$ linear time.
		</p>
	</section>
</section>

<section id="shifting_and_rotating">
	<h2>Shifting & Rotating</h2>
	<p>
		The next operations we consider are
		<var>leftShift()</var>, <var>rightShift()</var>,
		<var>leftRotate()</var>, and <var>rightRotate()</var>. Each of these
		operations involves moving elements to the left or right &mdash;
		particularly useful actions when implementing other algorithms (e.g.,
		filling in holes in the array).
	</p>
	<p>
		<span class="topic">Shifting an Element.</span> Suppose we had the
		following array:
	</p>
	<div id="array_to_shift_left"></div>
	<p>
		The operation of left-shifting is to shift all of the elements in the
		array to the left:
	</p>
	<div id="shift_left_1"></div>
	<p>
		Notice that in doing so, we lose the element 6. This is the natural
		consequence of left-shifting. We're shifting everything to the left,
		losing whichever element is at index ${i = 0}$ before the left-shift.
	</p>
	<p>
		The same idea extends to right-shifting. The difference, however, is
		that we're shifting elements to the right. Starting with the same
		previous array:
	</p>
	<div id="array_to_shift_right"></div>
	<p><var>rightShift()</var> results in:</p>
	<div id="array_shift_right1"></div>
	<p>
		Implementing both of these algorithms is fairly straightforward. For
		<var>leftShift()</var>, we're moving each element from the right to the
		left. Thus, we must iterate through the array, moving the element at
		<var>array[i+1]</var> to the position <var>array[i]</var>. We also
		include an operation for setting the last element to ${0}$:
	</p>

	<ol class="alg">
		<li>leftShift():</li>
		<ol>
			<li>for (int i = 0; i < length-1; i++): ${n \text{ operations}}$</li>
			<ol>
				<li>array[i] = array[i+1];</li>
			</ol>
			<li>arr[length-1] = 0; ${1 \text{ operation}}$</li>
		</ol>
	</ol>

	<p>
		For <var>rightShift()</var>, we're moving each element from the left to
		the right. Again we iterate through the array, but with a few
		differences: We start from the last element, and we move the element at
		<var>array[i-1]</var> to the position <var>array[i]</var>. We also
		include an operation for setting the first element to ${0}$:
	</p>

	<ol class="alg">
		<li>shiftRight():</li>
		<ol>
			<li>
				<span class="pop">for (int i = length - 1; i > 0; i--): </span>
				<div class="popText">
					<p>${n \text{ operations}}$</p>
				</div>
			</li>
			<ol>
				<li>arr[i] = arr[i - 1];</li>
			</ol>
			<li>
				<span class="pop">arr[0] = 0;</span>
				<div class="popText"><p>${1 \text{ operation}}$</p></div>
			</li>
		</ol>
	</ol>

	<p>
		Given the implementations above, we can see that both shifting
		operations have a time function of roughly ${f(n) = n + 1.}$
		Accordingly, both shifting operations have a time complexity of
		${O(n)}$ &mdash; linear time.
	</p>
	<p>
		<span class="topic">Rotating an Array.</span> Suppose performed a
		left-shift, pushing the element ${6}$ out of the array. What if we
		wanted to keep the ${6}$ somehow? To do so, we use the
		<var>leftRotate()</var> operator. Starting with this array:
	</p>
	<div id="array_to_left_rotate"></div>
	<p><var>leftRotate()</var> yields:</p>
	<div id="left_rotated_array_1"></div>
	<p>
		Notice that the element ${6}$ moves to ${i = length}$ when the
		left-shift pushes it out of the array. The same operation extends to
		rotating to the right &mdash; <var>rightRotate()</var>. Starting with:
	</p>
	<div id="array_to_right_rotate"></div>
	<p><var>rightRotate()</var> yields:</p>
	<div id="right_rotated_array_1"></div>
	<p>
		Implementing rotate follows cleanly from our implementations for
		shifting. All we must do is save the element pushed out of the array in
		a
		<var>temp</var> variable, then assign it to the resulting empty space.
		First, the operation <var>leftRotate()</var>:
	</p>

	<ol class="alg">
		<li>${f}$ leftRotate():</li>
		<ol>
			<li>temp = A[0]</li>
			<li>for (int i = 0; i < length-1; i++):</li>
			<ol>
				<li>array[i] = array[i+1];</li>
			</ol>
			<li>arr[length-1] = temp;</li>
		</ol>
	</ol>

	<p>Second, the operation <var>rightRotate()</var>:</p>

	<ol class="alg">
		<li>${f}$ rightRotate():</li>
		<ol>
			<li>temp = A[length]</li>
			<li>for (int i = length-1; i > 0; i--):</li>
			<ol>
				<li>array[i] = array[i-1];</li>
			</ol>
			<li>arr[0] = temp;</li>
		</ol>
	</ol>

	<p>
		The implementation above is similar to the shifting operations; the
		only difference is the inclusion of one more operation, saving the
		element popped off the array. Accordingly, both
		<var>leftRotate()</var> and <var>rightRotate()</var> have a time
		complexity of ${O(n).}$
	</p>
</section>

<section id="inserting_into_a_sorted_array">
	<h2>Sorted Insert</h2>
	<p>
		Suppose we had the following
		<span class="underlineText">sorted</span> array:
	</p>
	<div id="sorted_insert_array_start"></div>
	<p>
		When inserting into a sorted array like the one above, we often want to
		keep the array's sorted property. In other words, we want to insert the
		element in a sorted position. In this case,
		<var>insert(18)</var> should place the element ${18}$ after ${A_{3} =
		16.}$ This requires placing ${18}$ at ${i = 4,}$ which is presently
		occupied by ${A_{4} = 20.}$ Accordingly, we must make space for the new
		element. This is done by shifting the element at 7, then 6, then 5,
		then 4.
	</p>
	<p>
		How might this shifting be implemented? Well, let's consider a simpler
		case. If we instead wrote <var>insert(34)</var>, then no shifting would
		occur, since 34 would be the largest element. If, however, we wrote
		<var>insert(32)</var>, then 33 would have to be shifted, since ${32 >
		33.}$ Accordingly, when we shift elements, we keep right-shifting,
		starting from the last element, until we reach the
		<span class="underlineText">first</span> element less than the argument
		passed to <var>insert()</var> (i.e., the element we want to
		insert).<sup></sup> This implies that we never have to check the
		elements less than the new element. For example, with
		<var>insert(18)</var>, we never have to check the elements 4, 8, 13,
		and 16. All that matters is 20, 25, 28, and 33. The implementation:
	</p>
	<div class="note">
		<p>
			This algorithm only works because the array's elements are sorted.
		</p>
	</div>

	<ol class="alg">
		<li>${f}$ insert(${x}$):</li>
		<ol>
			<li>i = length-1; ${\color{lightgray} 1 \text{ operation}}$</li>
			<li>
				while (A[i] > ${x}$): ${\color{lightgray} n \text{ operations}}$
			</li>
			<ol>
				<li>array[i+1] = array[i]</li>
				<li>i--;</li>
			</ol>
			<li>A[i+1] = ${x}$; ${\color{lightgray} 1 \text{ operation}}$</li>
		</ol>
	</ol>

	<p>
		The implementation above follows our reasoning. First, in line 2, we
		establish our starting point: The last index in the array. Once that's
		done, we enter the while-loop. If the new element, ${x,}$ is greater
		than the current element, then perform the following: (1) Shift the
		current element to the right; (2) Decrement the index (so we can then
		check the element just before the start). As long as the new element
		${x}$ is greater than the current element, we keep performing the
		operation above. Once we've arrived at an element greater less than
		${x,}$ we exit the while loop and proceed to line 6: Assign to the
		position after the current position (an empty position) the new element
		${x.}$
	</p>
	<p>
		Looking at the annotations, we see that the time function for this
		algorithm is roughly ${f(n) = n + 2.}$ Accordingly, this algorithm has
		a time complexity of ${O(n)}$ &mdash; linear time. In the best case
		scenario, ${x}$ would be greater than or equal to the last element, in
		which case we have a time complexity of ${\Omega(1)}$ &mdash; constant
		time.
	</p>
	<p>
		<span class="topic">Checking if an Array is Sorted.</span> A necessary
		condition for the algorithm above is that the array is sorted. Indeed,
		the algorithm above is incorrect for unsorted arrays. Hence, the
		<var>insert()</var> operator requires some other operator to check if
		the array is sorted. We will call this operator <var>isSorted()</var>.
	</p>
	<p>Suppose we had the following array:</p>
	<div id="check_sorted_array_1"></div>
	<p>
		We can check if the array is sorted by comparing the element at
		position ${i}$ to the element at position ${i + 1.}$ Given that array
		above is sorted in ascending order, if the condition ${a_i \leq
		a_{i+1}}$ is true for
		<span class="underlineText">all</span> elements in the array, we can
		conclude that all the elements are sorted. In this case, the elements
		are sorted up until ${i = 3,}$ since ${26 \nleq 20.}$
	</p>
	<p>
		Implementing the <var>isSorted()</var> method is a good exercise in
		being mindful of the <span class="term">fencepost problem</span>.
		Because we want to check that each element ${a_i \leq a_{i+1},}$ we
		must be careful with endpoints. In this case, we want to check all of
		the elements in the list &mdash; the property <var>length</var>. But,
		we must make sure we do not perform the comparison ${a_{length} \leq
		a_{length + 1}.}$ This would lead to either (a) an out of bounds error,
		or (b) comparing the element at ${a_{length}}$ to a garbage value.
		Hence, we must stop at ${i = length-1.}$ The implementation:
	</p>

	<ol class="alg">
		<li>${f}$ isSorted()</li>
		<ol>
			<li>
				for (int i = 0; i < size-1; i++): ${\color{lightgray} n \text{
				operations}}$
			</li>
			<ol>
				<li>
					if (A[i] >= A[i+1]): ${\color{lightgray} 1 \text{ operation}}$
				</li>
				<ol>
					<li>return false; ${\color{lightgray} 1 \text{ operation}}$</li>
				</ol>
			</ol>
			<li>return true; ${\color{lightgray} 1 \text{ operation}}$</li>
		</ol>
	</ol>

	<p>
		Examining the annotations, assuming the array is sorted, the algorithm
		has a time function of roughly ${f(n) = 2n + 1.}$ Thus, this algorithm
		(assuming the array is sorted), has a time complexity of ${O(n),}$
		which is linear time. If the array is unsorted, then in the worst case
		scenario, the algorithm still has a running time of ${O(n).}$ In the
		best-case scenario, however, the algorithm has a running time of
		${\Omega(1)}$ &mdash; the first element is unsorted.
	</p>

	<h4>Negatives Towards Start & Positives Towards End</h4>
	<p>
		One problem that often appears with array data structures is where we
		have a mixture of positive and negative numbers. Confronting this
		problem, we often want to move all the negative numbers towards the
		beginning, or the right side, and the positive numbers towards the end.
		Note that we aren't sorting the elements. We're simply separating the
		negatives from the positives. For example, such an array might look
		like the following:
	</p>
	<div id="negative_to_positive_array_1"></div>
	<p>What we want to do is obtain an array that looks like:</p>
	<div id="negative_to_positive_array_2"></div>
	<p>
		Notice that we aren't sorting. We're just moving the positive and
		negative elements. We will call this operation
		<var>signSplit()</var>. With this operation, we will iterate. First, we
		create two variables: A variable <var>i</var> to track the indices
		starting from the left, and a variable <var>j</var> to the track the
		indices from the right. Then, we iterate through the array, as long as
		<var>i < j.</var>. Then, inside the while-loop, we place two more
		while-loops. As long as <var>A[i] < 0,</var> we will increment
		<var>i</var>. Otherwise, we go the second while-loop: As long as as
		<var>A[j] > 0,</var>, we will decrement <var>j</var>. Then, once that
		has finished executing, we will swap <var>A[i]</var> with
		<var>A[j]</var>. This process continues as long as
		<var>i < j.</var> The implementation:
	</p>

	<ol class="alg">
		<li>${f}$ signSplit():</li>
		<ol>
			<li>int i = 0;</li>
			<li>int j = length - 1;</li>
			<li>while (i ${<}$ j):</li>
			<ol>
				<li>while (array[i] ${<}$ 0): i++;</li>
				<li>while (array[j] ${\geq}$ 0): j--;</li>
				<li>swap(array[i], array[j]);</li>
			</ol>
		</ol>
	</ol>

	<p>
		The implementation above is a good example of how nested loops do not
		always imply polynomial time. Here, the time spent most is just on
		comparing the elements. In this case, there are a total of ${n + 2}$
		comparisons (+2 because both <var>i</var> and <var>j</var> must both
		check one extra number). Because the brunt of this time is spent on
		comparisons of ${n}$ elements, this approach has a time complexity of
		${O(n)}$ &mdash; linear time. To see that this is the case, the code
		above is equivalent to the following:
	</p>

	<ol class="alg">
		<li>${f}$ signSplit():</li>
		<ol>
			<li>int i = 0;</li>
			<li>int j = length - 1;</li>
			<li>while (i ${<}$ j):</li>
			<ol>
				<li>if (array[i] < 0) & (array[j] < 0):</li>
				<ol>
					<li>i++;</li>
				</ol>
				<li>else if (array[i] > 0) & (array[j] > 0):</li>
				<ol>
					<li>j--;</li>
				</ol>
				<li>else if (array[i] > 0) & (array[j] < 0):</li>
				<ol>
					<li>swap(array[i], array[j]);</li>
				</ol>
				<li>else:</li>
				<ol>
					<li>i++;</li>
					<li>j--;</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		With this implementation, we can clearly see that the algorithm has a
		time complexity of ${O(n).}$ We used the multiple while-loop approach
		simply because it's cleaner. Alternatively, here's another
		implementation that takes an approach similar to the partitioning
		algorithm of quicksort (an algorithm we will see in due course):
	</p>

	<ol class="alg">
		<li>${f}$ signSplit():</li>
		<ol>
			<li>int j = 0;</li>
			<li>for (int i = 0; i < length; i++):</li>
			<ol>
				<li>if (arr[i] < 0):</li>
				<ol>
					<li>if (i ${\neq}$ j):</li>
					<ol>
						<li>swap(arr[i], arr[j]);</li>
					</ol>
					<li>j++;</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		Clearly with this implementation, we still have a time complexity of
		${O(n).}$
	</p>
</section>

<section id="merging_arrays">
	<h2>Binary Operations on Arrays</h2>
	<p>
		In this section, we consider the
		<i>binary operations</i> on arrays. These are operations that involve
		two arrays as operands, namely: <var>merge(${A}$, ${B}$)</var>;
		<var>append(${A}$, ${B}$)</var>; <var>concat(${A}$, ${B}$)</var>; and
		<var>copy(${A}$)</var>, where ${A}$ and ${B}$ are arrays. We consider
		each in turn.
	</p>

	<section id="append">
		<p>
			<span class="topic">Appending an Array.</span> With the
			<var>${A}$.append(${B}$)</var> operation, we take an existing array
			${A}$ and add on to it an array ${B.}$ For example, suppose we had
			some array ${A}$:
		</p>
		<div id="array_to_be_concatenated"></div>
		<p>Then suppose we had the array ${B}$:</p>
		<div id="array_to_concatenate"></div>
		<p>
			With the <var>${A}$.append(${B}$)</var> operation, we receive as
			output the following array:
		</p>
		<div id="new_concatenated_array"></div>
		<p>
			Because we're working with a static array data structure, this
			operation works <span class="underlineText">only if</span> the array
			to append to (in this case ${A}$), has uninitialized positions. In
			other words, the array's <i>length</i> is less than its <i>size</i>.
			Otherwise, we would go beyond the array's bounds. Implementing this
			algorithm:
		</p>

		<ol class="alg">
			<li>${f}$ append(A[], B[]):</li>
			<ol>
				<li>if (A.length < A.size):</li>
				<ol>
					<li>int j = 0;</li>
					<li>for (int i = A.length+1; i < size; i++):</li>
					<ol>
						<li>A[i] = B[j];</li>
						<li>A.length++;</li>
						<li>j++;</li>
					</ol>
				</ol>
				<li>else:</li>
				<ol>
					<li>return "A has no free spaces";</li>
				</ol>
			</ol>
		</ol>

		<p>
			Here, we must perform ${n = s - \ell}$ comparisons for the index
			<var>i</var>, where ${s}$ is the size of the array and ${\ell}$ is
			the length of the array. Accordingly, this algorithm has a time
			complexity of ${O(n),}$ linear time, where ${n}$ is the difference
			between the array's size and its length.
		</p>
	</section>

	<section id="merging_arrays">
		<p>
			<span class="topic">Merging Arrays.</span> Say we had the following
			arrays:
		</p>
		<div class="split">
			<div id="array_to_merge_A"></div>
			<div id="array_to_merge_B"></div>
		</div>
		<p>
			We want to take these two arrays and construct the following array:
		</p>
		<div id="A_and_B_merged_array"></div>
		<p>
			This operation is called <span class="term">array merging</span>, and
			we denote it with the operator <var>merge(${A}$, ${B}$)</var>, where
			${B}$ is the array to be merged on to the array ${A.}$ Notice the
			outpout of <var>merge()</var>: It's an array where the elements of
			${A}$ and ${B}$ are placed into a single array, sorted. Accordingly,
			this operation requires a third array for its return.
		</p>
		<p>
			How does this operation work? Here, we need three pointers:
			<var>i</var>, <var>j</var>, and <var>k</var> for each of the arrays
			<var>A</var>, <var>B</var>, and the new array, <var>C</var>. The
			pointer <var>i</var> will track the indices of <var>A</var>, the
			pointer <var>j</var> the indices of <var>B</var>, and the pointer
			<var>k</var> the indices of <var>C</var>. Once these are established,
			we iterate, starting from the first position. If
			<var>A[i] < B[j]</var>, then: <var>A[i]</var> is assigned to
			<var>C[k]</var>, and both <var>i</var> and <var>k</var> are
			incremented. Otherwise, we assign <var>B[j]</var> to <var>C[k]</var>,
			and both <var>j</var> and <var>k</var> are incremented. Notice that
			with this procedure, <var>k</var> is always incremented. Whether
			<var>i</var> or <var>j</var> is incremented depends on whether the
			element at that particular position is less than the other. The
			implementation:
		</p>

		<ol class="alg">
			<li>${f}$ merge(A, B):</li>
			<ol>
				<li>new array C = A.length + B.length</li>
				<li>int i = 0, j = 0, k = 0;</li>
				<li>while (i < A.length & j < B.length):</li>
				<ol>
					<li>if (A[i] < B[j]):</li>
					<ol>
						<li>C[k] = A[i];</li>
						<li>i++;</li>
					</ol>
					<li>else:</li>
					<ol>
						<li>C[k] = B[j];</li>
						<li>j++;</li>
					</ol>
					<li>k++;</li>
				</ol>
				<li>for (i < A.length; i++):</li>
				<ol>
					<li>C[k++] = A[i];</li>
				</ol>
				<li>for (j < B.length; j++):</li>
				<ol>
					<li>C[k++] = B[j];</li>
				</ol>
			</ol>
		</ol>

		<p>
			Notice that we included two more for-loops at the end. This is to
			handle the &#8220;stragglers&#8221; &mdash; the elements remaining in
			either array <var>A</var> or array <var>B</var> that could not be
			copied over because the while-loop terminated before both arrays were
			completely compared. This occurs if either <var>A</var> or
			<var>B</var> has three elements in a row that are less than the given
			element in the other. For example, if <var>A = [1, 2]</var> and
			<var>B = [3, 4]</var>, then the while-loop would terminate the moment
			<var>i = 1</var> (at which point <var>k = 1</var>), and as such, the
			elements of <var>B</var> are not checked. The for-loop ensures the
			unchecked elements are checked and assigned accordingly.
		</p>
		<p>
			The time complexity for this operation is straightforward. We're
			comparing ${m}$ elements and ${n}$ elements (the two array
			arguments). Accordingly, this algorithm has a time complexity of
			${\Theta(m + n);}$ linear time. Whenever we see a time complexity of
			the form ${a + b,}$ it's highly likely that we're dealing with an
			algorithm that involves merging.
		</p>
	</section>
</section>

<section id="set_operations">
	<h2>Set Operations on Arrays</h2>
	<p>
		With arrays, we can also perform the fundamental set operations of
		<i>union</i>, <i>intersetion</i>, <i>difference</i>, and
		<i>membership</i>. We will call these operations as such:
		<var>union(${A}$, ${B}$)</var>, <var>intersection(${A}$, ${B}$)</var>,
		<var>difference(${A}$, ${B}$)</var>, and
		<var>isMember(${x}$, ${A}$)</var>.
	</p>

	<section id="union_arrays">
		<p>
			<span class="topic">Union of Arrays.</span> Recall that in
			mathematics, given a set ${A = \{ 3, 5, 10, 4, 6 \}}$ and a set ${B =
			\{ 12, 4, 7, 2, 5 \},}$ the union of ${A}$ and ${B}$ is the set ${A
			\cup B = \{ 3, 5, 10, 4, 6, 12, 7, 2 \}.}$ Notice that the union
			lists no duplicates. In this case, there were two duplicates: ${4}$
			and ${5.}$ These duplicate elements were omitted from the resulting
			set.
		</p>
		<p>
			We implement the process of forming a union through the operator
			<var>union(${A}$, ${B}$)</var>, where ${A}$ and ${B}$ are arrays.
			Implementing this operator, we want to keep in mind the requirement
			that there must be no duplicates in the resulting array. We aren't
			just blindly copying. Otherwise, the operator would be no different
			from <var>concatenate()</var>.
		</p>
		<p>Suppose the array ${A}$ is the following:</p>
		<div id="array_union_A"></div>
		<p>And the array ${B:}$</p>
		<div id="array_union_B"></div>
		<p>Executing <var>union(A, B)</var>, we have:</p>
		<div id="array_union_A_and_B"></div>
		<p>
			The algorithm consists of several steps. First, we have to assign all
			of the elements in the first array to the new array. If there are
			${m}$ elements, this process takes ${m}$ time. Then, to ensure we do
			not have any duplicates, we must check the ${n}$ elements in the
			second array against the ${m}$ elements inside the new array then
			assign the elements that do not match. Given ${m}$ elements in the
			new array, this checking takes ${m \cdot n}$ time. Accordingly, the
			algorithm has a runtime complexity of ${O(m + nm).}$ To simplify this
			expression for the purposes of asymptotic analysis, we want to only
			use one variable. Accordingly, the time complexity is ${O(n + nn),}$
			or more relevantly, ${O(n^2).}$ This is quadratic time.
		</p>
		<p>
			To improve this runtime, we can sort the array elements before
			performing the union. We will cover sorting algorithms in a later
			section, so for now, we will just assume that the array elements are
			already sorted. Suppose the array ${A}$ is:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>10</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>And the set ${B:}$</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${B}$</td>
					<td>2</td>
					<td>4</td>
					<td>5</td>
					<td>7</td>
					<td>12</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>
			With sorted arrays, all we have to do is merge while avoiding
			duplicates. We compare ${A_i}$ against ${B_j.}$ The lesser element is
			assigned, and the other element's index is incremented. If both
			elements are equal, we assign either one, and increment both indices.
			Thus:
		</p>
		<ol>
			<li>
				Start: ${i = 0,}$ the index for ${A,}$ ${j = 0,}$ the index for
				${B,}$ and ${k = 0,}$ the index for ${C.}$
			</li>
			<li>
				Compare ${A_i \leq B_j.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="redText">3</span></td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greenText">0</span></td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="redText">2</span></td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greenText">0</span></td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				${3}$ is not less than or equal to ${2,}$ so assign ${2}$ to the
				array ${C,}$ which is ${B_j.}$ Increment ${j}$ and ${k.}$ ${j}$ is
				now ${1}$ and ${k}$ is now ${1.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="redText">3</span></td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greenText">0</span></td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${C}$</td>
							<td>2</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k}$</td>
							<td>0</td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				Compare ${A_i \leq B_j.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="redText">3</span></td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greenText">0</span></td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="redText">4</span></td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				${3}$ is less than ${4,}$ so assign ${3}$ to the array ${C,}$ which
				is ${A_j.}$ Increment ${i}$ and ${k.}$ ${i}$ is now ${1}$ and ${k}$
				is now ${2.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${C}$</td>
							<td>2</td>
							<td>3</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k}$</td>
							<td>0</td>
							<td>1</td>
							<td><span class="greenText">2</span></td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				Compare ${A_i \leq B_j.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td>3</td>
							<td><span class="redText">4</span></td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td>0</td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="redText">4</span></td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greenText">1</span></td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				${4}$ is equal to ${4,}$ so assign ${4}$ to the array ${C,}$ which
				is ${A_j.}$ Increment ${i,}$ ${j,}$ and ${k.}$ ${i}$ is now ${2,}$
				${j}$ is now ${2,}$ and ${k}$ is now ${3.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td><span class="greyText">4</span></td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greenText">2</span></td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">4</span></td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greenText">2</span></td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${C}$</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				Compare ${A_i \leq B_j.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="redText">5</span></td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greenText">2</span></td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="redText">5</span></td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greenText">2</span></td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				${5}$ is equal to ${5,}$ so assign ${5}$ to the array ${C,}$ which
				is ${A_j.}$ Increment ${i,}$ ${j,}$ and ${k.}$ ${i}$ is now ${3,}$
				${j}$ is now ${3,}$ and ${k}$ is now ${4.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${C}$</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td><span class="greenText">4</span></td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				Compare ${A_i \leq B_j.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td><span class="redText">6</span></td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td><span class="redText">7</span></td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</li>
			<li>
				${6}$ is less than ${7,}$ so assign ${6}$ to the array ${C,}$ which
				is ${A_j.}$ Increment ${i}$ and ${k.}$ ${i}$ is now ${4,}$ ${j}$ is
				still ${3,}$ and ${k}$ is now ${5.}$

				<table class="array">
					<tbody>
						<tr>
							<td>${A}$</td>
							<td><span class="greyText">3</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td><span class="greyText">6</span></td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">3</span></td>
							<td><span class="greenText">4</span></td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${B}$</td>
							<td><span class="greyText">2</span></td>
							<td><span class="greyText">4</span></td>
							<td><span class="greyText">5</span></td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j}$</td>
							<td><span class="greyText">0</span></td>
							<td><span class="greyText">1</span></td>
							<td><span class="greyText">2</span></td>
							<td><span class="greenText">3</span></td>
							<td>4</td>
						</tr>
					</tbody>
				</table>

				<table class="array">
					<tbody>
						<tr>
							<td>${C}$</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td><span class="greenText">5</span></td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</li>
		</ol>
		<p>
			The procedure continues for the rest of the elements. Because this
			approach to <var>union()</var> is essentially merging two arrays, it
			has a runtime of ${O(m+n),}$ or more generally ${O(n).}$ This is
			linear time, which is better than quadratic time.
		</p>
	</section>

	<section id="intersection">
		<p>
			<span class="topic">Intersection.</span> From set theory, the
			intersection of two sets ${A}$ and ${B}$ is the set of all elements
			in both ${A}$ and ${B.}$ For example, suppose ${A = \{ 1, 2, 3 \}}$
			and ${B = \{ 1, 2, 4 \}.}$ The intersection ${A \cap B}$ is the set
			${\{ 1, 2 \}.}$ Like the <var>union()</var> operation, we can
			implement the intersection operation with arrays. We'll call this
			operation <var>intersection(${A}$, ${B}$)</var>, where ${A}$ and
			${B}$ are arrays.
		</p>
		<p>
			To illustrate, suppose ${A}$ and ${B}$ were the following. The array
			${A:}$
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>3</td>
					<td>5</td>
					<td>10</td>
					<td>4</td>
					<td>6</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>And the array ${B:}$</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${B}$</td>
					<td>12</td>
					<td>4</td>
					<td>7</td>
					<td>2</td>
					<td>5</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>
			We then have an empty array ${C:}$ which will store the intersection.
			An important question is what should be the size of ${C?}$ The size
			of ${C}$ is computed from the
			<a
				href="{% url 'numerm:disc_setTheory' %}#size_of_intersection_and_union"
				><i>Cardinal Number Formula:</i></a
			>
		</p>
		<figure>
			<div>
				<p>${n(A \cap B) = n(A) + n(B) - n(A \cup B)}$</p>
			</div>
		</figure>
		<p>
			Applying the formula, the size of ${C}$ is the length of ${A}$ plus
			the length of ${B,}$ minus the length of the array resulting from the
			union of ${A}$ and ${B.}$ While this would give us the exact number
			of spaces necessary for the intersection, it would be simpler, and
			more efficient, to use the length of whichever is smaller (in terms
			of the number of elements) between ${A}$ and ${B.}$ This is because
			the number of elements in common between ${A}$ and ${B}$ is at most
			the cardinality of the smaller between the two sets. If ${A}$ is a
			smaller set than ${B,}$ then the cardinality of ${A \cap B}$ is at
			most the cardinality of ${A}$ (all the elements in ${A}$ are elements
			in ${B}$). If ${B}$ is a smaller set than ${A,}$ then the cardinality
			of ${A \cap B}$ is at most the cardinality of ${B.}$ And if ${A}$ and
			${B}$ are of the same cardinality, then the cardinality of ${A \cap
			B}$ is at most the cardinality of ${A}$ (or ${B}$).
		</p>
		<p>
			In our case, the arrays ${A}$ and ${B}$ are of the same length, so
			the length of ${C}$ is at most ${5}$ (the elements of ${A}$ are all
			elements ${B}$ and vice versa):
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${C}$</td>
					<td></td>
					<td></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td>${k}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>
			We start by To output the intersection, we compare each element in
			${A}$ against each element in ${B.}$ If there's a match, then: (1) we
			assign the element in ${A}$ to the position in ${C,}$ and (2)
			increment ${k,}$ the index for ${C.}$ Comparing element in ${A}$ to
			each element in ${B}$ requires ${n \cdot m}$ operations. As such,
			this algorithm has a time complexity of ${O(n^2).}$ This isn't very
			efficient; it's quadratic time.
		</p>
		<p>
			Like the <var>union()</var> operation, we can improve this runtime if
			the arrays are sorted before performing <var>intersection()</var>.
			Suppose our previous arrays were sorted:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>10</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<table class="array">
			<tbody>
				<tr>
					<td>${B}$</td>
					<td>2</td>
					<td>4</td>
					<td>5</td>
					<td>7</td>
					<td>12</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p><var>intersection()</var> then works as such:</p>
		<ol>
			<li>
				Set <var>i = 0</var>, <var>j = 0</var>, and <var>k = 0</var>.
			</li>
			<li>Compare: <var>A[i]</var> and <var>B[j]</var>.</li>
			<ol>
				<li>If <var>A[i] > B[j]</var> increment <var>j</var>.</li>
				<li>If <var>A[i] < B[j]</var> increment <var>i</var>.</li>
				<li>
					If <var>A[i] = B[j]</var>, assign <var>A[i]</var> to
					<var>C[k]</var>, increment <var>i</var> <var>j</var>, and
					<var>k</var>.
				</li>
			</ol>
			<li>
				If <var>i > A.length</var> or <var>j > B.length</var>, return
				<var>C.</var> Else, return to step 2.
			</li>
		</ol>
		<p>
			With this approach, we have time complexity of ${O(m + n),}$ or more
			generally, ${O(n).}$ This is linear time; a marked improvement from
			quadratic time.
		</p>
	</section>

	<section id="difference">
		<p>
			<span class="topic">Difference.</span> Suppose we had the following
			sets:
		</p>
		<figure>
			<div>
				<p>${A = \{ 3, 5, 10, 4, 6 \}}$</p>
				<p>${B = \{ 12, 4, 7, 2, 5 \}}$</p>
			</div>
		</figure>
		<p>
			The difference between these two sets is the set consisting of
			elements not in both ${A}$ and ${B}$ (i.e., the set without the
			elements common to both ${A}$ and ${B}$). In this case, the common
			elements are ${4}$ and ${5.}$ Thus, ${A - B = \{ 3, 10, 6 \},}$ and
			${B - A = \{ 12, 7, 2 \}.}$ We implement this operation as the
			operator
			<var>difference()</var>.
		</p>
		<p>
			With the <var>difference()</var> operator, we say that order is
			material. Thus, <var>difference(A, B)</var> computes ${A - B,}$ and
			<var>difference(B, A)</var> computes ${B - A.}$ In other words, the
			arguments to the <var>difference()</var> operator are noncommutative.
		</p>
		<p>
			Like <var>intersection()</var>, we might implement
			<var>difference()</var> by comparing each element in ${A}$ against
			each element in ${B.}$ If an element in ${A}$ matches an element in
			${B,}$ we skip that element compare the next. If there is no match,
			we assign the element to the resulting array ${C.}$ Again, like
			<var>intersection()</var>, this algorithm requires a total of ${n
			\cdot m}$ operations to execute. This yields a quadratic runtime of
			${O(n^2).}$
		</p>
		<p>
			Just as we saw with <var>intersection()</var>, we can improve the
			time complexity by ensuring the array arguments are sorted before
			performing the <var>difference()</var> procedure. Suppose the arrays
			are sorted:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>10</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<table class="array">
			<tbody>
				<tr>
					<td>${B}$</td>
					<td>2</td>
					<td>4</td>
					<td>5</td>
					<td>7</td>
					<td>12</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<table class="array">
			<tbody>
				<tr>
					<td>${C}$</td>
					<td></td>
					<td></td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<td>${k}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
				</tr>
			</tbody>
		</table>

		<p>
			With the arrays sorted, the
			<var>difference()</var> operator's algorithm works as such:
		</p>
		<ol>
			<li>
				Set <var>i = 0</var>, <var>j = 0</var>, and <var>k = 0</var>.
			</li>
			<li>Compare <var>A[i]</var> with <var>B[j]</var>.</li>
			<ol>
				<li>If <var>A[i] > B[j]</var>, increment <var>j</var>.</li>
				<li>
					If <var>A[i] < B[j]</var>:
					<ol>
						<li>Assign <var>A[i]</var> to <var>C[k]</var>.</li>
						<li>Increment <var>i</var>.</li>
						<li>Increment <var>k</var>.</li>
					</ol>
				</li>
				<li>
					If <var>A[i] = B[j]</var>, increment <var>i</var>, increment
					<var>j</var>.
				</li>
			</ol>
			<li>
				If <var>i > A.length</var>, return <var>C</var>. Else, return to
				Step 2.
			</li>
		</ol>
		<p>
			The algorithm above computes the difference ${A - B.}$ As such, when
			difference is called, it is called as
			<var>difference(A, B)</var>. To compute ${B - A,}$ we perform the
			same algorithm, but swap <var>A[i]</var> and <var>B[j]</var> (and
			their respective indices) in the algorithm above.
		</p>
		<p>
			This algorithm performs in the same manner as the
			<var>merge()</var> operator. Accordingly, it has a time complexity of
			${O(m + n),}$ or, in a single variable, ${O(n).}$ This is linear
			time; faster than quadratic time.
		</p>
	</section>
</section>

<section id="find_missing_element_sorted">
	<h2>
		Search-and-rescue Algorithms: Algorithms for Finding Missing Elements
	</h2>
	<p>
		A particularly useful set of algorithms associated with arrays is the
		set of algorithms for finding missing elements. As an homage to
		search-and-rescue dogs, we call these algorithms
		<span class="term">search-and-rescue algorithms</span>.
	</p>
	<p>
		Search-and-rescue algorithms are particularly useful when we know that
		a particular sequence should contain certain elements. For example, a
		password, identification number, or waiting list number might have a
		pre-defined rule for what the sequence of digits should be. If the
		sequence is sufficiently long, it would be tedious for us to check, by
		hand, each element one by one just to spot a missing element.
	</p>
	<p>
		This is where the search-and-rescue algorithm comes in. Implementing
		these algorithms depends on four factors: (1) the sequence (implemented
		as an array) to check is sorted; (2) the sequence is unsorted; (3) the
		sequence contains a single missing element; and (4) the sequence
		contains multiple missing elements. For this section, we restrict the
		search-and-rescue algorithms to operating on sequences of numbers.
		However, our discussion should shed light on how these algorithms might
		be extended to arrays of other values, such as strings.
	</p>

	<section id="sorted_search_and_rescue_single">
		<h4>Sorted Search-and-rescue: Single Missing Elements</h4>
		<p>
			First, we consider a sequence implemented as a sorted array. Suppose
			the sorted array is the following:
		</p>
		<figure>
			<div>
				<p>${A = \lang 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12 \rang}$</p>
			</div>
		</figure>
		<p>
			This is the sequence of natural numbers. Although we immediately see
			that the missing element is ${7,}$ the task would be far more
			difficult if ${A}$ consisted of a thousand elements. The trick to
			finding the missing element in sorted array is to rely on the
			sequence's summation formula. In this case, the sum of the natural
			numbers is given by the following:
		</p>
		<figure>
			<div>
				<p>
					${\sum\limits_{k = 1}^{n} k = \dfrac{n(n+1)}{2} \qquad
					\text{where} ~~~~ k, n \in \N}$
				</p>
			</div>
		</figure>
		<p>
			Knowing that ${A}$ is the sequence of the natural numbers, we can
			find the sum of ${A}$ if the missing element was present. We'll call
			this the
			<i>expected sum</i>. In this case, the expected sum of the array
			${A}$ would be:
		</p>
		<figure>
			<div>
				<p>
					${\sum\limits_{i = 1}^{12} A_i = \dfrac{12(12 + 1)}{2} = 78}$
				</p>
			</div>
		</figure>
		<p>
			Next, we compute the sum of ${A}$ as is (without the missing element
			included). We'll call this the
			<i>current sum</i>. To do so, we use our familiar
			<a href="#summing_elements"><var>sum()</var> operator.</a>
			In this case, the <i>current sum</i> is ${71.}$ Once we obtain the
			current sum, the missing element is the difference between the
			<i>expected sum</i> and the <i>current sum</i>:
		</p>
		<figure>
			<div>
				<p>
					${\large A_{\text{missing}} = S_{\text{expected}} -
					S_{\text{current}}}$
				</p>
				<ul class="def">
					<li class="where">
						${A_{\text{missing}}}$ is the missing element;
					</li>
					<li>${S_{\text{expected}}}$ is the expected sum; and</li>
					<li>${S_{\text{current}}}$ is the current sum.</li>
				</ul>
			</div>
		</figure>
		<p>Applying this formula:</p>
		<figure>
			<div>
				$$ \begin{aligned} \large A_{\text{missing}} &= S_{\text{expected}}
				- S_{\text{current}} \\ &= 78 - 71 \\ &= 7 \end{aligned} $$
			</div>
		</figure>
		<p>The implementation might look like:</p>

		<ol class="alg">
			<li>${f}$ sum_natural_numbers(n):</li>
			<ol>
				<li>return ((n * (n + 1)) / 2);</li>
			</ol>
			<li></li>
			<li>${f}$ findMissing(A, summation_formula()):</li>
			<ol>
				<li>let current_sum = 0;</li>
				<li>for (i = 0; i < A.length - 1; i++):</li>
				<ol>
					<li>current_sum += A[i];</li>
				</ol>
				<li>let expected_sum = summation_formula(A.lastElement)</li>
				<li>let missing_element = expected_sum - current_sum;</li>
				<li>return missing_element;</li>
			</ol>
			<li></li>
			<li>findingMissing(A, sum_natural_numbers());</li>
		</ol>
		<p>
			With the implementation above, we rely on a separate function,
			<var>sum_natural_numbers(n)</var>, to compute the expected sum. There
			may be situations, however, where we do not know the summation
			formula for a particular sequence. Moreover, the call to
			<var>sum_natural_numbers(n)</var> requires an additional stack frame,
			and we may have space complexity concerns (certain summation formulas
			can get very complex or require large amounts of memory). As such, we
			consider an alternative implementation.
		</p>
		<p>
			With the alternative implementation, we rely on the indices of each
			element in the array. For example, suppose we had the following
			array:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>10</td>
					<td>11</td>
					<td>13</td>
					<td>14</td>
					<td>15</td>
					<td>16</td>
					<td>17</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>10</td>
				</tr>
			</tbody>
		</table>

		<p>
			Notice with each element in the array, the difference between the
			element and its index is 6, until we get to the element at index
			${6.}$
		</p>
		<figure>
			<div>
				$$ \begin{aligned} 6 - 0 &= 6 \\ 7 - 1 &= 6 \\ 8 - 2 &= 6 \\ 9 - 3
				&= 6 \\ 10 - 4 &= 6 \\ 11 - 5 &= 6 \\ 13 - 6 &= 7 \end{aligned} $$
			</div>
		</figure>
		<p>
			The break at ${13 - 6}$ indicates there's a missing element. The
			missing element is given by ${6 + 6,}$ which is ${12.}$ Implementing
			this approach:
		</p>
		<ol class="alg">
			<li>${f}$ findMissing(arr A):</li>
			<ol>
				<li>let low = A.firstElement;</li>
				<li>let difference = low - 0;</li>
				<li>for (let i = 0; i < A.length; i++):</li>
				<ol>
					<li>if (A[i] - i != difference):</li>
					<ol>
						<li>print "Missing element is: (i + difference)";</li>
						<li>break</li>
					</ol>
					<li>else: print "No missing elements";</li>
				</ol>
			</ol>
		</ol>
		<p>
			With both the summation formula approach and the index difference
			approach, we must iterate through ${n}$ elements. Accordingly, both
			algorithms have a time complexity of ${O(n)}$ &mdash; linear time.
		</p>
	</section>

	<section id="sorted_search_and_rescue_multiple">
		<h4>Sorted Search-and-rescue: Multiple Missing Elements</h4>
		<p>
			Now let's consider finding multiple missing elements. Consider the
			following array:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>11</td>
					<td>12</td>
					<td>15</td>
					<td>16</td>
					<td>17</td>
					<td>18</td>
					<td>19</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>10</td>
				</tr>
			</tbody>
		</table>

		<p>
			We have several missing elements: ${10, 13, 14.}$ Not only do we have
			multiple missing elements, we also have consecutive missing elements.
			To sniff out the missing, we'll use the same index-difference
			approach. But, we must account for a change in the problem's
			dynamics. The first occurence of the missing element's scent is at
			${i = 4.}$ This tells us that there's a missing element: ${i + d = 4
			+ 6 = 10.}$
		</p>
		<p>
			Equally important is the fact that this change in difference, from
			${6}$ to ${7,}$ permeates through the rest of the sequence.
			Accordingly, we must increment the difference: ${6 + 1 = 7.}$ The
			difference is now ${7.}$ At ${i = 5,}$ the difference is ${12 - 5 =
			7,}$ so we can conclude that there is no missing element.
			Accordingly, if there are no other missing elements, the difference
			should remain ${7}$ on and after ${i = 4.}$ Clearly, however, this
			isn't the case. At ${i = 6,}$ we have another change in the
			difference: ${15 - 6 = 9.}$ Because another change occurs (the
			difference should be ${7}$), we conclude that another element is
			missing: ${i + d = 6 + 7 = 13.}$ Once more we increment the
			difference: ${7 + 1 = 8.}$ At ${i = 6,}$ we see that ${15 - 6 = 9,}$
			which is not ${8.}$ Hence, we have another missing element: ${i + d =
			6 + 8 = 14.}$ Once more we increment the difference &mdash; ${8 + 1 =
			9.}$ At ${i = 6,}$ we have ${15 - 6 = 9.}$ Because this is the
			correct difference, we can conclude that the element is in the right
			position. This process yields the missing elements: ${10, 13, 14.}$
			Implementing:
		</p>

		<ol class="alg">
			<li>${f}$ findMissing(array A):</li>
			<ol>
				<li>let low = A.firstElement;</li>
				<li>let difference = low - 0;</li>
				<li>for (int i = 0; i < A.length; i++):</li>
				<ol>
					<li>if (A[i] - i != difference):</li>
					<ol>
						<li>while (difference < A[i] - i):</li>
						<ol>
							<li>print "Missing element is: (i + difference)";</li>
							<li>difference++;</li>
						</ol>
					</ol>
					<li>else: print "No missing elements";</li>
				</ol>
			</ol>
		</ol>

		<p>
			Although the algorithm above contains a while-loop inside a for-loop,
			the time taken to print the missing elements is negligible. The
			majority of the time taken to print the missing elements lies in the
			for-loop, where we must iterate through ${n}$ elements. Accordingly,
			this algorithm takes linear time to execute, ${O(n).}$
		</p>
	</section>

	<section id="search_and_rescue_unsorted">
		<h3>Bitsets: Search-and-rescue for Unsorted Arrays</h3>
		<p>
			Let's now consider how to find the missing elements of an unsorted
			array. Suppose we had the following array:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${A}$</td>
					<td>3</td>
					<td>7</td>
					<td>4</td>
					<td>9</td>
					<td>12</td>
					<td>6</td>
					<td>1</td>
					<td>11</td>
					<td>2</td>
					<td>10</td>
				</tr>
				<tr>
					<td>${i}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
				</tr>
			</tbody>
		</table>

		<p>
			To begin, we start by finding the largest element in the array. We'll
			call this the <var>high</var>. In this case, it's ${12.}$ Then, we
			create a new array of size ${13,}$ where each element in the array is
			${0:}$
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${H}$</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
					<td>0</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>10</td>
					<td>11</td>
					<td>12</td>
				</tr>
			</tbody>
		</table>

		<p>
			Now we scan through the array ${A.}$ For each of the elements, we
			will increment the ${0}$ occupying the corresponding index with the
			same value in the array ${H.}$ For example, the first element in
			${A}$ is ${3,}$ so we go to the ${0}$ at ${j = 3,}$ and increment it
			by ${1.}$ This results in the following array:
		</p>

		<table class="array">
			<tbody>
				<tr>
					<td>${H}$</td>
					<td>0</td>
					<td>1</td>
					<td>1</td>
					<td>1</td>
					<td>1</td>
					<td>0</td>
					<td>1</td>
					<td>1</td>
					<td>0</td>
					<td>1</td>
					<td>1</td>
					<td>1</td>
					<td>1</td>
				</tr>
				<tr>
					<td>${j}$</td>
					<td>0</td>
					<td>1</td>
					<td>2</td>
					<td>3</td>
					<td>4</td>
					<td>5</td>
					<td>6</td>
					<td>7</td>
					<td>8</td>
					<td>9</td>
					<td>10</td>
					<td>11</td>
					<td>12</td>
				</tr>
			</tbody>
		</table>

		<p>
			The remaining zero elements in the array ${H}$ indicate holes in the
			sequence. The array ${H}$ itself is more generally called a
			<span class="term">bitset</span>. In this case, we see that the
			missing elements are ${0,}$ ${5,}$ and ${8.}$ As we can see, this
			algorithm runs on linear time. All we must do is iterate through each
			of the elements in ${A,}$ then increment the corresponding element in
			${H.}$ Given ${n}$ elements, this has a time complexity of ${O(n).}$
			The implementation is straightforward:
		</p>
		<ol class="alg">
			<li>${f}$ findMissing(array A):</li>
			<ol>
				<li>let high = A.maxElement();</li>
				<li>let H = new Array[high];</li>
				<li>for (i = 0; i < H.length; i++):</li>
				<ol>
					<li>H[i] = 0;</li>
				</ol>
				<li>for (i = 0; i < A.length; i++):</li>
				<ol>
					<li>H[A[i]]++;</li>
				</ol>
				<li>for (i = 0; i < H.length; i++):</li>
				<ol>
					<li>if (H[i] = 0):</li>
					<ol>
						<li>print "Missing element is (i)";</li>
					</ol>
				</ol>
			</ol>
		</ol>
		<p>
			As an aside, the array ${H}$ is a very primitive example of a
			<i>hash table</i>. We will revisit hash tables in a later section,
			but it's worth mentioning this brief sighting as a precursor.
		</p>
		<p>
			Although the bitset is a clever approach to search-and-rescue, it is
			not without its costs. The primary concern for bitsets (and with hash
			tables as we'll see later), is the space complexity. Given an array
			whose
			<span class="underlineText">maximum element</span> is ${n,}$ the
			bitset requires a length of ${n + 1.}$ This means that if the array
			${A}$ contained the element ${1~000~000,}$ the bitset requires a
			length of ${1~000~001.}$ This is a large amount of memory.
		</p>
	</section>
</section>

<section id="uniquifying_algorithms">
	<h2>Duplicate Handling</h2>
	<p>
		Often, we want to eliminate, count, or store duplicate elements in a
		given sequence. When we eliminate duplicates in a given sequence, are
		performing a process called <span class="term">uniquifying</span> or
		<span class="term">deduplication</span>. Algorithms dedicated to
		accomplishing this task are called
		<span class="term">uniquifiers</span> (or <i>deduplicators</i>).
		Uniquifiers are part of a broader area called
		<span class="term">duplicate handling</span>. Duplicate handling itself
		is particularly important when it comes to databases. For example,
		ensuring that every user has a unique username or identification number
		requires duplicate handling.
	</p>
</section>

<section id="uniquifiers">
	<h2>Duplicate Spotters: Identifying Duplicates in a Sorted Sequence</h2>
	<p>
		The first step towards deduplication is to identify the duplicates.
		Algorithms that identify duplicates are called
		<span class="term">duplicate spotters</span>. Say we had the following
		array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>3</td>
				<td>6</td>
				<td>8</td>
				<td>8</td>
				<td>10</td>
				<td>12</td>
				<td>15</td>
				<td>15</td>
				<td>15</td>
				<td>20</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		Immediately, we see the following duplicates: ${8, 8, 15, 15, 15.}$ To
		find these duplicates, we scan through the list. Here, there are ${10}$
		elements, but this could be any number of ${n}$ elements. Starting at
		${i = 0,}$ we check if the element at that index, ${A_i}$ is the same
		as the element at ${i = 1,}$ the element ${A_{i+1}.}$ Since ${A_i}$ and
		${A_{i+1}}$ are not the same, we now check ${A_{i+1}}$ against
		${A_{i+2}.}$ Again, they aren't the same, so we check ${A_{i+2}}$
		against ${A_{i+3}.}$ Here we encounter our first duplicate, so we
		record the fact that the element at ${i = 2}$ is duplicated.
	</p>
	<p>
		We continue. Check ${A_{i+3}}$ against ${A_{i+4.}}$ No duplicate. Check
		${A_{i+4}}$ against ${A_{i+5}.}$ No duplicates. Check ${A_{i+5}}$
		against ${A_{i+6.}}$ Again no duplicates. Check ${A_{i+6}}$ against
		${A_{i+7.}}$ Now we have a duplicate, so we record the fact that the
		element at ${i=6}$ is duplicated. Checking ${A_{i+7}}$ against
		${A_{i+8,}}$ we have the same duplicate. Now we've arrived at a
		peculiar situation. Do we record the duplicate twice? No. We just want
		to know what the duplicate elements are. It would be confusing and
		unnecessary to duplicate the duplicates.
	</p>
	<p>
		One solution to this problem is to initialize a
		<span class="term">walker</span> &mdash; a variable that changes its
		value based on the current duplicate. The walker changes its value only
		if the duplicate changes. And only when the walker changes do we print
		its current value. The walker is initially zero. When we encounter the
		first duplicate, ${8,}$ the walker changes and prints its value, ${8.}$
		When we encounter the second duplicate, ${15,}$ the walker changes and
		prints its value, ${15.}$ Since the second duplicate at ${i = 8}$ the
		same duplicate, the walker doesn't change (and by contrapositive,
		doesn't print). Implementing this approach, we call the walker
		<var>lastDuplicate</var>:
	</p>

	<ol class="alg">
		<li>${f}$ findDuplicates(array A):</li>
		<ol>
			<li>let last_duplicate = 0;</li>
			<li>for (let i = 0; i < A.length; i++):</li>
			<ol>
				<li>if ((A[i] = A[i+1]) && (A[i] != last_duplicate)):</li>
				<ol>
					<li>print "Duplicate: |A[i]|";</li>
					<li>last_duplicate = A[i];</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		With this implementation, we're iterating over each element in the
		array ${A,}$ performing a comparison. This means that given ${n}$
		elements, this algorithm takes ${n}$ operations to execute. As such,
		the running time complexity is linear &mdash; ${O(n).}$
	</p>
	<p>
		<span class="topic">Useful Applications.</span> There are several
		useful applications for identifying duplicates:
	</p>
	<ul>
		<li>
			<b>Ensuring alternating values.</b> If we expect a given sequence to
			be ${\lang 1, 0, 1, 0, 1, \ldots \rang,}$ we can check the sequence
			follows the pattern by identifying any subsequence ${0,0}$ or
			${1,1.}$ One way to do so is by using a duplicate spotter.
		</li>
	</ul>
</section>

<section id="counting_duplicates">
	<h2>
		Duplicate Counters: Counting the Number of Duplicates in a Sorted
		Sequence
	</h2>
	<p>
		Determining the number of duplicates is critical for duplicate
		handling. Perhaps we only want to remove a certain number of
		duplicates. Perhaps our program has a particular threshold for the
		number of duplicates. A nightclub, for instance, might want to keep
		track of the ratio of female to male. After a certain amount of
		duplicates of the string property
		<var>"male"</var>, no further admissions are permitted for data with
		that property.
	</p>
	<p>
		Like the previous algorithm, we can count the number of duplicates in a
		sorted sequence through hashing. For example, say we had the following
		array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>3</td>
				<td>6</td>
				<td>8</td>
				<td>8</td>
				<td>10</td>
				<td>12</td>
				<td>15</td>
				<td>15</td>
				<td>15</td>
				<td>20</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		We see that the duplicated elements are ${8}$ and ${15.}$ The maximum
		element here is ${20,}$ so we need bitset of length ${21:}$
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
				<td>10</td>
				<td>11</td>
				<td>12</td>
				<td>13</td>
				<td>14</td>
				<td>15</td>
				<td>16</td>
				<td>17</td>
				<td>18</td>
				<td>19</td>
				<td>20</td>
			</tr>
		</tbody>
	</table>

	<p>
		Then, all we have to do is traverse the array ${A.}$ For each element
		${x}$ in ${A,}$ we increment the ${0}$ at the index in ${B}$ equal to
		${x.}$ This yields:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td class="beige">2</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">3</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
				<td>10</td>
				<td>11</td>
				<td>12</td>
				<td>13</td>
				<td>14</td>
				<td>15</td>
				<td>16</td>
				<td>17</td>
				<td>18</td>
				<td>19</td>
				<td>20</td>
			</tr>
		</tbody>
	</table>

	<p>
		With this approach, all we're doing is scanning through the array
		${A,}$ and incrementing each element in ${B}$ whose index equals the
		then-current element in ${A.}$ If the array contains ${n}$ elements,
		this algorithm takes ${n}$ comparisons to execute. As such, we have a
		time complexity of ${O(n).}$ This is linear time.
	</p>
	<p>Implementing this algorithm:</p>

	<ol class="alg">
		<li>${f}$ findDuplicates(array A):</li>
		<ol>
			<li>let length_of_A = A.length;</li>
			<li>let A_max_element = A[length_of_A];</li>
			<li>let B = new Array[A_max_element];</li>
			<li>for (i = 0; i < A_max_element; i++):</li>
			<ol>
				<li>B[i] = 0;</li>
			</ol>
			<li>for (i = 0; i < length_of_A; i++):</li>
			<ol>
				<li>B[A[i]]++;</li>
			</ol>
			<li>for (i = 0; i < A_max_element; i++):</li>
			<ol>
				<li>if (B[i] > 1):</li>
				<ol>
					<li>
						<span class="pop">Print "{i} has {B[i]-1} duplicates";</span>
						<div class="popText">
							<p>
								We use <var>B[i]-1</var> because the count includes the
								original.
							</p>
						</div>
					</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		Note that while there are multiple for-loops in this implementation,
		each loop simply takes ${n,}$ or some multiple of ${n,}$ operations to
		execute. Accordingly, the implementation above takes some ${k \cdot n}$
		operations to execute, where ${k}$ is some constant. Thus, our original
		analysis is unchanged: the algorithm has a running time complexity of
		${O(n).}$
	</p>
	<section id="finding_the_total_number_of_duplicates">
		<p>
			<span class="topic">Finding the Total Number of Duplicates.</span>
			With this implementation, counting the number of duplicate elements
			is trivial. If we wanted to find the total number of duplicate
			elements, we simply traverse the array ${B,}$ and summate the
			elements greater than ${1:}$
		</p>

		<ol class="alg">
			<li>${f}$ findDuplicates(array A):</li>
			<ol>
				<li>let total_duplicates = 0;</li>
				<li>let length_of_A = A.length;</li>
				<li>let A_max_element = A[length_of_A];</li>
				<li>let B = new Array[A_max_element];</li>
				<li>for (i = 0; i < A_max_element; i++):</li>
				<ol>
					<li>B[i] = 0;</li>
				</ol>
				<li>for (i = 0; i < length_of_A; i++):</li>
				<ol>
					<li>B[A[i]]++;</li>
				</ol>
				<li>for (i = 0; i < A_max_element; i++):</li>
				<ol>
					<li>if (B[i] > 1):</li>
					<ol>
						<li>total_duplicates += B[i];</li>
					</ol>
				</ol>
				<li>return total_duplicates;</li>
			</ol>
		</ol>

		<p>
			Again, this doesn't change our complexity analysis. The algorithm
			above still takes ${O(n)}$ time.
		</p>
	</section>
</section>

<section id="finding_duplicate_elements_in_an_unsorted_array">
	<h2>Duplicate Counter: Counting Duplicates in an Unsorted Sequence</h2>
	<p>
		The previous algorithm counted the number of duplicates in a sorted
		sequence. How might we count the number of duplicates in an
		<span class="underlineText">unsorted</span> sequence? Consider this
		unsorted array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>8</td>
				<td>3</td>
				<td>6</td>
				<td>4</td>
				<td>6</td>
				<td>5</td>
				<td>6</td>
				<td>8</td>
				<td>2</td>
				<td>7</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		Above, we see the duplicates are ${8}$ and ${6.}$ To count these
		duplicates, we use the following procedure:
	</p>
	<ol class="recipe">
		<li>
			Instantiate a variable called <var>count</var>. This variable will
			increment each time a duplicate is encountered.
		</li>
		<li>
			Instantiate two integer variables, ${i = 0}$ and ${j = i + 1.}$
		</li>
		<li>As long as ${i < j}$, perform the following:</li>
		<ol>
			<li>Compare ${A_i}$ against ${A_j:}$</li>
			<ol>
				<li>If ${A_i \neq A_j,}$ increment ${j.}$</li>
				<li>Otherwise (i.e., ${A_i}$ = ${A_j}$):</li>
				<ol>
					<li>Increment <var>count</var>.</li>
					<li>Replace ${A_j}$ with ${\texttt{-}1.}$</li>
					<li>Increment ${j.}$</li>
				</ol>
			</ol>
		</ol>
	</ol>
	<p>
		Notice that in step 3.1.2.2, we replace ${A_j}$ with ${\texttt{-}1.}$
		We use the value ${\texttt{-}1}$ to mark the duplicate element as
		accounted for. If we don't include this marking step, we would be
		duplicating our count. For example, when we reach the duplicate ${6,}$
		we would increment
		<var>count</var> after encountering the second ${6,}$ and increment
		again after encountering the third ${6.}$ When we reach the second
		${6,}$ we would increment <var>count</var> again when we encounter the
		third ${6,}$ even though we've already counted that ${6.}$ By replacing
		the values with ${\texttt{-}1,}$ we ensure that we don't count
		duplicates that have already been counted. Implementing this algorithm:
	</p>

	<ol class="alg">
		<li>${f}$ countDuplicates(array A):</li>
		<ol>
			<li>
				<span class="pop">let B = new Array[A.length];</span>
				<div class="popText">
					<p>
						Make a new array <var>B</var>. This will be a copy of
						<var>A</var>.
					</p>
				</div>
			</li>
			<li>
				<span class="pop">let count = 0;</span>
				<div class="popText">
					<p>
						Initialize the <var>count</var> variable. This will keep track
						of how many duplicates we encounter.
					</p>
				</div>
			</li>
			<li>
				<span class="pop">for (i = 0; i < B.size; i++): B[i] = A[i];</span>
				<div class="popText">
					<p>
						Make a copy of the array <var>A</var>; the elements of
						<var>A</var> are stored in <var>B</var>.
					</p>
				</div>
			</li>
			<li>
				<span class="pop">for (i = 0; i < A.length - 1; i++):</span>
				<div class="popText">
					<p>
						Now we iterate from ${0}$ to ${1}$ less than the length of
						<var>A</var>.
					</p>
				</div>
			</li>
			<ol>
				<li>
					<span class="pop">for (j = i + 1; i < A.length; j++):</span>
					<div class="popText">
						<p>
							Because we have to compare the current element against all
							other elements, we need a second for-loop. We use the
							variable
							<var>j</var> to track which of the other elements we're
							considering.
						</p>
					</div>
				</li>
				<ol>
					<li>
						<span class="pop">if (A[i] == A[j]):</span>
						<div class="popText">
							<p>
								If the current element is the same as the other element, we
								increment <var>count</var> and change the element at
								<var>B[j]</var> to ${\texttt{-}1.}$
							</p>
						</div>
					</li>
					<ol>
						<li>count++;</li>
						<li>B[j] = -1</li>
					</ol>
				</ol>
				<li>
					<span class="pop">if (count > 0):</span>
					<div class="popText">
						<p>
							If <var>count</var> is greater than ${0,}$ indicate that
							there are duplicates.
						</p>
					</div>
				</li>
				<ol>
					<li>print "Element {A[i]} is duplicated {count} times"</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		The time complexity for this algorithm is ${O(n^2).}$ Because we start
		by comparing the first element against all the others in an array of
		${n}$ elements, the algorithm performs ${n - 1}$ comparisons at first.
		After comparing the first element against the others, the algorithm
		moves to the second. This yields ${n - 2}$ comparisons. After the
		second, the algorithm moves to the third, performing ${n - 3}$
		comparisons. The pattern:
	</p>
	<figure>
		<div>
			<p>
				${\large \lang n-1,~n-2,~n-3,~n-4,~n-5,~\ldots,~3,~2,~1 \rang}$
			</p>
		</div>
	</figure>
	<p>The sum of this sequence:</p>
	<figure>
		<div>
			$$ \begin{aligned} \sum\limits_{k = 1}^{n - 1} &= (n - 1) + (n - 2) +
			\ldots + 3 + 2 + 1 \\[1em] &= 1 + 2 + 3 + \ldots + (n - 2) + (n - 1)
			\\[1em] &= \dfrac{n(n-1)}{2} \\[1em] &= \dfrac{n^2 - n}{2}
			\end{aligned} $$
		</div>
	</figure>
	<p>
		Thus, the running time function of this algorithm is ${f(n) =
		\dfrac{n^2 - n}{2}.}$ Applying asymptotic analysis, we see that this
		algorithm runs on quadratic time &mdash; ${O(n^2).}$
	</p>
	<p>
		Alternatively, we can use a bitset, just as we did with the sorted
		sequences. Using the same unsorted array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>8</td>
				<td>3</td>
				<td>6</td>
				<td>4</td>
				<td>6</td>
				<td>5</td>
				<td>6</td>
				<td>8</td>
				<td>2</td>
				<td>7</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		We create a bit set with a size equal to the largest element of ${A}$
		plus one. In this case, that element is ${8,}$ so we need bitset of
		size ${9:}$
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
			</tr>
		</tbody>
	</table>

	<p>
		The procedure is the same as we saw previously for sorted sequences. We
		iterate through the array ${A,}$ and for each element ${x}$ in ${A,}$
		we increment the ${0}$ at the index ${j = x.}$ This results in:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
				<td class="beige">1</td>
				<td class="beige">1</td>
				<td class="beige">1</td>
				<td class="beige">3</td>
				<td class="beige">1</td>
				<td class="beige">2</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
			</tr>
		</tbody>
	</table>

	<p>
		The implementation for this approach is the same as we saw earlier:
	</p>

	<ol class="alg">
		<li>${f}$ findDuplicates(array A):</li>
		<ol>
			<li>let length_of_A = A.length;</li>
			<li>let A_max_element = A[length_of_A];</li>
			<li>let B = new Array[A_max_element];</li>
			<li>for (i = 0; i < A_max_element; i++):</li>
			<ol>
				<li>B[i] = 0;</li>
			</ol>
			<li>for (i = 0; i < length_of_A; i++):</li>
			<ol>
				<li>B[A[i]]++;</li>
			</ol>
			<li>for (i = 0; i < A_max_element; i++):</li>
			<ol>
				<li>if (B[i] > 1):</li>
				<ol>
					<li>Print "{i} has {B[i]-1} duplicates";</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		Compared to the previous approach, all that's required for this
		algorithm is to iterate through ${n}$ elements and incrementing the
		element at the corresponding index in the bitset. Hence, this algorithm
		has a time complexity of ${O(n).}$ This is linear time, a faster
		approach compared with the quadratic time for the previous algorithm.
	</p>
</section>

<section id="pair_to_sum_unsorted">
	<h2>Pair to Sum: Unsorted Arrays</h2>
	<p>Consider the following problem:</p>
	<figure>
		<div class="rule">
			<p>
				Given an array of ${n}$ integers and an integer ${k,}$ find all
				pairs ${(a, b)}$ in the array such that ${a + b = k.}$
			</p>
		</div>
	</figure>
	<p>
		The brute-force approach to solving this algorithm is to iterate
		through each of the elements. For example, consider the following
		array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>6</td>
				<td>3</td>
				<td>8</td>
				<td>10</td>
				<td>16</td>
				<td>7</td>
				<td>5</td>
				<td>2</td>
				<td>9</td>
				<td>14</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		Suppose ${k = 10.}$ Just looking at the array, we see that there is, in
		fact, a pair ${(a, b)}$ such that ${a + b = 10.}$ In this case, ${a =
		3}$ and ${b = 7.}$ With the brute force approach, we employ the
		following algorithm:
	</p>
	<figure>
		<ol class="recipe">
			<li>Suppose ${k}$ is the sum.</li>
			<li>For ${i = 0, 1, 2, 3, \ldots, n-1}$ perform the following:</li>
			<ol>
				<li>Let ${d = k - A_i.}$</li>
				<li>Let ${j = i + 1.}$</li>
				<li>For ${j = 1, 2, 3, \ldots, n,}$ perform the following:</li>
				<ol>
					<li>If ${A_j = d,}$ print ${(A_i, A_j).}$</li>
					<li>Otherwise, increment ${j}$ and return to step 2.3.</li>
				</ol>
			</ol>
		</ol>
	</figure>
	<p>Implementing this algorithm:</p>

	<ol class="alg">
		<li>${f}$ sumPairFinder(array A, sum):</li>
		<ol>
			<li>for (i = 0; i < A.length - 1; i++):</li>
			<li>let d = sum - A[i];</li>
			<ol>
				<li>for (j = i + 1; j < A.length; i++):</li>
				<ol>
					<li>if (A[j] = d): print "Pair: A[i] + A[j] = k";</li>
				</ol>
			</ol>
		</ol>
	</ol>

	<p>
		Like one of our previous duplicate counters, this algorithm relies on a
		nested for-loop to find a pair. Hence, given an array of ${n}$
		elements, this algorithm has a running time complexity of ${O(n^2).}$
		Note, however, that this algorithm only works if the array contains no
		duplicates. If the array contains duplicates, then we must use one of
		the duplicate spotters and remove the duplicate elements before
		employing this approach.
	</p>
	<p>
		Alternatively, we can use a bitset to find the pair ${(a, b).}$ Using
		the same unsorted array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>6</td>
				<td>3</td>
				<td>8</td>
				<td>10</td>
				<td>16</td>
				<td>7</td>
				<td>5</td>
				<td>2</td>
				<td>9</td>
				<td>14</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		We see that the largest element is ${16,}$ so we need a bit set of size
		${17:}$
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
				<td>10</td>
				<td>11</td>
				<td>12</td>
				<td>13</td>
				<td>14</td>
				<td>15</td>
				<td>16</td>
			</tr>
		</tbody>
	</table>

	<p>
		Now, rather than simply iterating over ${A}$ and incrementing the
		corresponding ${0}$ in ${B,}$ the algorithm performs the following:
	</p>
	<ol class="recipe">
		<li>Iterate through ${A:}$</li>
		<ol>
			<li>Compute the difference ${d = k - A_i.}$</li>
			<li>
				Check if the element ${B_d \neq 0.}$ If it is, return ${B_d}$ and
				${A_i.}$
			</li>
			<li>Increment element ${B_j}$ where ${j = A_i.}$</li>
		</ol>
	</ol>
	<p>
		The final step, checking if ${B_d > 0,}$ is how we determine if the
		other term, ${b,}$ is present in the array. By the time we reach the
		element ${7}$ and increment ${B_7,}$ the bitset looks like:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${B}$</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
				<td class="beige">1</td>
				<td class="beige">1</td>
				<td>0</td>
				<td class="beige">1</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td>0</td>
				<td class="beige">1</td>
			</tr>
			<tr>
				<td>${j}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
				<td>10</td>
				<td>11</td>
				<td>12</td>
				<td>13</td>
				<td>14</td>
				<td>15</td>
				<td>16</td>
			</tr>
		</tbody>
	</table>

	<p>
		And at this point, ${d = 3.}$ Checking if ${B_3}$ is greater than zero,
		we see that it's true, and we have our first pair, ${(7, 3).}$ When we
		get to ${A_7,}$ we see that ${B_8 > 0,}$ and we find the second pair,
		${(2, 8).}$ Implementing this algorithm:
	</p>

	<ol class="alg">
		<li>${f}$ pairSumFinder(array A, k):</li>
		<ol>
			<li>let B = new array[A.length];</li>
			<li>for (i = 0; i < B.length; i++):</li>
			<ol>
				<li>B[i] = 0;</li>
			</ol>
			<li>for (i = 0; i < A.length; i++):</li>
			<ol>
				<li>let d = k - A[i];</li>
				<li>if (B[d] != 0): print "Pair: A[i] + A[j] = k"</li>
				<li>B[A[i]]++;</li>
			</ol>
		</ol>
	</ol>

	<p>
		As we know from hashing, this algorithm requires iterating through each
		of the elements in ${n,}$ and the operations at each iteration run in
		constant time. Accordingly, this approach has a time complexity of
		${O(n)}$ &mdash; linear time, which is better than our previous
		approach running on quadratic time.
	</p>
</section>

<section id="pair_to_sum_sorted">
	<h2>Pair to Sum: Sorted Arrays</h2>
	<p>
		The algorithms above found pairs in unsorted sequences. What about
		sorted sequences? For example, suppose we were asked to find the pairs
		in this sorted sequence:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>1</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>8</td>
				<td>9</td>
				<td>10</td>
				<td>12</td>
				<td>14</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		Looking at this array, we see two pairs: ${(1, 9)}$ and ${(4, 6).}$
		Because all of the elements are sorted in ascending order, we have the
		smaller elements to the left and the larger elements to the right. From
		real analysis, we know that given a pair of real numbers ${(a, b),}$
		there are only two possibilities &mdash; (1) either ${a = b,}$ or (2)
		one of the elements is smaller than the other. Because there are only
		two possibilities, and the fact that the array is already sorted, we
		can search for an ${a}$ and a ${b}$ such that ${a + b = k,}$ from
		<span class="underlineText">both sides</span> of the array.
	</p>
	<p>Applying these facts, the algorithm proceeds as such:</p>
	<figure>
		<ol class="recipe">
			<li>
				Create a variable ${i.}$ Starting at the first index of ${A,}$
				${i}$ will be incremented (if necessary) until it reaches ${i =
				\text{ A's length}.}$
			</li>
			<li>
				Create a variable ${j.}$ Starting at the last index of ${A,}$ ${j}$
				will be decremented (if necessary) until it reaches ${j = 0.}$
			</li>
			<li>As long as ${i \neq j:}$</li>
			<ol>
				<li>If ${A_i + A_j = k:}$</li>
				<ol>
					<li>Return ${A_i}$ and ${A_j.}$ These are pairs.</li>
					<li>Increment ${i}$ and decrement ${j.}$</li>
				</ol>
				<li>Otherwise:</li>
				<ol>
					<li>If ${A_i + A_j < k,}$ increment ${i.}$</li>
					<li>Else, decrement ${j.}$</li>
				</ol>
			</ol>
		</ol>
	</figure>
	<p>Implementing the algorithm in pseudocode:</p>

	<ol class="alg">
		<li>${f}$ findPairInSorted(array A, k):</li>
		<ol>
			<li>int i = 0;</li>
			<li>int j = A.length;</li>
			<li>while (i &NotEqual; j):</li>
			<ol>
				<li>if (A[i] + A[j] = k):</li>
				<ol>
					<li>print "Pairs: A[i] + A[j] = k";</li>
					<li>i++, j--;</li>
				</ol>
				<li>else if (A[i] + A[j] < k): i++;</li>
				<li>else: j--</li>
			</ol>
		</ol>
	</ol>

	<p>
		Examining the code above, this algorithm only requires iterating
		through the array ${A.}$ The operations inside the while-loop's body
		run in constant time, so this algorithm has a time complexity of
		${O(n).}$
	</p>
</section>

<section id="finding_both_min_and_max">
	<h2>Finding a Minimum and a Maximum in a Single Scan</h2>
	<p>
		With the algorithm's we've seen so far, we likely noticed how useful it
		is to know what the maximum and minimum elements are for an unsorted
		sequence. Rather than calling two separate functions that find the
		minimum and maximum respectively, we can write a single function that
		returns both. For example, say we had the following unsorted array:
	</p>

	<table class="array">
		<tbody>
			<tr>
				<td>${A}$</td>
				<td>5</td>
				<td>8</td>
				<td>3</td>
				<td>9</td>
				<td>6</td>
				<td>2</td>
				<td>10</td>
				<td>7</td>
				<td>-1</td>
				<td>4</td>
			</tr>
			<tr>
				<td>${i}$</td>
				<td>0</td>
				<td>1</td>
				<td>2</td>
				<td>3</td>
				<td>4</td>
				<td>5</td>
				<td>6</td>
				<td>7</td>
				<td>8</td>
				<td>9</td>
			</tr>
		</tbody>
	</table>

	<p>
		We see that the maximum in this array is ${10,}$ and the minimum is
		${-1.}$ The trick to finding these elements is to first instantiate two
		variables,
		<var>min</var> and <var>max</var>. Initially, the both of these
		variables are assigned the first element in the array. In this case,
		${5:}$
	</p>
	<figure>
		<div>
			<p><var>min = A[0]</var></p>
			<p><var>max = A[0]</var></p>
		</div>
	</figure>
	<p>
		Then, we begin iterating, from <var>i = 0</var> to
		<var>i = ${\text{length of \texttt{A}},}$</var>
		performing the following:
	</p>
	<figure>
		<ol class="recipe">
			<li>
				Is <var>A[i]</var> less than <var>min</var>? If it is, change the
				value of <var>min</var> to <var>A[i]</var> and go to step 3.
				Otherwise, ask the next question.
			</li>
			<li>
				Is <var>A[i]</var> greater than <var>max</var>? If it is, change
				the value of <var>max</var>. Otherwise, go to step 3.
			</li>
			<li>
				If <var>i</var> is less than the length of <var>A</var> increment
				<var>i</var> and return to step 1.
			</li>
			<li>
				Otherwise, return
				<var>min</var> and <var>max</var>.
			</li>
		</ol>
	</figure>
	<p>Implementing this algorithm:</p>

	<ol class="alg">
		<li>${f}$ findMinMax(array A):</li>
		<ol>
			<li>let min = A[0];</li>
			<li>let max = A[0];</li>
			<li>for (i = 0; i < A.length; i++):</li>
			<ol>
				<li>if (A[i] < min): min = A[i];</li>
				<li>else if (A[i] > max): max = A[i];</li>
			</ol>
			<li>return (min, max);</li>
		</ol>
	</ol>

	<p>
		With this algorithm, all we are doing is iterating over ${n}$ elements.
		The comparison operators run in constant time, so they do not impact
		our analysis. Hence, this algorithm has runs on linear time: ${O(n).}$
	</p>
	<p>
		As an aside, it's worth considering how many comparisons are made. In
		the best-case scenario, the array <var>A</var> is sorted in ascending
		order. In that scenario, the <var>if</var> block alone is executed.
		Given that we're comparing against every element other than the first,
		we have a total of ${n - 1}$ comparisons. In the worst-case scenario,
		the array <var>A</var> is sorted in descending order. There, the the
		<var>if</var> block is executed
		<span class="underlineText">and</span> the <var>else if</var> block is
		executed. This yields ${2(n-1)}$ comparisons. Applying asymptotic
		analysis, the best-case and the worst-case scenarios are the same
		&mdash; we end up with linear time, either or.
	</p>
	<p>
		The more important point, however, is that there's distinction between
		an algorithm's cases and the algorithm's time complexities. The
		<i>worst case</i> for this algorithm is if the array is in descending
		order, and the <i>best case</i> for this algorithm is if the array is
		in ascending order. Being aware of this difference goes a long way.
		There are situations where the time complexity is less important than
		the algorithm's cases. The algorithm might have the same time
		complexity across all cases, but the worst case specifically occurs far
		more often. Knowing this fact can impact other aspects of the
		algorithm's assessment, whether that's space complexity, readability,
		heuristics, etc.
	</p>
</section>

<section id="array_addressing">
	<h2>Array Addressing</h2>
	<p>
		Whenever we write expressions that index into an array, e.g.,
		<var>A[2] = 4</var>, the compiler must translate the expression into an
		address. Because arrays are a fundamental data structure, it's worth
		knowing how this translation is done. Put simply, the compiler makes
		performs this translation by applying a particular formula. For
		example, suppose we initialized the following array:
	</p>
	<pre class="language-c"><code>
    int main() {
      int A[3] = {8, 3, 5};
      return 0;
    }
  </code></pre>
	<p>
		As we know, the identifier <var>A</var> is an identifier for array's
		base address &mdash; the address of <var>A[0]</var>. Suppose the
		address of <var>A[0]</var> is <var>200</var>. This means that the
		address of <var>A[1]</var> is <var>204</var> (since an
		<var>int</var> takes 4 bytes), an the address of <var>A[2]</var> is
		<var>208</var>. Abstracting this computation, we can think of the
		compiler performing the following when it encounters <var>A[2]</var>:
	</p>
	<figure class="math-display">
		<div>
			$$ \begin{aligned} \textit{address-of}(A[2])&=
			\textit{address-of}(A[0]) + (2)(4) \\ &= 200 + 8 \\ &= 209
			\end{aligned} $$
		</div>
	</figure>
	<p>We can abstract this computation into a formula:</p>
	<figure class="math-display">
		<div>
			<p>${\alpha(a_i) = \alpha(a_0) + i \omega}$</p>
		</div>
	</figure>
	<p>
		In the formula above, ${\alpha(n)}$ is a function that returns the
		memory address of some data ${n}$. Thus, ${\alpha(a_i)}$ returns the
		address of the ${i^{\text{\scriptsize{th}}}}$ element of the array, and
		${\alpha(a_0)}$ returns the address of the first element. The variable
		${i}$ represents the index of the element, and the variable ${\omega}$
		represents the size of the data type (e.g., the size of the data type
		<var>int</var> is 4 bytes).
	</p>
	<p>
		As an aside, many older languages like Fortran use 1-based indexing. C
		came after Fortran, so why do so many languages use 0-based indexing?
		One reason is because of the hardware limitations at the time languages
		like C, BCPL, and Fortran were implemented. With 1-based indexing, we
		would have to use a different formula in determining the address of a
		given element:
	</p>
	<figure class="math-display">
		<div>
			<p>${\alpha(a_i) = \alpha(a_1) + (i-1)\omega}$</p>
		</div>
	</figure>
	<p>
		There's an additional computation with this formula &mdash; a
		decrement. This additional operation proves to be costly on older
		machines &mdash; there are 3 separate computations. Compare that with
		the previous formula, which calls for only 2 computations. Given that a
		core goal of C's design was efficiency, it made sense to opt for the
		more efficient implementation.
	</p>
	<p>
		Of course, modern computers have surpassed many of these limitations.
		The additional decrementing operation doesn't make much of a difference
		for most applications. So why then do recent languages go with
		zero-based indexing? Because zero-based indexing has become the norm. C
		inspired a whole host of languages (e.g., C++ and Objective-C), which
		in turn inspired many others (e.g., C to C++ to Java to Kotlin, C to
		Objective-C to Swift). Given that language designers are programmers
		first and foremost, it isn't all that surprising to see a designer
		sticking with what they're familiar with.
	</p>
	<p>
		Moreover, if often makes more sense to use zero-based indexing over
		one-based indexing. We can appreciate this idea by recognizing that
		<i>indexing</i> is <span class="underlineText">not</span> the same as
		<i>counting</i>. Instead, indexing is much more akin to
		<i>offsetting</i> from a given point. For example, given the array
		<var>int A[3] = {1, 2, 3}</var>, the starting point is <var>1</var>. If
		we designate that as the element with index 0 (<var>A[0]</var>, the
		first element), then the second element, <var>A[1]</var>, is the
		element 1-off the first element. The third element, <var>A[2]</var>, is
		2-off the first element. And so on and so forth.
	</p>
</section>

<script src="https://d3js.org/d3.v7.min.js"></script>
<script type="module" src="../../../static/numerc/csmd.mjs"></script>
<script
	type="module"
	src="../../../static/numerc/scripts/cpp_dynamicArrays.js"
></script>

{% endblock %}
