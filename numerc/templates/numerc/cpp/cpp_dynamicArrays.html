{% extends '../layout.html' %} {% load static %} {% block description %}
<meta name="description" content="Dynamic arrays, sets, and sequences." />
{% endblock %} {% block title %}
<title>Sequences</title>
{% endblock %} {% block content %}

<h1>Arrays</h1>
<section id="intro">
	<p>
		<span class="drop">T</span>he first set of abstract data types we explore is
		the <span class="term">sequence</span>. Sequences allow us to store ${n}$
		things in a specific order. Those things could be strings, integers,
		floating point values, or even other abstract data type objects.
	</p>
	<p>
		The sequence data type consists of two subtypes: (a) the
		<span class="term">tuple</span
		><label for="tuple" class="margin-toggle"><sup></sup></label>
		<input type="checkbox" id="tuple" class="margin-toggle sidenote-number" />
		<span class="marginnote"
			>The tuple is also called a
			<span class="italicsText">static sequence</span>.</span
		>
		and (b) the <span class="term">list</span>.<label
			for="list"
			class="margin-toggle"
			><sup></sup
		></label>
		<input type="checkbox" id="list" class="margin-toggle sidenote-number" />
		<span class="marginnote"
			>The list data type is also called a
			<span class="italicsText">vector</span> or
			<span class="italicsText">dynamic sequence</span>.</span
		>
		The tuple type is a sequence with a fixed size. I.e., the number of elements
		in the sequence does not change. The list type is a sequence with a dynamic
		size; the sequence can grow or shrink through the insertion, shifting, or
		removing of elements in the sequence.
	</p>
</section>

<section id="static_lists">
	<h2>Static Arrays</h2>
	<p>
		We turn our attention first to the tuple. Because tuples are of fixed size,
		whenever we talk about tuples, we talk about some ${n-}$tuple. For example,
		2-tuple is could a <span class="italicsText">double</span>. A 3-tuple is
		called a <span class="italicsText">triple</span>. A 4-tuple is a
		<span class="italicsText">quadruple</span>, and so on. Because tuples are of
		fixed size, they necessarily have a smaller API.
	</p>
	<p>
		Examining these data and properties, we proceed to examining implementation
		approaches. The first implementation approach we consider is the
		<span class="italicsText">static array</span>. While the static array is the
		simplest of all data structures, it is one of the most important. Numerous
		data structures depend on arrays, so we spend a considerable amount of time
		exploring them in depth.
	</p>
	<p>
		<span class="topic">Printing an Array.</span>
		First, the <span class="monoText">print()</span> operation. To print a
		tuple, we must iterate over each of the tuple's element, displaying each
		element to the console (i.e., with something lik
		<span class="monoText">cout</span> or <span class="monoText">printf</span>).
		Because we're iterating over each element, the
		<span class="monoText">print()</span> operation has a time complexity of
		${O(n)}$ given the ${n-}$tuple. This is linear time.
	</p>
	<p>
		<span class="topic">Appending an Element to an Array.</span> Second, the
		<span class="monoText">append(${x}$)</span> operation, where ${x}$ is an
		element. To append an element ${x,}$ we insert the element ${x}$ at the very
		end of the tuple. In other words, &#8220;Insert this element ${x}$ at the
		first instance of free space.&#8221; Thus, given an array of length 10 and
		size 5, <span class="monoText">append(${x}$)</span> inserts the element
		${x}$ at ${i = 6.}$ For <span class="monoText">append(${x}$)</span>, we can
		think of this as performing three distinct operations &mdash; accessing the
		array at ${i = \textit{length},}$ assigning the element ${x}$ to that
		particular index, and updating the ${\textit{length}}$ property. Hence,
		${O(3).}$ Applying complexity analysis, this is really ${f(n) = 3.}$
		Rewriting this as ${f(n) = 3n^0,}$ we have ${O(n^0),}$ which reduces to
		${O(1).}$ I.e., constant time.
	</p>
	<p>
		<span class="topic">Inserting an Element to an Array.</span> With the
		<span class="monoText">insert(${i}$, ${x}$)</span> operation, we're
		inserting an element ${x}$ at the index ${i.}$ For example, suppose we have
		the tuple ${(0, 1, 2, 3, 4, \_, \_, \_).}$ This is a tuple of size 8, with
		length 5. If we write <span class="monoText">insert(${2}$, ${9}$)</span>, we
		would have the tuple ${(0, 9, 1, 2, 3, 4, \_, \_).}$ Notice that this causes
		a shift. To perform this shift, have to use a loop. In pseudocode:
	</p>
	<figure class="math-display">
		<div>
			<pre class="language-pseudo"><code>
				insert(index, x) {
					for (i = length; i > index, i--) {
						A[i] = A[i - 1];
					}
					A[index] = x;
					length++;
				}
			</code></pre>
		</div>
	</figure>
	<p>
		The operation of inserting an element into a tuple provides an opportunity
		to examine the different forms of complexity analysis. If we insert the
		element at the very end of the tuple &mdash;
		<span class="monoText">insert(${length}$, ${x}$)</span> &mdash; no shifting
		occurs. Accordingly, this operation has a time complexity of order ${O(1),}$
		constant time. However, if we insert the element at the very beginning
		&mdash; <span class="monoText">insert(${0}$, ${x}$)</span> &mdash; then we
		must shift <span class="underlineText">all</span> the elements. Given a
		tuple of length ${n,}$ this operation would require iterating over all ${n}$
		elements. This operation's time complexity is of order ${O(n).}$
	</p>
	<p>
		Examining these possibilities, we have a best-case scenario and a worst-case
		scenario. The best-case scenario is ${\Omega(1),}$ constant time, which
		occurs only if we insert at the very end. The worst-case scenario is
		${O(n),}$ linear time, which occurs if we insert at the origin, ${i = 0.}$
	</p>
	<p>
		<span class="topic">Deleting an Element from an Array.</span> The operation
		<span class="monoText">deleteElementAt(${i}$)</span> deletes, or removes, an
		element at the index ${i.}$ Suppose we have the array ${(1, 5, 8, 3, 2, \_,
		\_, \_).}$ In this example, there are three cases for deletion:
		<span class="monoText">deleteElementAt(${0}$)</span>,
		<span class="monoText">deleteElementAt(${\textit{length}}$)</span>, and
		<span class="monoText">deleteElementAt(${n}$)</span>, where ${0 < n <
		\textit{length}.}$ The two problematic cases are the first and the third.
		They are problematic because if we delete an element other than the last,
		then we would have gaps in the array:
	</p>
	<figure class="math-display">
		<div>
			<p>
				<span class="monoText">deleteElementAt(0)</span> ${ \implies (\_, 5, 8,
				3, 2, \_, \_, \_)}$
			</p>
			<p>
				<span class="monoText">deleteElementAt(3)</span> ${ \implies (0, 5, 8,
				\_, 2, \_, \_, \_)}$
			</p>
		</div>
	</figure>
	<p>
		These gaps lead to all sorts of problems, particularly with respect to
		iteration. One way to avoid these problems is to manually check if a given
		index has an element. This is not a good approach. The better approach is to
		get right to the root of the problem &mdash; &#8220;holes&#8221; in the
		array. We can prevent these holes by shifting elements to the right whenever
		one of the two cases above occurs. Thus:
	</p>
	<figure class="math-display">
		<div>
			<p>
				<span class="monoText">deleteElementAt(3)</span> ${ \implies (0, 5, 8,
				\_, 2, \_, \_, \_) \implies (0, 5, 8, 2, \_, \_, \_, \_)}$
			</p>
		</div>
	</figure>
	<p>
		To understand how to perform this shifting, we consider the example
		<span class="monoText">deleteElementAt(3)</span>. Here, ${i = 3.}$ So, we
		start by removing the element at ${i = 3,}$ then shift the element at ${i +
		1}$ to ${i = 3.}$ This creates a hole at ${i = 4,}$ so we set ${i = 4,}$
		then shift the element at ${i + 1}$ to ${i = 4.}$ This creates a hole at ${i
		= 5,}$ so we shift the element at ${i + 1}$ to ${i = 6,}$ and so on, up
		until we reach the value of ${i = \textit{length} - 1}$ (the second to last
		element). In pseudocode:
	</p>
	<figure class="math-display">
		<div>
			<pre class="language-pseudo"><code>
				deleteElementAt(index):
					element = A[index];
					for (i = index; i < array.length - 1; i++):
						A[i] = A[i + 1];
					length--;
			</code></pre>
		</div>
	</figure>
	<p>
		The time complexity for this algorithm depends on the value of
		<span class="monoText">index</span>. If
		<span class="monoText">index = length</span>, then no shifting occurs, in
		which case we only have to perform two operations: Initializing
		<span class="monoText">element</span> and decrementing
		<span class="monoText">length</span>. This yields a complexity of ${O(2),}$
		or simply ${O(1)}$ &mdash; constant time.
	</p>
	<p>
		If, however, <span class="monoText">index = 0</span>, then we have to
		perform ${n}$ shifts. This yields ${O(n + 2),}$ or ${O(n).}$ This is linear
		time. Accordingly, deleting an element from a array, in the best case
		scenario, is ${\Omega(1),}$ and in the worst case scenario, ${O(n).}$
	</p>

	<section id="searching_an_array">
		<h3>Searching an Array</h3>
		<p>
			Searching for a particular element ${x}$ in a array depends on the search
			algorithm employed. There are two algorithms available: (1)
			<span class="italicsText">linear search</span> and (2)
			<span class="italicsText">binary search</span>. We consider linear search
			first.
		</p>

		<section id="linear_search">
			<h4>Linear Search</h4>
			<p>
				Under
				<span class="term">linear search</span>, we iterate over each of the
				array's elements, checking if the element matches our query. Say we had
				the following array:
			</p>
			<figure class="math-display">
				<div>
					<p>${A = (8, 9, 4, 7, 6, 5, 10, 2, 11)}$</p>
				</div>
			</figure>
			<p>
				With the linear search approach, we go through each of the elements of
				${A,}$ checking if the element matches the key. Suppose the key is the
				integer ${5.}$ We start with ${A[0],}$ and ask, &#8220;${A[0] =
				5?}$&#8221; False. So we continue to ${A[1].}$ Again we ask,
				&#8220;${A[1] = 5?}$&#8221; False again. So we go to ${A[2].}$ We
				continue all the way up to ${A[5],}$ wherein ${A[5] = 5}$ is true.
				Because our key was found, we say that the search was
				<span class="italicsText">successful.</span>
			</p>
			<p>
				Now, what if the key was the integer ${22?}$ In that case, we go all the
				way up to ${A[\textit{length}],}$ or ${A[8],}$ to determine that ${22}$
				is not in the array. This is an example of an
				<span class="italicsText">unsuccessful search</span>.
			</p>
			<p>
				Implementing linear search is straightforward. We are simply traversing
				the array. We start with ${A[0],}$ then continue to the last element of
				the list, ${A[\textit{length}].}$
			</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
					arrayLinearSearch(x) {
						for (i = 0; i < length; i++) {
							if (key == A[i]){
								return i;
							}
						}
						return -1;
					}
				</code></pre>
				</div>
			</figure>
			<p>
				What is the time complexity for linear search? Well, in the worst-case
				scenario, the array does not contain our key. In which case we would
				have to perform the comparison operation
				<span class="monoText">key == A[i]</span> on all the array's elements.
				Thus, given an ${n-}$array not containing our key, we have time
				complexity of order ${O(n).}$ This is linear time.
			</p>
			<p>
				In the best-case scenario, ${A[0]}$ is our key, in which case only one
				comparision operation is performed. Accordingly, in the best-case
				scenario, linear search has a time complexity of order ${\Omega(1)}$
				&mdash; constant time.
			</p>
			<p>
				What about the average-case scenario? To determine the average-case
				scenario, we ask, how many comparisons are needed to determine whether
				${i = 1}$ matches our key? We must perform 1 comparison. We again ask,
				how many comparisons are needed to determine whether the element at ${i
				= 2}$ matches our key? We must perform 2 comparisons. We ask the same
				question for ${i = 3,}$ ${i = 4,}$ ${i = 5,}$ and so on. The sum of
				comparisons is the sum of arithmetic sequence of the positive integers:
			</p>
			<figure class="math-display">
				<div>
					<p>${1 + 2 + 3 + \ldots + n = \dfrac{n(n + 1)}{2}}$</p>
				</div>
			</figure>
			<p>
				Thus, the total amount of time for all possible cases is
				${\dfrac{n(n+1)}{2}.}$ Dividing this by the total number of cases,
				${n,}$ provides us with the average case:
			</p>
			<figure class="math-display">
				<div>
					$$ \begin{aligned} \dfrac{ \dfrac{n(n + 1)}{2} }{n} &= \dfrac{
					\dfrac{\cancel{n}(n + 1)}{2} }{\cancel{n}} \\[1.2em] &= \dfrac{n +
					1}{2} \end{aligned} $$
				</div>
			</figure>
			<p>
				Hence, in the average-case scenario, linear search has a complexity of
				${\Theta\left(\dfrac{n+1}{2}\right).}$ Or, asymptotically,
				${\Theta(n).}$ Notice that both the average-case runtime and the
				worst-case runtime are the same. With linear search, we're almost always
				running on linear time. We can, however, optimize the linear search
				algorithm.
			</p>
			<p>
				<span class="topic">Transposition.</span> The first method to improving
				linear search is with <span class="term">transposition</span>. The idea
				behind transposition is best understood via analogy. Suppose you're
				conducting research, and you know there's a particular book relevant to
				a topic. You proceed to the shelf and retrieve the book. Instead of
				returning the book to the original place, you might leave the book on a
				particular table, or place it somewhere closer to your work space. Why?
				Because there's a high likelihood of you needing to use the same book
				again.
			</p>
			<p>
				This same idea extends to linear search. In search for some key ${k,}$
				there's a likelihood of searching for ${k}$ again, so we bring it closer
				to ${i = 0.}$ For example, say we have the array:
			</p>
			<figure class="math-display">
				<div>
					<p>${T = (8, 9, 4, 6, 7, 3, 2, 11)}$</p>
				</div>
			</figure>
			<p>
				and our key is ${6.}$ A linear search for 6 returns a successful search,
				so we swap 6 and 4 (swap ${T[3]}$ and ${T[2]}$):
			</p>
			<figure class="math-display">
				<div>
					<p>${T = (8, 9, 6, 4, 7, 3, 2, 11)}$</p>
				</div>
			</figure>
			<p>Search for 3 again, and we swap ${T[1]}$ and ${T[2]}$:</p>
			<figure class="math-display">
				<div>
					<p>${T = (8, 6, 9, 4, 7, 3, 2, 11)}$</p>
				</div>
			</figure>
			<p>Search 3 one more time, and we swap ${T[1]}$ and ${T[0]}$:</p>
			<figure class="math-display">
				<div>
					<p>${T = (6, 8, 9, 4, 7, 3, 2, 11)}$</p>
				</div>
			</figure>
			<p>
				Notice that 6 is now at the head of the array. Now whenever we search
				for ${6,}$ we have a runtime of ${O(1)}$ &mdash; constant time. Of
				course, 6 will only get to the array's head if we search for it enough
				times.
			</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
					arrayLinearSearch(x) {
						for (i = 0; i < length; i++) {
							if (key == T[i]){
								swap(T[i], T[i-1])
								return i - 1;
							}
						}
						return -1;
					}
				</code></pre>
				</div>
			</figure>
			<p>
				<span class="topic">Move-to-head.</span> With transposition, we do not
				reach ${O(1)}$ unless we search for the key ${k}$ ${n}$ times, where
				${n}$ is the index of ${k.}$ This means that the key ${k}$ can take a
				fair amount of time to get to the list's head. Moreover, if ${k}$ is not
				searched, it slowly moves towards the tail-end. To get to the head
				faster, we can use the <span class="term">move-to-head</span> approach.
				With move-to-head, after a successful search, we immediately place the
				key at ${i = 0.}$
			</p>
			<figure class="math-display">
				<div>
					<ol class="numd">
						<li>${T = (8, 9, 4, 6, 7, 3, 2, 11)}$</li>
						<li><span class="monoText">arrayLinearSearch${(6)}$</span></li>
						<li>${T = (6, 9, 4, 8, 7, 3, 2, 11)}$</li>
					</ol>
				</div>
			</figure>
			<p>In pseudocode:</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
						arrayLinearSearch(x) {
							for (i = 0; i < length; i++) {
								if (key == T[i]){
									swap(T[i], T[0])
									return 0;
								}
							}
							return -1;
						}
					</code></pre>
				</div>
			</figure>
		</section>

		<section id="binary_search">
			<h4>Binary Search</h4>
			<p>
				The <span class="term">binary search</span> algorithm is correct only if
				the array is <span class="underlineText">sorted</span>. There are a
				whole host of sorting algorithms, so we will cover them in a separate
				section. For now, suppose we have the following sorted array:
			</p>
			<figure class="math-display">
				<div>
					$$ \begin{matrix} T = [& 4 & 8 & 10 & 15 & 18 & 21 & 24 & 27 & 29 & 33
					& 34 & 37 & 39 & 41 & 43 &] \\ i = & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8
					& 9 & 10 & 11 & 12 & 13 & 14 & \end{matrix} $$
				</div>
			</figure>
			<p>
				Suppose our key is ${k = 18.}$ We see that 18 is at index ${i = 4.}$
				With linear search, we must perform 5 comparisions before ${k}$ is
				found. Let's see how binary search compares.
			</p>
			<p>
				First, with binary search, we need three variables: ${\ell,}$ ${h,}$ and
				${M.}$ These variables represent three variants: ${\ell}$ represents the
				lower bound (an index), ${h}$ represents the upper bound (also an
				index), and ${M}$ represents the index exactly between ${\ell}$ and
				${h.}$ Accordingly, the value of ${M}$ is given by:
			</p>
			<figure class="math-display">
				<div>
					<p>${M = \lfloor \dfrac{\ell + h}{2} \rfloor}$</p>
				</div>
			</figure>
			<p>
				This simply the arithmetic mean, but we will floor the result to account
				for the possibility of an odd number of elements in the array. For
				example, if the array has 5 elements, then ${\ell = 0,}$ and ${h = 5.}$
				Calculating ${M:}$ ${(0 + 5) / 2 = 2.5.}$ Obviously an index cannot be
				${2.5,}$ so we floor the result: ${M \equiv i = 2.}$
			</p>
			<p>
				That said, let's trace our program. We know ${k = 18.}$ So, we first
				initialize ${\ell}$ and ${h:}$
			</p>
			<figure class="math-display">
				<div>
					<p>${\ell = 0}$</p>
					<p>${h = 14}$</p>
				</div>
			</figure>
			<p>Then we compute ${M:}$</p>
			<figure class="math-display">
				<div>
					<p>${M = \dfrac{0 + 14}{2} = 7}$</p>
				</div>
			</figure>
			<p>
				Thus, ${M}$ is ${i = 7.}$ We then ask, is ${T[7] = k?}$ If yes, the
				search is successful, and we return the index 7. Otherwise, we ask, is
				${T[7] < k}$ or is ${T[7] > k?}$ Here, ${T[7] < k.}$ Because ${T[7] <
				k,}$ ${k}$ must be on the left-hand side of the array. I.e., ${\ell \leq
				k < M.}$ Why can we conclude this? Because the array ${T}$ is sorted. If
				${T[7] > k,}$ then ${k}$ must be on the right-hand side (${M < k \leq
				h}$).
			</p>
			<p>
				In this case, since ${T[7] < k,}$ ${\ell}$ remains as ${i = 0,}$ but we
				change ${h}$ to ${i = 6.}$ Now we're working the left-hand side, which
				is ${T[0] < k \leq T[6].}$ Now we have a new mean: ${(0 + 6) / 2 = 3.}$
				Thus, now the middle element is ${T[3] = 15.}$ We again ask, is ${k =
				T[3]?}$ No. Is ${k < T[3]}$ or is ${k > T[3]?}$ Here, ${18 > 15,}$ so
				we're looking at the right-hand side of the array.
			</p>
			<p>
				Because ${T[M] > k,}$ we again change the lower bounds and upper bounds.
				${\ell = 4,}$ and ${h = 4.}$ The mean is now ${M = (4 + 4) / 2 = 4.}$
				Thus, the middle element is now ${T[4] = 18.}$ We now ask, is ${k =
				T[4]?}$ Yes. We have found our key. Notice that we found our key in a
				total of 4 comparisons, compared to 5 comparisons with linear search.
			</p>
			<p>
				Let's try another key. ${k = 34.}$ We set the upper bounds and lower
				bounds. ${\ell = 0}$ and ${h = 14.}$ Then we compute the mean index.
				${(0 + 14) / 2 = 7.}$ Again we have ${T[7] = 27.}$ Is ${T[M] = k?}$ No.
				Is ${T[M] > k}$ or is ${T[M] < k?}$ ${27 < 34.}$ Thus, we're now
				restricting our search to the right-hand side.
			</p>
			<p>
				We change the upper and lower bounds. ${\ell = M + 1 = 7 + 1 = 8.}$ And
				${h = 14.}$ Then compute the mean index: ${(8 + 14) / 2 = 11.}$ Thus,
				the middle element is ${T[M] = T[11] = 37.}$ Is ${T[M] = k?}$ No. Is
				${T[M] > k}$ or ${T[M] < k?}$ ${37 > 34,}$ so we're looking at the
				left-hand side.
			</p>
			<p>
				We again change the upper and lower bounds. ${\ell = 8}$ and ${h = 11 -
				1 = 10.}$ Computing the mean: ${(10 + 8) / 2 = 9.}$ Is ${(T[9] = 33) =
				34?}$ No. Is ${33 > 34}$ or is ${33 < 34?}$ ${34}$ is less than ${33.}$
				So, the number is on the right-hand side. Once more we modify the upper
				and lower bounds.
			</p>
			<p>
				${\ell = M + 1 = 9 + 1 = 10,}$ and ${h = 10.}$ We compute the mean:
				${(10 + 10) / 2 = 10.}$ Is ${T[10] = 34?}$ Yes. We've found our key in 4
				comparisons. Compare that with linear search, which would have taken 10
				comparisions.
			</p>
			<p>
				Let's try another key, ${k = 25.}$ Set the upper and lower bounds:
				${\ell = 0}$ and ${h = 14.}$ Compute the mean: ${M = (0 + 14) = 7.}$
				Compare ${T[7]}$ to ${k.}$ ${k}$ is not equal to ${T[7].}$ ${k < T[M],}$
				so we're looking at the left-hand side.
			</p>
			<p>
				Change the upper and lower bounds. ${\ell = 0,}$ and ${h = 7 - 1 = 6.}$
				Compute the mean: ${M = (0 + 6)/2 = 3.}$ ${T[3]}$ is not equal to ${k.}$
				Because ${k > T[M],}$ we're looking at the right-hand side. So we change
				the upper and lower bounds.
			</p>
			<p>
				${\ell = 3 + 1 = 4,}$ and ${h = 6.}$ We compute the mean: ${(4 + 6) / 2
				= 5.}$ The middle element is ${T[5].}$ ${T[5]}$ is not equal to ${25,}$
				${k > T[5].}$ So again we're looking at the left-hand side. Once more we
				modify the lower and upper bounds.
			</p>
			<p>
				${\ell = 5 + 1 = 6,}$ and ${h = 6.}$ The mean: ${(6 + 6) / 2 = 6.}$
				${T[6]}$ is not equal to ${25.}$ ${25 > T[6],}$ so we modify the upper
				and lower bounds.
			</p>
			<p>
				${\ell = 6 + 1 = 7,}$ and ${h = 6.}$ This is where we stop. The moment
				${\ell > h,}$ we've arrived at an unsuccessful search, so we return
				${-1.}$ Notice that it took 4 comparisons to reach an unsuccessful
				search, compared to the 15 comparisions it would've taken with linear
				search.
			</p>
			<p>Implementing binay search in pseudocode:</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
						BinarySearch(k, low, high) {
							while (low <= high) {
								middle = floor((low + high) / 2);
								if (k == T[mean]) {
									return mean;
								}
								else if (k < T[mean]) {
									high = mean - 1;
								}
								else {
									low = mean + 1;
								}
							}
							return -1;
						}
					</code></pre>
				</div>
			</figure>
			<p>
				Alternatively, we can implement the binary search algorithm with tail
				recursion:
			</p>
			<figure class="math-display">
				<div>
					<pre class="language-pseudo"><code>
						BinarySearch(k, low, high) {
							if (low <= high) {
								mean = floor((low + high) / 2);
								if (k == T[mean]) {
									return mean;
								}
								else if (key < T[mean]) {
									return BinarySearch(low, mean - 1, key);
								}
								else {
									return BinarySearch(mean + 1, high, key);
								}
							}
							return -1;
						}
					</code></pre>
				</div>
			</figure>
			<p>
				To understand the time complexity for binary search, the crucial point
				is that we're cutting the array in half each time. However, before any
				of that splitting, we checked if the middle element is in fact the key.
				Accordingly, in the best-case scenario, binary search has a time
				complexity of ${\Omega(1)}$ &mdash; constant time.
			</p>
			<p>
				However, if the middle element was not the key, then we proceed to
				checking if the left- or right-hand side contained the key. Suppose it's
				the left-hand side. If it's the left-hand side, then ${\ell = 0}$ and
				${h = 6,}$ yielding ${M = 3.}$ If it's on the right-hand side, then
				${\ell = 8}$ and ${h = 14,}$ yielding ${M = 11.}$ This is halving the
				array and restricting our search to just the relevant half. If the
				middle element in either half is the key, then we've found our key in 2
				comparisons.
			</p>
			<p>
				If neither of the halves contains the middle element, then we again
				perform the split. For the left-hand side of the left-hand side, ${\ell
				= 0}$ and ${h = 2,}$ yielding ${M = 1.}$ If it's the right-hand side of
				the left-hand side, then ${\ell = 4}$ and ${h = 6,}$ yielding ${M = 5.}$
				For the left-hand side of the right-hand side, we have ${\ell = 8}$ and
				${h = 10,}$ yielding ${M = 9.}$ For the right-hand side of the
				right-hand side, we have ${\ell = 12}$ and ${h = 14,}$ yielding ${M =
				13.}$ In this case, the key can be found in 3 comparisons. Visualizing
				the tree:
			</p>
			<figure>
				<img
					src="{% static 'images/binary_search_tree.svg' %}"
					alt="The binary search tree's middle element computations"
					loading="lazy"
				/>
			</figure>
			<p>
				Splitting further, the key can be found in 4 comparisions, then 5, then
				6, and so on. Modelling binary search as a tree, the height of the tree
				is ${\lceil\log_{2}(n + 1)\rceil,}$ where ${n}$ is the number of
				elements in the array. Why ${\log_{2}(n + 1)?}$ Because the tree's
				height is directly proportional to the number of times we divide ${n}$
				by 2 such that we only have a remainder of 1. And as we know from
				mathematics, the answer to &#8220;How many times can I divide ${n}$ by 2
				to reach a remainder of 1?&#8221; is a logarithm of base 2. Successive
				multiplication yields a power, and successive division yields a
				logarithm. Thus, in terms of asymptotic analysis, the binary search
				algorithm has a runtime of order ${O(\lg n)}$ &mdash; logarithmic time.
			</p>
			<p>
				What about the average-case? For the average-case, we're asking for the
				total time for all the possible cases, divided by the number of cases.
				Revisiting the tree diagram above, we see that at the first level, there
				is only 1 case, with only 1 comparison. Let ${c}$ be the number of
				cases:
			</p>
			<figure class="math-display">
				<div>
					<p>${c = 1}$</p>
				</div>
			</figure>
			<p>
				On the second level, there are 2 cases, each requiring 1 comparison:
			</p>
			<figure class="math-display">
				<div>
					<p>${c = 1 + (1 \cdot 2)}$</p>
				</div>
			</figure>
			<p>
				On the third level, there are 4 cases, each requiring 2 comparisons:
			</p>
			<figure class="math-display">
				<div>
					<p>${c = 1 + (1 \cdot 2) + (2 \cdot 4)}$</p>
				</div>
			</figure>
			<p>
				On the fourth level, there are 8 cases, each requiring 3 comparisons:
			</p>
			<figure class="math-display">
				<div>
					<p>${c = 1 + (1 \cdot 2) + (2 \cdot 4) + (3 \cdot 8)}$</p>
				</div>
			</figure>
			<p>We can see pattern in this series:</p>
			<figure class="math-display">
				<div>
					<p>${c = 1 + (1 \cdot 2^1) + (2 \cdot 2^2) + (3 \cdot 2^3)}$</p>
				</div>
			</figure>
			<p>We can then express this pattern as:</p>
			<figure class="math-display">
				<div>
					<p>${\sum\limits_{i = 1}^{3} i \cdot 2^i}$</p>
				</div>
			</figure>
			<p>
				That 3 is intresting &mdash; it's the tree's height. Accordingly, our
				series can be generalized as:
			</p>
			<figure class="math-display">
				<div>
					<p>
						${\sum\limits_{i = 1}^{\log n} i \cdot 2^i = \log n \cdot 2^{\log
						n}}$
					</p>
				</div>
			</figure>
			<p>
				But, we must divide this sum by ${n,}$ the number of elements (and by
				implication, the number of possible cases):
			</p>
			<figure class="math-display">
				<div>
					<p>${\dfrac{\log n \cdot 2^{\log n}}{n} = \log n}$</p>
				</div>
			</figure>
			<p>
				Hence, the average-case running time is ${\Theta(\log n)}$ An
				algorithm's average-case, however, may be different depending on the
				conditions. For example, with respect to binary search, there's an
				average-case running time for a successful search, and an average-case
				running time for an unsuccessful search.
			</p>
			<p>
				A successful search occurs if the element is found. In the tree diagram
				above, the number of possible cases for a successful search is
				equivalent to the number of internal nodes (i.e., all of the nodes other
				than the nodes on the fifth level). If we examine the tree closely, the
				number of edges from the root to a given node represents the number of
				comparisons needed to reach the given node. For example, to find the ${k
				= 8,}$ binary-search requires 3 comparisons. Accordingly, the number of
				comparisons to reach a given node containing ${k}$ is ${e + 1,}$ where
				${e}$ is the number of edges leading to the node from the root (we add
				${1}$ because a comparison must be performed for the root).
			</p>
			<p>
				The number of possible cases for an unsuccesful search, in contrast, is
				found from the number of nodes on the fifth level. These are called
				<span class="term">external nodes</span>. It is on these external nodes
				that binary search terminates. Like the successful search, the number of
				comparisons needed to reach an unsuccessful search is the number of
				edges leading to an external node plus 1.
			</p>
			<p>
				With these basic facts, suppose that ${I}$ represents the sum of all the
				paths leading to internal nodes and ${E}$ represents the sum of the
				paths leading to external nodes. It follows then that:
			</p>
			<figure class="math-display">
				<div>
					<p>${E = I + 2n,}$ where ${n}$ is the number of internal nodes</p>
				</div>
			</figure>
			<p>
				Why ${+ 2n?}$ Because each of the internal nodes have 2 children (since
				the binary search algorithm works by successively dividing the problem
				by 2). For example, here's a simple binary tree:
			</p>
			<figure>
				<img
					src="{% static 'images/internal_v_external_nodes.svg' %}"
					alt="Internal versus external nodes"
					loading="lazy"
					class="sixty-p"
				/>
			</figure>
			<p>
				Notice that ${n = 3.}$ Thus, ${2n = 6.}$ Then, notice that ${I = 2.}$
				Hence, ${E = 2 + 6 = 8.}$ Indeed, there are 8 paths from the root to the
				external nodes.
			</p>
			<p>
				Alongside the facts above, we also know that the number of external
				nodes is the number of internal does plus 1: ${e = n + 1,}$ where ${e}$
				is the number of external nodes, and ${n}$ is the number of internal
				nodes. Knowing all of this, the average-case runtime for a successful
				search on an ${n}$ element array is the sum of the paths to internal
				nodes divided by the number of nodes (the sum of all possible cases
				divided by the number of cases) plus 1 (including the comparison for the
				root node):
			</p>
			<figure class="math-display">
				<div class="rule">
					<p>
						${\Omega\left(1 + \dfrac{I}{n}\right)}$, where ${I}$ is the sum of
						all paths to internal nodes and ${n}$ is the number of nodes.
					</p>
				</div>
			</figure>
			<p>Similarly, the average-case runtime for an unsuccesful search is:</p>
			<figure class="math-display">
				<div class="rule">
					<p>
						${\Omega\left( \dfrac{E}{n + 1} \right),}$ where ${E}$ is the sum of
						all paths to external nodes and ${n}$ is the number of nodes
					</p>
				</div>
			</figure>
			<p>
				Note that the sum of all paths to external nodes is roughly the height
				of the tree &mdash; ${n \log n.}$ Accordingly we can generalize the
				average-case runtime for an unsuccessful search as:
			</p>
			<figure class="math-display">
				<div class="rule">
					<p>${\Omega\left( \dfrac{n \log n}{n + 1} \right)}$</p>
				</div>
			</figure>
			<p>Generalizing even further:</p>
			<figure class="math-display">
				<div class="rule">
					<p>${\Omega(\log n)}$</p>
				</div>
			</figure>
			<p>
				Using what we know about ${E,}$ we can use substitution to find a more
				generalized version of the average-case runtime for a successful search.
				Where ${A_s(n)}$ is the average-case runtime for a successful search:
			</p>
			<figure class="math-display">
				<div>
					$$ \begin{aligned} A_s(n) &= 1 + \dfrac{I}{n} \\[1em] &= 1 + \dfrac{E
					- 2n}{n} \\[1em] &= 1 + \dfrac{E}{n} - 2 \\[1em] &= 1 + \dfrac{n \log
					n}{n} - 2 \\[1em] &= 1 + \log n + 2 \end{aligned} $$
				</div>
			</figure>
			<p>
				Applying asymptotic analysis, the average-case runtime for a successful
				search is:
			</p>
			<figure class="math-display">
				<div>
					<p>${\Omega (\log n)}$</p>
				</div>
			</figure>
		</section>
	</section>

	<section id="getting">
		<p>
			<span class="topic">Accessing an Array Element.</span> In the API above,
			we specified an operation called <span class="monoText">get(${i}$)</span>,
			where ${i}$ is an index. This operation returns the array's element at
			index ${i.}$
		</p>
		<p>
			Really, there are only two operations we must perform for
			<span class="monoText">get(${i}$)</span>: First, we must ensure the index
			argument ${i}$ is an integer not less than 0. It wouldn't make sense to
			pass an ${i}$ of 2.178 or an ${i}$ of -1. Second, we must ensure the index
			is less than <span class="monoText">length</span>. If the ${i >
			\texttt{length},}$ then we risk (a) getting some garbage value or (b)
			receiving an out-of-bounds error. The implementation:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
					get(int index) {
						if ( (index >= 0) ∧ (index < length) ) {
							⟹ return A[index];
						} 
					}
				</code></pre>
			</div>
		</figure>
		<p>
			Because only two operations are required for
			<span class="monoText">get(${i}$)</span>, the
			<span class="monoText">get(${i}$)</span> operator has a time complexity of
			${O(1)}$ &mdash; constant time.
		</p>
	</section>

	<section id="setting">
		<p>
			<span class="topic">Replacing an Array Element.</span> The
			<span class="monoText">set(${x}$, ${i}$)</span> operation will set the
			element ${x}$ and the index ${i.}$ Effectively, this will replace the
			element ${y}$ occupying the index ${i.}$ Like the
			<span class="monoText">get(${i}$)</span> operator, we must ensure that the
			index passed is an integer and that ${i < \texttt{length}.}$ In
			pseudocode:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
					get(int x, int index) {
						if ( (index >= 0) ∧ (index < length) ) {
							⟹ A[index] = x;
						} 
					}
				</code></pre>
			</div>
		</figure>
		<p>
			Once more, because there are really only two operations performed
			(ensuring the requirements are met and assignment), replacing an element
			in an array has running time of ${O(1)}$ &mdash; constant time.
		</p>
	</section>

	<section id="maximum">
		<p>
			<span class="topic">Finding the Maximum in an Array.</span> Finding the
			maximum element in a given array is an instance of a
			<span class="term">peak finding</span> problem. For example, suppose we
			had the following array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${u = }$</td>
						<td>8</td>
						<td>3</td>
						<td>9</td>
						<td>15</td>
						<td>6</td>
						<td>10</td>
						<td>7</td>
						<td>2</td>
						<td>12</td>
						<td>4</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			The <span class="italicsText">peak</span>, or
			<span class="italicsText">maximum</span>, in the array above is the
			element ${15.}$ We will see in later sections that peak finding extends to
			many other problem domains. For now, we focus on the array data structure.
		</p>
		<p>
			How do we find the maximum element? It depends on whether the array's
			elements are sorted. Yet another example of why sorting algorithms are so
			important. For unsorted lists, we have no recourse other than to check
			each of the elements one by one. To do so, we first suppose that the
			maximum is the first element in the array &mdash; ${max = u_0 = 8.}$ We
			then compare ${u_0}$ with ${u_1.}$ If ${u_1 > u_0,}$ then ${max = u_1.}$
			Otherwise, we compare ${u_0}$ with ${u_2.}$ If ${max = u_1,}$ then we
			compare ${u_1}$ with ${u_2.}$ If ${u_2 > u_1,}$ then ${max = u_2.}$
			Otherwise, we compare ${u_2}$ with ${u_3.}$ We keep doing so until we
			reach the very last element. In pseudocode:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
					max() {
						max = u[0];
						for (int i = 1; i < length; i++) {
							if (u[i] > max) {
								max = u[i];
							}
						}
						return max;
					}
				</code></pre>
			</div>
		</figure>
		<p>
			With this approach, we're effectively performing an instance of a linear
			search. We must traverse the entire array, checking each element (starting
			with the second element) all the way up to the last. Counting the number
			of operations, we have:
		</p>
		<figure class="math-display">
			<div>
				<pre class="language-pseudo"><code>
					max() {
						max = u[0]; <span class="redText">&larr; 1 operation</span>
						for (int i = 1; i < length; i++) { <span class="redText">&larr; n operations</span>
							if (u[i] > max) { <span class="redText">&larr; n - 1 operations</span>
								max = u[i];
							}
						}
						return max; <span class="redText">&larr; 1 operation</span>
					}
				</code></pre>
			</div>
		</figure>
		<p>
			Thus, there are a total of ${1 + 1 + n + (n - 1)}$ operations, or ${2n +
			1.}$ Accordingly, because the time function is ${f(n) = 2n + 1,}$ the
			above approach has a time complexity of ${O(n)}$ &mdash; linear time.
		</p>
		<p>
			On the other hand, if the list is sorted, then the last element is the
			maximum.
		</p>
	</section>

	<section id="finding_minimum">
		<p>
			<span class="topic">Finding a Minimum.</span> The
			<span class="monoText">min()</span> operator returns the minimum element
			in the array. Finding a minimum is an instance of a
			<span class="term">valley-finding problem</span>. We can think of it as
			the inverse of finding a maximum. Like peak-finding, how efficiently we
			can find a minimum depends on whether the array's elements are sorted. If
			the elements are unsorted, then we have no recourse other than to use a
			linear search approach.
		</p>
		<p>Supppose we had the same array from the previous section:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${u = }$</td>
						<td>8</td>
						<td>3</td>
						<td>9</td>
						<td>15</td>
						<td>6</td>
						<td>10</td>
						<td>7</td>
						<td>2</td>
						<td>12</td>
						<td>4</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			The valley here is the element ${u_7 = 2.}$ To find this element, we start
			by assuming the first element, ${u_0,}$ is the minimum. We then check if
			${u_1 < u_0.}$ If it is, then the minimum is ${u_1,}$ and we compare that
			to ${u_2.}$ If it isn't, then the minimum remains ${u_0,}$ and we compare
			it against ${u_2.}$ We repeat this process all the way up to the last
			element. In pseudocode:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>min():</li>
				<ol>
					<li>min = u[0] ${\text{1 operation}}$</li>
					<li>for (i = 1; i < length; i++): ${n \text{ operations} }$</li>
					<ol>
						<li>if (u[i] < min): ${n - 1 \text{ operations}}$</li>
						<ol>
							<li>min = u[i]</li>
						</ol>
					</ol>
					<li>return min ${\text{1 operation}}$</li>
				</ol>
			</ol>
		</figure>
		<p>
			Examining the operation count above, we again see that the running time
			function is ${f(n) = 1 + n + (n - 1) + 1 = 2n + 1.}$ Accordingly, this
			approach also has a time complexity of ${O(n)}$ &mdash; linear time.
		</p>
	</section>

	<section id="summing_elements">
		<p>
			<span class="topic">Summing Elements.</span> The
			<span class="monoText">sum()</span> operator will return the sum of all
			the elements in the array. Summing the elements of an array requires
			traversing the entire element, adding each element to some variable ${t}$
			representing the sum. In pseudocode:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>sum():</li>
				<ol>
					<li>total = 0; ${\text{1 operation}}$</li>
					<li>for (i = 0; i < length; i++): ${n + 1 \text{ operations}}$</li>
					<ol>
						<li>total += array[i] ${n \text{ operations}}$</li>
					</ol>
				</ol>
				<li>return total ${\text{1 operation}}$</li>
			</ol>
		</figure>
		<p>
			From the operation count above, we see that this approach has a running
			time function of ${f(n) = 2n + 3.}$ Accordingly, this algorithm has a time
			complexity of ${O(n),}$ which is linear time.
		</p>
		<p>Alternatively, we can apply a recursive implementation:</p>
		<figure class="math-display">
			<ol class="alg">
				<li>sum(array):</li>
				<ol>
					<li>if (array.length - 1 > 0):</li>
					<ol>
						<li>return 0;</li>
					</ol>
					<li>else:</li>
					<ol>
						<li>return sum(A, array.length - 1) + A[array.length]</li>
					</ol>
				</ol>
			</ol>
		</figure>
		<p>
			The recursive implementation also has a time complexity of ${O(n).}$ The
			difference, however, is that each recursive call will result in a new
			stack generation, leading to a space complexity of ${O(n).}$ This is in
			contrast to the iterative approach, which has a space complexity of
			${O(1).}$
		</p>
	</section>

	<section id="averaging">
		<p>
			<span class="topic">Computing the Arithmetic Mean.</span> A useful
			operator to have when working with arrays is returning the
			<span class="italicsText">arithmetic mean</span>. This is done with the
			<span class="monoText">ArithmeticMean()</span> operator. The
			implementation is straightforward. We simply compute the sum of all the
			elements, and divide it by the number of elements.
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>average():</li>
				<ol>
					<li>total = 0; ${\text{1 operation}}$</li>
					<li>for (i = 0; i < length; i++): ${n + 1 \text{ operations}}$</li>
					<ol>
						<li>total += array[i] ${n \text{ operations}}$</li>
					</ol>
				</ol>
				<li>return total / length ${\text{2 operations}}$</li>
			</ol>
		</figure>
		<p>
			As we can see, the time complexity is no different, save for the extra
			operation in the last line of dividing by the length. Accordingly, this
			approach has a time complexity of ${O(n)}$ &mdash; linear time.
		</p>
	</section>

	<section id="reversing">
		<h4>Reversing the Elements of an Array</h4>
		<p>
			The
			<span class="monoText">reverse()</span> operator performs exactly what it
			sounds like: It reverses all the original elements of the array. For
			example, given the array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>8</td>
						<td>3</td>
						<td>9</td>
						<td>15</td>
						<td>6</td>
						<td>10</td>
						<td>7</td>
						<td>2</td>
						<td>12</td>
						<td>14</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p><span class="monoText">reverse()</span> returns the array:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>14</td>
						<td>12</td>
						<td>2</td>
						<td>7</td>
						<td>10</td>
						<td>6</td>
						<td>15</td>
						<td>9</td>
						<td>3</td>
						<td>8</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			To reverse an array, there are two methods we can use: (1)
			<span class="italicsText">reversing in place</span> and (2) using an
			<span class="italicsText">auxiliary array</span>. We first consider the
			latter.
		</p>

		<section id="auxiliary_array">
			<p>
				<span class="topic">Reversing with an Auxiliary Array.</span> With the
				auxiliary array approach, we use an additional array to place the
				reversed elements. The idea is straightforward: We start at the last
				element of the array and traverse to the first element, copying each
				element to the auxiliary array. After copying all of the elements into
				the auxiliary array, we then replace the corresponding elements in the
				original array with the elements in the auxiliary array.
			</p>
			<p>Implementing this approach in pseudocode:</p>
			<figure class="math-display">
				<ol class="alg">
					<li>reverse():</li>
					<ol>
						<li>for (i = length - 1, j = 0; i >= 0; i--, j++):</li>
						<ol>
							<li>auxiliaryArr[j] = originalArr[i];</li>
						</ol>
						<li>for (i = 0; i < lenght; i++):</li>
						<ol>
							<li>originalArr[i] = auxiliaryArr[j];</li>
						</ol>
					</ol>
				</ol>
			</figure>
			<p>
				What is this approach's time complexity? Copying the elements from the
				original array to the auxiliary array takes ${n}$ operations, since we
				must traverse through ${n}$ elements. Then, copying the elements from
				the auxiliary array back to the original array takes ${n}$ operations,
				again because we must traverse through ${n}$ elements. Accordingly, this
				approach has a time function of roughly ${f(n) = 2n.}$ Asymptotically,
				the approach has a time complexity of order ${O(n)}$ &mdash; linear
				time.
			</p>
		</section>

		<section id="reversing_in_place">
			<p>
				<span class="topic">Reversing in Place.</span> With the reverse-in-place
				approach, we swap the first and the last elements, then the second and
				the second to last, then the third and the third to last, and so on.
				This is done by assigning two indexing variables: ${i}$ to track indices
				offsetting from and including the first element, and ${j}$ to track
				indices offsetting from and including the last element. We continue the
				process until either ${i}$ and ${j}$ have arrived at the same index, or
				when ${i > j.}$ The implementation:
			</p>
			<figure class="math-display">
				<ol class="alg">
					<li>reverse():</li>
					<ol>
						<li>for (i = 0, j = length - 1; i < j; i++, j--):</li>
						<ol>
							<li>temp = A[i];</li>
							<li>A[i] = A[j];</li>
							<li>A[j] = temp;</li>
						</ol>
					</ol>
				</ol>
			</figure>
			<p>
				With the implementation above, we can see that this approach also
				requires traversing through the array's ${n}$ elements. Accordingly,
				this approach, too, has a running time of ${O(n);}$ linear time.
			</p>
		</section>
	</section>

	<section id="left_shift">
		<h4>Shifting & Rotating</h4>
		<p>
			The next operations we consider are
			<span class="monoText">leftShift()</span>,
			<span class="monoText">rightShift()</span>,
			<span class="monoText">leftRotate()</span>, and
			<span class="monoText">rightRotate()</span>. Each of these operations
			involves moving elements to the left or right &mdash; particularly useful
			actions when implementing other algorithms (e.g., filling in holes in the
			array).
		</p>
		<p>
			<span class="topic">Shifting an Element.</span> Suppose we had the
			following array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			The operation of left-shifting is to shift all of the elements in the
			array to the left:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
						<td></td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Notice that in doing so, we lose the element 6. This is the natural
			consequence of left-shifting. We're shifting everything to the left,
			losing whichever element is at index ${i = 0}$ before the left-shift.
		</p>
		<p>
			The same idea extends to right-shifting. The difference, however, is that
			we're shifting elements to the right. Starting with the same previous
			array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p><span class="monoText">rightShift()</span> results in:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td></td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Implementing both of these algorithms is fairly straightforward. For
			<span class="monoText">leftShift()</span>, we're moving each element from
			the right to the left. Thus, we must iterate through the array, moving the
			element at <span class="monoText">array[i+1]</span> to the position
			<span class="monoText">array[i]</span>. We also include an operation for
			setting the last element to ${0}$:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>leftShift():</li>
				<ol>
					<li>for (int i = 0; i < length-1; i++): ${n \text{ operations}}$</li>
					<ol>
						<li>array[i] = array[i+1];</li>
					</ol>
					<li>arr[length-1] = 0; ${1 \text{ operation}}$</li>
				</ol>
			</ol>
		</figure>
		<p>
			For <span class="monoText">rightShift()</span>, we're moving each element
			from the left to the right. Again we iterate through the array, but with a
			few differences: We start from the last element, and we move the element
			at <span class="monoText">array[i-1]</span> to the position
			<span class="monoText">array[i]</span>. We also include an operation for
			setting the first element to ${0}$:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>shiftRight():</li>
				<ol>
					<li>
						<span class="pop">for (int i = length - 1; i > 0; i--): </span>
						<div class="popText">
							<p>${n \text{ operations}}$</p>
						</div>
					</li>
					<ol>
						<li>arr[i] = arr[i - 1];</li>
					</ol>
					<li>
						<span class="pop">arr[0] = 0;</span>
						<div class="popText"><p>${1 \text{ operation}}$</p></div>
					</li>
				</ol>
			</ol>
		</figure>
		<p>
			Given the implementations above, we can see that both shifting operations
			have a time function of roughly ${f(n) = n + 1.}$ Accordingly, both
			shifting operations have a time complexity of ${O(n)}$ &mdash; linear
			time.
		</p>
		<p>
			<span class="topic">Rotating an Array.</span> Suppose performed a
			left-shift, pushing the element ${6}$ out of the array. What if we wanted
			to keep the ${6}$ somehow? To do so, we use the
			<span class="monoText">leftRotate()</span> operator. Starting with this
			array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p><span class="monoText">leftRotate()</span> yields:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
						<td>6</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Notice that the element ${6}$ moves to ${i = length}$ when the left-shift
			pushes it out of the array. The same operation extends to rotating to the
			right &mdash; <span class="monoText">rightRotate()</span>. Starting with:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
						<td>9</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p><span class="monoText">rightRotate()</span> yields:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>9</td>
						<td>6</td>
						<td>3</td>
						<td>8</td>
						<td>5</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Implementing rotate follows cleanly from our implementations for shifting.
			All we must do is save the element pushed out of the array in a
			<span class="monoText">temp</span> variable, then assign it to the
			resulting empty space. First, the operation
			<span class="monoText">leftRotate()</span>:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ leftRotate():</li>
				<ol>
					<li>temp = A[0]</li>
					<li>for (int i = 0; i < length-1; i++):</li>
					<ol>
						<li>array[i] = array[i+1];</li>
					</ol>
					<li>arr[length-1] = temp;</li>
				</ol>
			</ol>
		</figure>
		<p>Second, the operation <span class="monoText">rightRotate()</span>:</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ rightRotate():</li>
				<ol>
					<li>temp = A[length]</li>
					<li>for (int i = length-1; i > 0; i--):</li>
					<ol>
						<li>array[i] = array[i-1];</li>
					</ol>
					<li>arr[0] = temp;</li>
				</ol>
			</ol>
		</figure>
		<p>
			The implementation above is similar to the shifting operations; the only
			difference is the inclusion of one more operation, saving the element
			popped off the array. Accordingly, both
			<span class="monoText">leftRotate()</span> and
			<span class="monoText">rightRotate()</span> have a time complexity of
			${O(n).}$
		</p>
	</section>

	<section id="inserting_into_a_sorted_array">
		<p>
			<span class="topic">Inserting into a Sorted Array.</span> Suppose we had
			the following <span class="underlineText">sorted</span> array:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>4</td>
						<td>8</td>
						<td>13</td>
						<td>16</td>
						<td>20</td>
						<td>25</td>
						<td>28</td>
						<td>33</td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			When inserting into a sorted array like the one above, we often want to
			keep the array's sorted property. In other words, we want to insert the
			element in a sorted position. In this case,
			<span class="monoText">insert(18)</span> should place the element ${18}$
			after ${A_{3} = 16.}$ This requires placing ${18}$ at ${i = 4,}$ which is
			presently occupied by ${A_{4} = 20.}$ Accordingly, we must make space for
			the new element. This is done by shifting the element at 7, then 6, then
			5, then 4.
		</p>
		<p>
			How might this shifting be implemented? Well, let's consider a simpler
			case. If we instead wrote <span class="monoText">insert(34)</span>, then
			no shifting would occur, since 34 would be the largest element. If,
			however, we wrote <span class="monoText">insert(32)</span>, then 33 would
			have to be shifted, since ${32 > 33.}$ Accordingly, when we shift
			elements, we keep right-shifting, starting from the last element, until we
			reach the <span class="underlineText">first</span> element less than the
			argument passed to <span class="monoText">insert()</span> (i.e., the
			element we want to insert).<label for="insert" class="margin-toggle"
				><sup></sup
			></label>
			<input
				type="checkbox"
				id="insert"
				class="margin-toggle sidenote-number"
			/>
			<span class="marginnote"
				>This algorithm only works because the array's elements are
				sorted.</span
			>
			This implies that we never have to check the elements less than the new
			element. For example, with <span class="monoText">insert(18)</span>, we
			never have to check the elements 4, 8, 13, and 16. All that matters is 20,
			25, 28, and 33. The implementation:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ insert(${x}$):</li>
				<ol>
					<li>i = length-1; ${\color{lightgray} 1 \text{ operation}}$</li>
					<li>
						while (A[i] > ${x}$): ${\color{lightgray} n \text{ operations}}$
					</li>
					<ol>
						<li>array[i+1] = array[i]</li>
						<li>i--;</li>
					</ol>
					<li>A[i+1] = ${x}$; ${\color{lightgray} 1 \text{ operation}}$</li>
				</ol>
			</ol>
		</figure>
		<p>
			The implementation above follows our reasoning. First, in line 2, we
			establish our starting point: The last index in the array. Once that's
			done, we enter the while-loop. If the new element, ${x,}$ is greater than
			the current element, then perform the following: (1) Shift the current
			element to the right; (2) Decrement the index (so we can then check the
			element just before the start). As long as the new element ${x}$ is
			greater than the current element, we keep performing the operation above.
			Once we've arrived at an element greater less than ${x,}$ we exit the
			while loop and proceed to line 6: Assign to the position after the current
			position (an empty position) the new element ${x.}$
		</p>
		<p>
			Looking at the annotations, we see that the time function for this
			algorithm is roughly ${f(n) = n + 2.}$ Accordingly, this algorithm has a
			time complexity of ${O(n)}$ &mdash; linear time. In the best case
			scenario, ${x}$ would be greater than or equal to the last element, in
			which case we have a time complexity of ${\Omega(1)}$ &mdash; constant
			time.
		</p>
		<p>
			<span class="topic">Checking if an Array is Sorted.</span> A necessary
			condition for the algorithm above is that the array is sorted. Indeed, the
			algorithm above is incorrect for unsorted arrays. Hence, the
			<span class="monoText">insert()</span> operator requires some other
			operator to check if the array is sorted. We will call this operator
			<span class="monoText">isSorted()</span>.
		</p>
		<p>Suppose we had the following array:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>4</td>
						<td>8</td>
						<td>13</td>
						<td>26</td>
						<td>20</td>
						<td>25</td>
						<td>28</td>
						<td>33</td>
						<td></td>
						<td></td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			We can check if the array is sorted by comparing the element at position
			${i}$ to the element at position ${i + 1.}$ Given that array above is
			sorted in ascending order, if the condition ${a_i \leq a_{i+1}}$ is true
			for
			<span class="underlineText">all</span> elements in the array, we can
			conclude that all the elements are sorted. In this case, the elements are
			sorted up until ${i = 3,}$ since ${26 \nleq 20.}$
		</p>
		<p>
			Implementing the <span class="monoText">isSorted()</span> method is a good
			exercise in being mindful of the
			<span class="term">fencepost problem</span>. Because we want to check that
			each element ${a_i \leq a_{i+1},}$ we must be careful with endpoints. In
			this case, we want to check all of the elements in the list &mdash; the
			property <span class="monoText">length</span>. But, we must make sure we
			do not perform the comparison ${a_{length} \leq a_{length + 1}.}$ This
			would lead to either (a) an out of bounds error, or (b) comparing the
			element at ${a_{length}}$ to a garbage value. Hence, we must stop at ${i =
			length-1.}$ The implementation:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ isSorted()</li>
				<ol>
					<li>
						for (int i = 0; i < size-1; i++): ${\color{lightgray} n \text{
						operations}}$
					</li>
					<ol>
						<li>
							if (A[i] >= A[i+1]): ${\color{lightgray} 1 \text{ operation}}$
						</li>
						<ol>
							<li>return false; ${\color{lightgray} 1 \text{ operation}}$</li>
						</ol>
					</ol>
					<li>return true; ${\color{lightgray} 1 \text{ operation}}$</li>
				</ol>
			</ol>
		</figure>
		<p>
			Examining the annotations, assuming the array is sorted, the algorithm has
			a time function of roughly ${f(n) = 2n + 1.}$ Thus, this algorithm
			(assuming the array is sorted), has a time complexity of ${O(n),}$ which
			is linear time. If the array is unsorted, then in the worst case scenario,
			the algorithm still has a running time of ${O(n).}$ In the best-case
			scenario, however, the algorithm has a running time of ${\Omega(1)}$
			&mdash; the first element is unsorted.
		</p>

		<h4>Negatives Towards Start & Positives Towards End</h4>
		<p>
			One problem that often appears with array data structures is where we have
			a mixture of positive and negative numbers. Confronting this problem, we
			often want to move all the negative numbers towards the beginning, or the
			right side, and the positive numbers towards the end. Note that we aren't
			sorting the elements. We're simply separating the negatives from the
			positives. For example, such an array might look like the following:
		</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>-6</td>
						<td>3</td>
						<td>-8</td>
						<td>10</td>
						<td>5</td>
						<td>-7</td>
						<td>-9</td>
						<td>12</td>
						<td>-4</td>
						<td>2</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>What we want to do is obtain an array that looks like:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A = }$</td>
						<td>-6</td>
						<td>-4</td>
						<td>-8</td>
						<td>-9</td>
						<td>-7</td>
						<td>5</td>
						<td>10</td>
						<td>12</td>
						<td>3</td>
						<td>2</td>
					</tr>
					<tr>
						<td>${i = }$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
					</tr>
				</tbody>
			</table>
		</figure>
		<p>
			Notice that we aren't sorting. We're just moving the positive and negative
			elements. We will call this operation
			<span class="monoText">signSplit()</span>. With this operation, we will
			iterate. First, we create two variables: A variable
			<span class="monoText">i</span> to track the indices starting from the
			left, and a variable <span class="monoText">j</span> to the track the
			indices from the right. Then, we iterate through the array, as long as
			<span class="monoText">i < j.</span>. Then, inside the while-loop, we
			place two more while-loops. As long as
			<span class="monoText">A[i] < 0,</span> we will increment
			<span class="monoText">i</span>. Otherwise, we go the second while-loop:
			As long as as <span class="monoText">A[j] > 0,</span>, we will decrement
			<span class="monoText">j</span>. Then, once that has finished executing,
			we will swap <span class="monoText">A[i]</span> with
			<span class="monoText">A[j]</span>. This process continues as long as
			<span class="monoText">i < j.</span> The implementation:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ signSplit():</li>
				<ol>
					<li>int i = 0;</li>
					<li>int j = length - 1;</li>
					<li>while (i ${<}$ j):</li>
					<ol>
						<li>while (array[i] ${<}$ 0): i++;</li>
						<li>while (array[j] ${\geq}$ 0): j--;</li>
						<li>swap(array[i], array[j]);</li>
					</ol>
				</ol>
			</ol>
		</figure>
		<p>
			The implementation above is a good example of how nested loops do not
			always imply polynomial time. Here, the time spent most is just on
			comparing the elements. In this case, there are a total of ${n + 2}$
			comparisons (+2 because both <span class="monoText">i</span> and
			<span class="monoText">j</span> must both check one extra number). Because
			the brunt of this time is spent on comparisons of ${n}$ elements, this
			approach has a time complexity of ${O(n)}$ &mdash; linear time. To see
			that this is the case, the code above is equivalent to the following:
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ signSplit():</li>
				<ol>
					<li>int i = 0;</li>
					<li>int j = length - 1;</li>
					<li>while (i ${<}$ j):</li>
					<ol>
						<li>if (array[i] < 0) & (array[j] < 0):</li>
						<ol>
							<li>i++;</li>
						</ol>
						<li>else if (array[i] > 0) & (array[j] > 0):</li>
						<ol>
							<li>j--;</li>
						</ol>
						<li>else if (array[i] > 0) & (array[j] < 0):</li>
						<ol>
							<li>swap(array[i], array[j]);</li>
						</ol>
						<li>else:</li>
						<ol>
							<li>i++;</li>
							<li>j--;</li>
						</ol>
					</ol>
				</ol>
			</ol>
		</figure>
		<p>
			With this implementation, we can clearly see that the algorithm has a time
			complexity of ${O(n).}$ We used the multiple while-loop approach simply
			because it's cleaner. Alternatively, here's another implementation that
			takes an approach similar to the partitioning algorithm of quicksort (an
			algorithm we will see in due course):
		</p>
		<figure class="math-display">
			<ol class="alg">
				<li>${f}$ signSplit():</li>
				<ol>
					<li>int j = 0;</li>
					<li>for (int i = 0; i < length; i++):</li>
					<ol>
						<li>if (arr[i] < 0):</li>
						<ol>
							<li>if (i ${\neq}$ j):</li>
							<ol>
								<li>swap(arr[i], arr[j]);</li>
							</ol>
							<li>j++;</li>
						</ol>
					</ol>
				</ol>
			</ol>
		</figure>
		<p>
			Clearly with this implementation, we still have a time complexity of
			${O(n).}$
		</p>
	</section>

	<section id="merging_arrays">
		<h3>Binary Operations on Arrays</h3>
		<p>
			In this section, we consider the
			<span class="italicsText">binary operations</span> on arrays. These are
			operations that involve two arrays as operands, namely:
			<span class="monoText">merge(${A}$, ${B}$)</span>;
			<span class="monoText">append(${A}$, ${B}$)</span>;
			<span class="monoText">concat(${A}$, ${B}$)</span>; and
			<span class="monoText">copy(${A}$)</span>, where ${A}$ and ${B}$ are
			arrays. We consider each in turn.
		</p>

		<section id="append">
			<p>
				<span class="topic">Appending an Array.</span> With the
				<span class="monoText">${A}$.append(${B}$)</span> operation, we take an
				existing array ${A}$ and add on to it an array ${B.}$ For example,
				suppose we had some array ${A}$:
			</p>

			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A =}$</td>
							<td>2</td>
							<td>3</td>
							<td>9</td>
							<td>1</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
						</tr>
					</tbody>
				</table>
			</figure>

			<p>Then suppose we had the array ${B}$:</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B = }$</td>
							<td>4</td>
							<td>9</td>
							<td>7</td>
						</tr>
						<tr>
							<td>${i = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				With the <span class="monoText">${A}$.append(${B}$)</span> operation, we
				receive as output the following array:
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A =}$</td>
							<td>2</td>
							<td>3</td>
							<td>9</td>
							<td>1</td>
							<td>4</td>
							<td>9</td>
							<td>7</td>
							<td></td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				Because we're working with a static array data structure, this operation
				works <span class="underlineText">only if</span> the array to append to
				(in this case ${A}$), has uninitialized positions. In other words, the
				array's <span class="italicsText">length</span> is less than its
				<span class="italicsText">size</span>. Otherwise, we would go beyond the
				array's bounds. Implementing this algorithm:
			</p>
			<figure class="math-display">
				<ol class="alg">
					<li>${f}$ append(A[], B[]):</li>
					<ol>
						<li>if (A.length < A.size):</li>
						<ol>
							<li>int j = 0;</li>
							<li>for (int i = A.length+1; i < size; i++):</li>
							<ol>
								<li>A[i] = B[j];</li>
								<li>A.length++;</li>
								<li>j++;</li>
							</ol>
						</ol>
						<li>else:</li>
						<ol>
							<li>return "A has no free spaces";</li>
						</ol>
					</ol>
				</ol>
			</figure>
			<p>
				Here, we must perform ${n = s - \ell}$ comparisons for the index
				<span class="monoText">i</span>, where ${s}$ is the size of the array
				and ${\ell}$ is the length of the array. Accordingly, this algorithm has
				a time complexity of ${O(n),}$ linear time, where ${n}$ is the
				difference between the array's size and its length.
			</p>
		</section>

		<section id="merging_arrays">
			<p>
				<span class="topic">Merging Arrays.</span> Say we had the following
				arrays:
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A =}$</td>
							<td>3</td>
							<td>8</td>
							<td>16</td>
							<td>20</td>
							<td>25</td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
				<hr />
				<table class="array">
					<tbody>
						<tr>
							<td>${B =}$</td>
							<td>4</td>
							<td>10</td>
							<td>12</td>
							<td>22</td>
							<td>23</td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>We want to take these two arrays and construct the following array:</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${C =}$</td>
							<td>3</td>
							<td>4</td>
							<td>8</td>
							<td>10</td>
							<td>12</td>
							<td>16</td>
							<td>20</td>
							<td>22</td>
							<td>23</td>
							<td>25</td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				This operation is called <span class="term">merging</span> the arrays,
				and we denote it with the operator
				<span class="monoText">merge(${A}$, ${B}$)</span>, where ${B}$ is the
				array to be merged on to the array ${A.}$ Notice the outpout of
				<span class="monoText">merge()</span>: It's an array where the elements
				of ${A}$ and ${B}$ are placed into a single array, sorted. Accordingly,
				this operation requires a third array for its return.
			</p>
			<p>
				How does this operation work? Here, we need three pointers:
				<span class="monoText">i</span>, <span class="monoText">j</span>, and
				<span class="monoText">k</span> for each of the arrays
				<span class="monoText">A</span>, <span class="monoText">B</span>, and
				the new array, <span class="monoText">C</span>. The pointer
				<span class="monoText">i</span> will track the indices of
				<span class="monoText">A</span>, the pointer
				<span class="monoText">j</span> the indices of
				<span class="monoText">B</span>, and the pointer
				<span class="monoText">k</span> the indices of
				<span class="monoText">C</span>. Once these are established, we iterate,
				starting from the first position. If
				<span class="monoText">A[i] < B[j]</span>, then:
				<span class="monoText">A[i]</span> is assigned to
				<span class="monoText">C[k]</span>, and both
				<span class="monoText">i</span> and <span class="monoText">k</span> are
				incremented. Otherwise, we assign <span class="monoText">B[j]</span> to
				<span class="monoText">C[k]</span>, and both
				<span class="monoText">j</span> and <span class="monoText">k</span> are
				incremented. Notice that with this procedure,
				<span class="monoText">k</span> is always incremented. Whether
				<span class="monoText">i</span> or <span class="monoText">j</span> is
				incremented depends on whether the element at that particular position
				is less than the other. The implementation:
			</p>
			<figure class="math-display">
				<ol class="alg">
					<li>${f}$ merge(A, B):</li>
					<ol>
						<li>new array C = A.length + B.length</li>
						<li>int i = 0, j = 0, k = 0;</li>
						<li>while (i < A.length & j < B.length):</li>
						<ol>
							<li>if (A[i] < B[j]):</li>
							<ol>
								<li>C[k] = A[i];</li>
								<li>i++;</li>
							</ol>
							<li>else:</li>
							<ol>
								<li>C[k] = B[j];</li>
								<li>j++;</li>
							</ol>
							<li>k++;</li>
						</ol>
						<li>for (i < A.length; i++):</li>
						<ol>
							<li>C[k++] = A[i];</li>
						</ol>
						<li>for (j < B.length; j++):</li>
						<ol>
							<li>C[k++] = B[j];</li>
						</ol>
					</ol>
				</ol>
			</figure>
			<p>
				Notice that we included two more for-loops at the end. This is to handle
				the &#8220;stragglers&#8221; &mdash; the elements remaining in either
				array <span class="monoText">A</span> or array
				<span class="monoText">B</span> that could not be copied over because
				the while-loop terminated before both arrays were completely compared.
				This occurs if either <span class="monoText">A</span> or
				<span class="monoText">B</span> has three elements in a row that are
				less than the given element in the other. For example, if
				<span class="monoText">A = [1, 2]</span> and
				<span class="monoText">B = [3, 4]</span>, then the while-loop would
				terminate the moment <span class="monoText">i = 1</span> (at which point
				<span class="monoText">k = 1</span>), and as such, the elements of
				<span class="monoText">B</span> are not checked. The for-loop ensures
				the unchecked elements are checked and assigned accordingly.
			</p>
			<p>
				The time complexity for this operation is straightforward. We're
				comparing ${m}$ elements and ${n}$ elements (the two array arguments).
				Accordingly, this algorithm has a time complexity of ${\Theta(m + n);}$
				linear time. Whenever we see a time complexity of the form ${a + b,}$
				it's highly likely that we're dealing with an algorithm that involves
				merging.
			</p>
		</section>
	</section>

	<section id="set_operations">
		<h3>Set Operations on Arrays</h3>
		<p>
			With arrays, we can also perform the fundamental set operations of
			<span class="italicsText">union</span>,
			<span class="italicsText">intersetion</span>,
			<span class="italicsText">difference</span>, and
			<span class="italicsText">membership</span>. We will call these operations
			as such: <span class="monoText">union(${A}$, ${B}$)</span>,
			<span class="monoText">intersection(${A}$, ${B}$)</span>,
			<span class="monoText">difference(${A}$, ${B}$)</span>, and
			<span class="monoText">isMember(${x}$, ${A}$)</span>.
		</p>

		<section id="union_arrays">
			<p>
				<span class="topic">Union of Arrays.</span> Recall that in mathematics,
				given a set ${A = \{ 3, 5, 10, 4, 6 \}}$ and a set ${B = \{ 12, 4, 7, 2,
				5 \},}$ the union of ${A}$ and ${B}$ is the set ${A \cup B = \{ 3, 5,
				10, 4, 6, 12, 7, 2 \}.}$ Notice that the union lists no duplicates. In
				this case, there were two duplicates: ${4}$ and ${5.}$ These duplicate
				elements were omitted from the resulting set.
			</p>
			<p>
				We implement the process of forming a union through the operator
				<span class="monoText">union(${A}$, ${B}$)</span>, where ${A}$ and ${B}$
				are arrays. Implementing this operator, we want to keep in mind the
				requirement that there must be no duplicates in the resulting array. We
				aren't just blindly copying. Otherwise, the operator would be no
				different from <span class="monoText">concatenate()</span>.
			</p>
			<p>Suppose the array ${A}$ is the following:</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A = }$</td>
							<td>3</td>
							<td>5</td>
							<td>10</td>
							<td>4</td>
							<td>6</td>
						</tr>
						<tr>
							<td>${i = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>And the array ${B:}$</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B = }$</td>
							<td>12</td>
							<td>4</td>
							<td>7</td>
							<td>2</td>
							<td>5</td>
						</tr>
						<tr>
							<td>${j = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>Executing <span class="monoText">union(A, B)</span>, we have:</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${C =}$</td>
							<td>3</td>
							<td>5</td>
							<td>10</td>
							<td>4</td>
							<td>6</td>
							<td>12</td>
							<td>7</td>
							<td>2</td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>7</td>
							<td>8</td>
							<td>9</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				The algorithm consists of several steps. First, we have to assign all of
				the elements in the first array to the new array. If there are ${m}$
				elements, this process takes ${m}$ time. Then, to ensure we do not have
				any duplicates, we must check the ${n}$ elements in the second array
				against the ${m}$ elements inside the new array then assign the elements
				that do not match. Given ${m}$ elements in the new array, this checking
				takes ${m \cdot n}$ time. Accordingly, the algorithm has a runtime
				complexity of ${O(m + nm).}$ To simplify this expression for the
				purposes of asymptotic analysis, we want to only use one variable.
				Accordingly, the time complexity is ${O(n + nn),}$ or more relevantly,
				${O(n^2).}$ This is quadratic time.
			</p>
			<p>
				To improve this runtime, we can sort the array elements before
				performing the union. We will cover sorting algorithms in a later
				section, so for now, we will just assume that the array elements are
				already sorted. Suppose the array ${A}$ is:
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A =}$</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>And the set ${B:}$</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B =}$</td>
							<td>2</td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j =}$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				With sorted arrays, all we have to do is merge while avoiding
				duplicates. We compare ${A_i}$ against ${B_j.}$ The lesser element is
				assigned, and the other element's index is incremented. If both elements
				are equal, we assign either one, and increment both indices. Thus:
			</p>
			<ol>
				<li>
					Start: ${i = 0,}$ the index for ${A,}$ ${j = 0,}$ the index for ${B,}$
					and ${k = 0,}$ the index for ${C.}$
				</li>
				<li>
					Compare ${A_i \leq B_j.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="redText">3</span></td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greenText">0</span></td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="redText">2</span></td>
									<td>4</td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greenText">0</span></td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					${3}$ is not less than or equal to ${2,}$ so assign ${2}$ to the array
					${C,}$ which is ${B_j.}$ Increment ${j}$ and ${k.}$ ${j}$ is now ${1}$
					and ${k}$ is now ${1.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="redText">3</span></td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greenText">0</span></td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td>4</td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${C =}$</td>
									<td>2</td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
								</tr>
								<tr>
									<td>${k =}$</td>
									<td>0</td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>7</td>
									<td>8</td>
									<td>9</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					Compare ${A_i \leq B_j.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="redText">3</span></td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greenText">0</span></td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="redText">4</span></td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					${3}$ is less than ${4,}$ so assign ${3}$ to the array ${C,}$ which is
					${A_j.}$ Increment ${i}$ and ${k.}$ ${i}$ is now ${1}$ and ${k}$ is
					now ${2.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td>4</td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${C =}$</td>
									<td>2</td>
									<td>3</td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
								</tr>
								<tr>
									<td>${k =}$</td>
									<td>0</td>
									<td>1</td>
									<td><span class="greenText">2</span></td>
									<td>3</td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>7</td>
									<td>8</td>
									<td>9</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					Compare ${A_i \leq B_j.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td>3</td>
									<td><span class="redText">4</span></td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td>0</td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="redText">4</span></td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greenText">1</span></td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					${4}$ is equal to ${4,}$ so assign ${4}$ to the array ${C,}$ which is
					${A_j.}$ Increment ${i,}$ ${j,}$ and ${k.}$ ${i}$ is now ${2,}$ ${j}$
					is now ${2,}$ and ${k}$ is now ${3.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td><span class="greyText">4</span></td>
									<td>5</td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greenText">2</span></td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">4</span></td>
									<td>5</td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greenText">2</span></td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${C =}$</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
								</tr>
								<tr>
									<td>${k =}$</td>
									<td>0</td>
									<td>1</td>
									<td>2</td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td>7</td>
									<td>8</td>
									<td>9</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					Compare ${A_i \leq B_j.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="redText">5</span></td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greenText">2</span></td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="redText">5</span></td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greenText">2</span></td>
									<td>3</td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					${5}$ is equal to ${5,}$ so assign ${5}$ to the array ${C,}$ which is
					${A_j.}$ Increment ${i,}$ ${j,}$ and ${k.}$ ${i}$ is now ${3,}$ ${j}$
					is now ${3,}$ and ${k}$ is now ${4.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td>6</td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${C =}$</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
									<td>5</td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
								</tr>
								<tr>
									<td>${k =}$</td>
									<td>0</td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td><span class="greenText">4</span></td>
									<td>5</td>
									<td>6</td>
									<td>7</td>
									<td>8</td>
									<td>9</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					Compare ${A_i \leq B_j.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td><span class="redText">6</span></td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td><span class="redText">7</span></td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
				<li>
					${6}$ is less than ${7,}$ so assign ${6}$ to the array ${C,}$ which is
					${A_j.}$ Increment ${i}$ and ${k.}$ ${i}$ is now ${4,}$ ${j}$ is still
					${3,}$ and ${k}$ is now ${5.}$
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${A =}$</td>
									<td><span class="greyText">3</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td><span class="greyText">6</span></td>
									<td>10</td>
								</tr>
								<tr>
									<td>${i =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">3</span></td>
									<td><span class="greenText">4</span></td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${B =}$</td>
									<td><span class="greyText">2</span></td>
									<td><span class="greyText">4</span></td>
									<td><span class="greyText">5</span></td>
									<td>7</td>
									<td>12</td>
								</tr>
								<tr>
									<td>${j =}$</td>
									<td><span class="greyText">0</span></td>
									<td><span class="greyText">1</span></td>
									<td><span class="greyText">2</span></td>
									<td><span class="greenText">3</span></td>
									<td>4</td>
								</tr>
							</tbody>
						</table>
					</figure>
					<figure>
						<table class="array">
							<tbody>
								<tr>
									<td>${C =}$</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
									<td>5</td>
									<td>6</td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
									<td></td>
								</tr>
								<tr>
									<td>${k =}$</td>
									<td>0</td>
									<td>1</td>
									<td>2</td>
									<td>3</td>
									<td>4</td>
									<td><span class="greenText">5</span></td>
									<td>6</td>
									<td>7</td>
									<td>8</td>
									<td>9</td>
								</tr>
							</tbody>
						</table>
					</figure>
				</li>
			</ol>
			<p>
				The procedure continues for the rest of the elements. Because this
				approach to <span class="monoText">union()</span> is essentially merging
				two arrays, it has a runtime of ${O(m+n),}$ or more generally ${O(n).}$
				This is linear time, which is better than quadratic time.
			</p>
		</section>

		<section id="intersection">
			<p>
				<span class="topic">Intersection.</span> From set theory, the
				intersection of two sets ${A}$ and ${B}$ is the set of all elements in
				both ${A}$ and ${B.}$ For example, suppose ${A = \{ 1, 2, 3 \}}$ and ${B
				= \{ 1, 2, 4 \}.}$ The intersection ${A \cap B}$ is the set ${\{ 1, 2
				\}.}$ Like the <span class="monoText">union()</span> operation, we can
				implement the intersection operation with arrays. We'll call this
				operation <span class="monoText">intersection(${A}$, ${B}$)</span>,
				where ${A}$ and ${B}$ are arrays.
			</p>
			<p>
				To illustrate, suppose ${A}$ and ${B}$ were the following. The array
				${A:}$
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A = }$</td>
							<td>3</td>
							<td>5</td>
							<td>10</td>
							<td>4</td>
							<td>6</td>
						</tr>
						<tr>
							<td>${i = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>And the array ${B:}$</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B = }$</td>
							<td>12</td>
							<td>4</td>
							<td>7</td>
							<td>2</td>
							<td>5</td>
						</tr>
						<tr>
							<td>${j = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				We then have an empty array ${C:}$ which will store the intersection. An
				important question is what should be the size of ${C?}$ The size of
				${C}$ is computed from the
				<a
					href="{% url 'numerm:disc_setTheory' %}#size_of_intersection_and_union"
					><i>Cardinal Number Formula:</i></a
				>
			</p>
			<figure>
				<div>
					<p>${n(A \cap B) = n(A) + n(B) - n(A \cup B)}$</p>
				</div>
			</figure>
			<p>
				Applying the formula, the size of ${C}$ is the length of ${A}$ plus the
				length of ${B,}$ minus the length of the array resulting from the union
				of ${A}$ and ${B.}$ While this would give us the exact number of spaces
				necessary for the intersection, it would be simpler, and more efficient,
				to use the length of whichever is smaller (in terms of the number of
				elements) between ${A}$ and ${B.}$ This is because the number of
				elements in common between ${A}$ and ${B}$ is at most the cardinality of
				the smaller between the two sets. If ${A}$ is a smaller set than ${B,}$
				then the cardinality of ${A \cap B}$ is at most the cardinality of ${A}$
				(all the elements in ${A}$ are elements in ${B}$). If ${B}$ is a smaller
				set than ${A,}$ then the cardinality of ${A \cap B}$ is at most the
				cardinality of ${B.}$ And if ${A}$ and ${B}$ are of the same
				cardinality, then the cardinality of ${A \cap B}$ is at most the
				cardinality of ${A}$ (or ${B}$).
			</p>
			<p>
				In our case, the arrays ${A}$ and ${B}$ are of the same length, so the
				length of ${C}$ is at most ${5}$ (the elements of ${A}$ are all elements
				${B}$ and vice versa):
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${C = }$</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>

			<p>
				We start by To output the intersection, we compare each element in ${A}$
				against each element in ${B.}$ If there's a match, then: (1) we assign
				the element in ${A}$ to the position in ${C,}$ and (2) increment ${k,}$
				the index for ${C.}$ Comparing element in ${A}$ to each element in ${B}$
				requires ${n \cdot m}$ operations. As such, this algorithm has a time
				complexity of ${O(n^2).}$ This isn't very efficient; it's quadratic
				time.
			</p>
			<p>
				Like the <span class="monoText">union()</span> operation, we can improve
				this runtime if the arrays are sorted before performing
				<span class="monoText">intersection()</span>. Suppose our previous
				arrays were sorted:
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A = }$</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B = }$</td>
							<td>2</td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p><span class="monoText">intersection()</span> then works as such:</p>
			<ol>
				<li>
					Set <span class="monoText">i = 0</span>,
					<span class="monoText">j = 0</span>, and
					<span class="monoText">k = 0</span>.
				</li>
				<li>
					Compare: <span class="monoText">A[i]</span> and
					<span class="monoText">B[j]</span>.
				</li>
				<ol>
					<li>
						If <span class="monoText">A[i] > B[j]</span> increment
						<span class="monoText">j</span>.
					</li>
					<li>
						If <span class="monoText">A[i] < B[j]</span> increment
						<span class="monoText">i</span>.
					</li>
					<li>
						If <span class="monoText">A[i] = B[j]</span>, assign
						<span class="monoText">A[i]</span> to
						<span class="monoText">C[k]</span>, increment
						<span class="monoText">i</span> <span class="monoText">j</span>, and
						<span class="monoText">k</span>.
					</li>
				</ol>
				<li>
					If <span class="monoText">i > A.length</span> or
					<span class="monoText">j > B.length</span>, return
					<span class="monoText">C.</span> Else, return to step 2.
				</li>
			</ol>
			<p>
				With this approach, we have time complexity of ${O(m + n),}$ or more
				generally, ${O(n).}$ This is linear time; a marked improvement from
				quadratic time.
			</p>
		</section>

		<section id="difference">
			<p>
				<span class="topic">Difference.</span> Suppose we had the following
				sets:
			</p>
			<figure>
				<div>
					<p>${A = \{ 3, 5, 10, 4, 6 \}}$</p>
					<p>${B = \{ 12, 4, 7, 2, 5 \}}$</p>
				</div>
			</figure>
			<p>
				The difference between these two sets is the set consisting of elements
				not in both ${A}$ and ${B}$ (i.e., the set without the elements common
				to both ${A}$ and ${B}$). In this case, the common elements are ${4}$
				and ${5.}$ Thus, ${A - B = \{ 3, 10, 6 \},}$ and ${B - A = \{ 12, 7, 2
				\}.}$ We implement this operation as the operator
				<span class="monoText">difference()</span>.
			</p>
			<p>
				With the <span class="monoText">difference()</span> operator, we say
				that order is material. Thus,
				<span class="monoText">difference(A, B)</span> computes ${A - B,}$ and
				<span class="monoText">difference(B, A)</span> computes ${B - A.}$ In
				other words, the arguments to the
				<span class="monoText">difference()</span> operator are noncommutative.
			</p>
			<p>
				Like <span class="monoText">intersection()</span>, we might implement
				<span class="monoText">difference()</span> by comparing each element in
				${A}$ against each element in ${B.}$ If an element in ${A}$ matches an
				element in ${B,}$ we skip that element compare the next. If there is no
				match, we assign the element to the resulting array ${C.}$ Again, like
				<span class="monoText">intersection()</span>, this algorithm requires a
				total of ${n \cdot m}$ operations to execute. This yields a quadratic
				runtime of ${O(n^2).}$
			</p>
			<p>
				Just as we saw with <span class="monoText">intersection()</span>, we can
				improve the time complexity by ensuring the array arguments are sorted
				before performing the
				<span class="monoText">difference()</span> procedure. Suppose the arrays
				are sorted:
			</p>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${A = }$</td>
							<td>3</td>
							<td>4</td>
							<td>5</td>
							<td>6</td>
							<td>10</td>
						</tr>
						<tr>
							<td>${i = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${B = }$</td>
							<td>2</td>
							<td>4</td>
							<td>5</td>
							<td>7</td>
							<td>12</td>
						</tr>
						<tr>
							<td>${j = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<figure>
				<table class="array">
					<tbody>
						<tr>
							<td>${C = }$</td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
							<td></td>
						</tr>
						<tr>
							<td>${k = }$</td>
							<td>0</td>
							<td>1</td>
							<td>2</td>
							<td>3</td>
							<td>4</td>
						</tr>
					</tbody>
				</table>
			</figure>
			<p>
				With the arrays sorted, the
				<span class="monoText">difference()</span> operator's algorithm works as
				such:
			</p>
			<ol>
				<li>
					Set <span class="monoText">i = 0</span>,
					<span class="monoText">j = 0</span>, and
					<span class="monoText">k = 0</span>.
				</li>
				<li>
					Compare <span class="monoText">A[i]</span> with
					<span class="monoText">B[j]</span>.
				</li>
				<ol>
					<li>
						If <span class="monoText">A[i] > B[j]</span>, increment
						<span class="monoText">j</span>.
					</li>
					<li>
						If <span class="monoText">A[i] < B[j]</span>:
						<ol>
							<li>
								Assign <span class="monoText">A[i]</span> to
								<span class="monoText">C[k]</span>.
							</li>
							<li>Increment <span class="monoText">i</span>.</li>
							<li>Increment <span class="monoText">k</span>.</li>
						</ol>
					</li>
					<li>
						If <span class="monoText">A[i] = B[j]</span>, increment
						<span class="monoText">i</span>, increment
						<span class="monoText">j</span>.
					</li>
				</ol>
				<li>
					If <span class="monoText">i > A.length</span>, return
					<span class="monoText">C</span>. Else, return to Step 2.
				</li>
			</ol>
			<p>
				The algorithm above computes the difference ${A - B.}$ As such, when
				difference is called, it is called as
				<span class="monoText">difference(A, B)</span>. To compute ${B - A,}$ we
				perform the same algorithm, but swap
				<span class="monoText">A[i]</span> and
				<span class="monoText">B[j]</span> (and their respective indices) in the
				algorithm above.
			</p>
			<p>
				This algorithm performs in the same manner as the
				<span class="monoText">merge()</span> operator. Accordingly, it has a
				time complexity of ${O(m + n),}$ or, in a single variable, ${O(n).}$
				This is linear time; faster than quadratic time.
			</p>
		</section>
	</section>

	<section id="find_missing_element_sorted">
		<h3>
			Search-and-rescue Algorithms: Algorithms for Finding Missing Elements
		</h3>
		<p>
			A particularly useful set of algorithms associated with arrays is the set
			of algorithms for finding missing elements. As an homage to
			search-and-rescue dogs, we call these algorithms
			<span class="term">search-and-rescue algorithms</span>.
		</p>
		<p>
			Search-and-rescue algorithms are particularly useful when we know that a
			particular sequence should contain certain elements. For example, a
			password, identification number, or waiting list number might have a
			pre-defined rule for what the sequence of digits should be. If the
			sequence is sufficiently long, it would be tedious for us to check, by
			hand, each element one by one just to spot a missing element.
		</p>
		<p>
			This is where the search-and-rescue algorithm comes in. Implementing these
			algorithms depends on four factors: (1) the sequence (implemented as an
			array) to check is sorted; (2) the sequence is unsorted; (3) the sequence
			contains a single missing element; and (4) the sequence contains multiple
			missing elements. For this section, we restrict the search-and-rescue
			algorithms to operating on sequences of numbers. However, our discussion
			should shed light on how these algorithms might be extended to arrays of
			other values, such as strings.
		</p>
		<p>
			First, we consider a sequence implemented as a sorted array. Suppose the
			sorted array is the following:
		</p>
		<figure>
			<div>
				<p>${A = \lang 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12 \rang}$</p>
			</div>
		</figure>
		<p>
			This is the sequence of natural numbers. Although we immediately see that
			the missing element is ${7,}$ the task would be far more difficult if
			${A}$ consisted of a thousand elements. The trick to finding the missing
			element in sorted array is to rely on the sequence's summation formula. In
			this case, the sum of the natural numbers is given by the following:
		</p>
		<figure>
			<div>
				<p>
					${\sum\limits_{k = 1}^{n} k = \dfrac{n(n+1)}{2} \qquad \text{where}
					~~~~ k, n \in \N}$
				</p>
			</div>
		</figure>
		<p>
			Knowing that ${A}$ is the sequence of the natural numbers, we can find the
			sum of ${A}$ if the missing element was present. We'll call this the
			<span class="italicsText">expected sum</span>. In this case, the expected
			sum of the array ${A}$ would be:
		</p>
		<figure>
			<div>
				<p>${\sum\limits_{i = 1}^{12} A_i = \dfrac{12(12 + 1)}{2} = 78}$</p>
			</div>
		</figure>
		<p>
			Next, we compute the sum of ${A}$ as is (without the missing element
			included). We'll call this the
			<span class="italicsText">current sum</span>. To do so, we use our
			familiar
			<a href="#summing_elements"
				><span class="monoText">sum()</span> operator.</a
			>
			In this case, the <span class="italicsText">current sum</span> is ${71.}$
			Once we obtain the current sum, the missing element is the difference
			between the <span class="italicsText">expected sum</span> and the
			<span class="italicsText">current sum</span>:
		</p>
		<figure>
			<div>
				<p>
					${\large A_{\text{missing}} = S_{\text{expected}} -
					S_{\text{current}}}$
				</p>
				<ul class="def">
					<li class="where">${A_{\text{missing}}}$ is the missing element;</li>
					<li>${S_{\text{expected}}}$ is the expected sum; and</li>
					<li>${S_{\text{current}}}$ is the current sum.</li>
				</ul>
			</div>
		</figure>
		<p>Applying this formula:</p>
		<figure>
			<div>
				$$ \begin{aligned} \large A_{\text{missing}} &= S_{\text{expected}} -
				S_{\text{current}} \\ &= 78 - 71 \\ &= 7 \end{aligned} $$
			</div>
		</figure>
		<p>The implementation might look like:</p>

		<ol class="alg">
			<li>${f}$ sum_natural_numbers(n):</li>
			<ol>
				<li>return ((n * (n + 1)) / 2);</li>
			</ol>
			<li></li>
			<li>${f}$ findMissing(A, summation_formula()):</li>
			<ol>
				<li>let current_sum = 0;</li>
				<li>for (i = 0; i < A.length - 1; i++):</li>
				<ol>
					<li>current_sum += A[i];</li>
				</ol>
				<li>let expected_sum = summation_formula(A.lastElement)</li>
				<li>let missing_element = expected_sum - current_sum;</li>
				<li>return missing_element;</li>
			</ol>
			<li></li>
			<li>findingMissing(A, sum_natural_numbers());</li>
		</ol>
		<p>
			With the implementation above, we rely on a separate function,
			<span class="monoText">sum_natural_numbers(n)</span>, to compute the
			expected sum. There may be situations, however, where we do not know the
			summation formula for a particular sequence. Moreover, the call to
			<span class="monoText">sum_natural_numbers(n)</span> requires an
			additional stack frame, and we may have space complexity concerns (certain
			summation formulas can get very complex or require large amounts of
			memory). As such, we consider an alternative implementation.
		</p>
		<p>With the alternative implementation, we rely on the indices of each element in the array. For example, suppose we had the following array:</p>
		<figure>
			<table class="array">
				<tbody>
					<tr>
						<td>${A}$</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
						<td>10</td>
						<td>11</td>
						<td>12</td>
						<td>13</td>
						<td>14</td>
						<td>15</td>
						<td>16</td>
						<td>17</td>
					</tr>
					<tr>
						<td>${i}$</td>
						<td>0</td>
						<td>1</td>
						<td>2</td>
						<td>3</td>
						<td>4</td>
						<td>5</td>
						<td>6</td>
						<td>7</td>
						<td>8</td>
						<td>9</td>
						<td>10</td>
						<td>11</td>
					</tr>
				</tbody>
			</table>
		</figure>
	</section>
</section>

<section id="list">
	<h2>Lists</h2>
	<p>
		The <span class="term">list</span> data type is sequence of variable size.
		The data type may also be called a
		<span class="term">dynamic sequence</span> or
		<span class="term">vector</span>. With variable size, we suddenly have a
		much larger API. This shouldn't be all that surprising &mdash; the more
		properties we can mutate, the more operations we can implement.
	</p>
</section>

<section id="linked_lists">
	<p>
		<span class="topic">Linked Lists.</span> We can implement the dynamic
		sequence type above with a <span class="term">linked list</span>. In a
		linked list, elements in the sequence are stored in
		<span class="italicsText">nodes</span>. Each node consists of: (1) the
		sequence element and (2) a pointer to the next node.
	</p>
	<p>
		With linked lists, there are two points of particular interest: the
		<span class="italicsText">head</span> of the linked list (the first node in
		the linked list) and the <span class="italicsText">tail</span> of the list
		(the last node in the linked list). Importantly, the tail consists of a node
		whose pointer points to nothing (i.e., a
		<span class="italicsText">null pointer</span>).
	</p>
</section>

<section id="array_addressing">
	<h2>Array Addressing</h2>
	<p>
		Whenever we write expressions that index into an array, e.g.,
		<span class="monoText">A[2] = 4</span>, the compiler must translate the
		expression into an address. Because arrays are a fundamental data structure,
		it's worth knowing how this translation is done. Put simply, the compiler
		makes performs this translation by applying a particular formula. For
		example, suppose we initialized the following array:
	</p>
	<pre class="language-c"><code>
		int main() {
			int A[3] = {8, 3, 5};
			return 0;
		}
	</code></pre>
	<p>
		As we know, the identifier <span class="monoText">A</span> is an identifier
		for array's base address &mdash; the address of
		<span class="monoText">A[0]</span>. Suppose the address of
		<span class="monoText">A[0]</span> is <span class="monoText">200</span>.
		This means that the address of <span class="monoText">A[1]</span> is
		<span class="monoText">204</span> (since an
		<span class="monoText">int</span> takes 4 bytes), an the address of
		<span class="monoText">A[2]</span> is <span class="monoText">208</span>.
		Abstracting this computation, we can think of the compiler performing the
		following when it encounters <span class="monoText">A[2]</span>:
	</p>
	<figure class="math-display">
		<div>
			$$ \begin{aligned} \textit{address-of}(A[2])&= \textit{address-of}(A[0]) +
			(2)(4) \\ &= 200 + 8 \\ &= 209 \end{aligned} $$
		</div>
	</figure>
	<p>We can abstract this computation into a formula:</p>
	<figure class="math-display">
		<div>
			<p>${\alpha(a_i) = \alpha(a_0) + i \omega}$</p>
		</div>
	</figure>
	<p>
		In the formula above, ${\alpha(n)}$ is a function that returns the memory
		address of some data ${n}$. Thus, ${\alpha(a_i)}$ returns the address of the
		${i^{\text{\scriptsize{th}}}}$ element of the array, and ${\alpha(a_0)}$
		returns the address of the first element. The variable ${i}$ represents the
		index of the element, and the variable ${\omega}$ represents the size of the
		data type (e.g., the size of the data type
		<span class="monoText">int</span> is 4 bytes).
	</p>
	<p>
		As an aside, many older languages like Fortran use 1-based indexing. C came
		after Fortran, so why do so many languages use 0-based indexing? One reason
		is because of the hardware limitations at the time languages like C, BCPL,
		and Fortran were implemented. With 1-based indexing, we would have to use a
		different formula in determining the address of a given element:
	</p>
	<figure class="math-display">
		<div>
			<p>${\alpha(a_i) = \alpha(a_1) + (i-1)\omega}$</p>
		</div>
	</figure>
	<p>
		There's an additional computation with this formula &mdash; a decrement.
		This additional operation proves to be costly on older machines &mdash;
		there are 3 separate computations. Compare that with the previous formula,
		which calls for only 2 computations. Given that a core goal of C's design
		was efficiency, it made sense to opt for the more efficient implementation.
	</p>
	<p>
		Of course, modern computers have surpassed many of these limitations. The
		additional decrementing operation doesn't make much of a difference for most
		applications. So why then do recent languages go with zero-based indexing?
		Because zero-based indexing has become the norm. C inspired a whole host of
		languages (e.g., C++ and Objective-C), which in turn inspired many others
		(e.g., C to C++ to Java to Kotlin, C to Objective-C to Swift). Given that
		language designers are programmers first and foremost, it isn't all that
		surprising to see a designer sticking with what they're familiar with.
	</p>
	<p>
		Moreover, if often makes more sense to use zero-based indexing over
		one-based indexing. We can appreciate this idea by recognizing that
		<span class="italicsText">indexing</span> is
		<span class="underlineText">not</span> the same as
		<span class="italicsText">counting</span>. Instead, indexing is much more
		akin to <span class="italicsText">offsetting</span> from a given point. For
		example, given the array <span class="monoText">int A[3] = {1, 2, 3}</span>,
		the starting point is <span class="monoText">1</span>. If we designate that
		as the element with index 0 (<span class="monoText">A[0]</span>, the first
		element), then the second element, <span class="monoText">A[1]</span>, is
		the element 1-off the first element. The third element,
		<span class="monoText">A[2]</span>, is 2-off the first element. And so on
		and so forth.
	</p>
</section>

{% endblock %}
