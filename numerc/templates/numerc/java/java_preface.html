{% extends '../layout.html' %} {% load static %} {% block description %}
<meta name="description" content="Introduction to Java" />
{% endblock %} {% block title %}
<title>Java Intro</title>
{% endblock %} {% block content %}
<h1>Foundations I: Java</h1>

<section id="intro">
	<p>
		<span class="drop">C</span>omputer science. What is it? To answer this
		question, we ask another: What does a computer do? Well, we can imagine a
		computer as a <i>black box</i>. A very special box indeed. We feed inputs,
		and the box returns outputs:
	</p>
	<figure>
		<img
			src="{% static 'images/blackbox.svg' %}"
			alt="blackbox"
			loading="lazy"
			width="100px"
			height="100px"
		/>
	</figure>
	<p>
		Inside the black box, we find code and hardware. Various instances of these
		two components work together to take our inputs, process them, and output
		results. But use this black box, we must start the process. We bear the
		burden of feeding the box inputs. But what inputs do we give? This is the
		underlying question of <i>representation</i>.
	</p>
</section>
<section id="representation">
	<h2>Representation</h2>
	<p>
		Consider the concept of numbers. How are those represented? As children (and
		as adults), we use our fingers. Five on one hand for the first five positive
		integers, and five on the other for nine through ten. With two hands
		(assuming no missing fingers), we can represent 10 digits.<sup></sup>
	</p>
	<div class="note">
		<p>
			Some societies, like the ancient Mayans, used their toes for counting as
			well, positing a possible explanation for their vigesimal system&mdash;a
			base-20 representation scheme. For now, we'll stick to base-10. As an
			aside, note that numbers <span class="underlineText">do not</span> have
			bases. Representations do. We count this as a single sentence, whether we
			represent it as one, 1, ‰∏Ä, ‡§è‡§ï, Ÿàÿßÿ≠ÿØ, ., or íêÅ. Humans all count the same
			way; we just represent the count differently.
		</p>
	</div>
	<p>
		For more formal settings, however, we use the
		<span class="termlics">decimal system</span>. In this system, we represent
		numbers in <i>base-10</i>, using Hindu-Arabic numerals to represent the
		numbers 0 through 9: ${\{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}.}$ The descriptor
		base-10 is derived from the fact that with the above digits, we can
		represent numbers with powers of 10. The number 256, for example, is really
		just:
	</p>

	<figure>
		$$ \begin{align*} (2 \times 10^2) + (5 \times 10^1) + (6 \times 10^0) &= 200
		+ 50 + 6 \\ &= 256 \end{align*} $$
	</figure>

	<p>
		Our black box (the computer), however, needs a much simpler system to
		represent numbers, as a matter of efficieny. That simpler system is
		<i>binary</i>.
	</p>

	<p>
		In <i>binary</i>, the numbers are represented entirely by two numerals: $\{
		0, 1 \}$. 0s and 1s are represented in by computers as <b>bits</b
		><sup></sup> 0s and 1s are preferable because computers, at the end of the
		day, work by turning millions of switches off and on: electricity flowing
		(switch on, i.e., <var>0</var>) and electricity not flowing (switch off,
		i.e., <var>1</var>). We can imagine how this works with lighbulbs. With 1
		light bulb, we can count from 0 to 1:
	</p>
	<div class="note">
		<p>
			A contraction of "<b>b</b>inary dig<span class="boldText">its</span>",
			coined by the computer scientists Claude Shannon. In his master's thesis,
			Shannon argued Boolean logic could be used to switch circuits, which in
			turn could be used for arithmetic calculations. Although his work led
			directly to the binary arithmetic necessary for modern computation,
			Shannon received considerable pushback from the scientific community.
		</p>
	</div>

	<figure>
		<img
			src="{% static 'images/lightbulbs.svg' %}"
			alt="light bulbs"
			loading="lazy"
			width="70px"
			height="70px"
		/>
		<figcaption>Light bulb on, light bulb off.</figcaption>
	</figure>

	<p>Can we count higher than 0 and 1? Sure. We just need more light bulbs:</p>

	<figure>
		<img
			src="{% static 'images/threeOffLights.svg' %}"
			alt="light bulbs"
			loading="lazy"
			width="70px"
			height="70px"
		/>
		<figcaption>Three light bulbs.</figcaption>
	</figure>

	<p>
		With 3 light bulbs, there are 8 different arrangements of the light bulbs
		being on or off:
	</p>

	<figure>
		<img
			src="{% static 'images/lightbulbpossibilites.svg' %}"
			alt="light bulb possibilities"
			loading="lazy"
			width="450px"
			height="450px"
		/>
		<figcaption>Light bulb on/off permutations.</figcaption>
	</figure>

	<p>
		The above consists of 8
		<i>unique</i> arrangements. Because they are unique arrangements, we can
		assign them to numbers:
	</p>

	<figure>
		<table>
			<thead>
				<th>Arrangement</th>
				<th>Number</th>
			</thead>
			<tbody>
				<tr>
					<td>0 0 0</td>
					<td>0</td>
				</tr>
				<tr>
					<td>0 0 1</td>
					<td>1</td>
				</tr>
				<tr>
					<td>0 1 0</td>
					<td>2</td>
				</tr>
				<tr>
					<td>0 1 1</td>
					<td>3</td>
				</tr>
				<tr>
					<td>1 0 0</td>
					<td>4</td>
				</tr>
				<tr>
					<td>1 0 1</td>
					<td>5</td>
				</tr>
				<tr>
					<td>1 1 0</td>
					<td>6</td>
				</tr>
				<tr>
					<td>1 1 1</td>
					<td>7</td>
				</tr>
			</tbody>
		</table>
		<figcaption>Possible arrangements of light bulbs.</figcaption>
	</figure>

	<p>
		By assigning arrangements of 1s and 0s to represent numbers, we have
		constructed the
		<b>binary system</b>. The system works exactly like the decimal system, with
		one crucial difference: rather than having 10 unique digits to work with, we
		only have 2; this means that our numbers are written with powers of 2. 12,
		for example, is:
	</p>

	<figure>
		$$ \begin{aligned} (1 \times 2^3) + (1 \times 2^2) + (0 \times 2^1) + (0
		\times 2^0) &= 8 + 4 + 0 + 0 \\ &= 12 \end{aligned} $$
	</figure>

	<p>
		The binary equivalent of 12 then is ${1100_{[2]}}$. The subscripted
		${_{[2]}}$ indicates the number we're using is represented in base-2
		(binary). We could represent 12 as ${12_{[10]},}$ but since there is no
		${2}$ in binary, we can simply write 12.
	</p>

	<p>
		In the light bulbs above, we might have imagined a physical switch to turn
		the light bulbs on and off. In computers, the same concept applies, but the
		switches are tiny devices called
		<b>transistors</b>, and there are millions of them in a modern computer.
	</p>

	<p>
		Thinking carefully about these lights, each bulb has a
		<b>state</b>&mdash;a &#8220;snapshot&#8221; of the present conditions of a
		given system. In a system with just one light bulb, the system only has two
		states: on or off. With two lighbulbs, we have ${2 \times 2 = 2^2 = 4}$
		possible states. This same analysis applies to bits. However, instead of a
		board of light bulbs, the bits are aggregated in <b>main memory</b> (or more
		specifically, <i>Random Access Memory (RAM)</i>). Main memory is effectively
		a representation of a computer's state. If the computer's RAM can only hold
		3 bits, the computer has ${2 \times 2 \times 2 = 2^3}$ possible states. With
		4 bits, the computer has ${2^4 = 16}$ possible states. Most modern computers
		have 8GB of RAM at a minimum. That's ${2^{68,719,476,736}}$ possible states.
		A more expensive computer can have 16GB (${2^{137,438,953,472}}$ possible
		states), and a high-end computer can have 64GB (${2^{549,755,813,888}}$).
		Custom built computers can ship with 128GB (${2^{1,099,511,627,776}}$).
		These are unfathomably large numbers, yet they're surprisingly not enough.
		Pandemic predictions, fluid simulations, climate modelling, encryption key
		generation, natural language processing, economic forecasts &mdash; all of
		these problems require meeting numerous conditions for successful solutions.
		And the more conditions we must meet, the more states we demand of our
		computers.<label for="ramOverkill" class="margin-toggle"><sup></sup></label>
		<input
			type="checkbox"
			id="ramOverkill"
			class="margin-toggle sidenote-number"
		/>
		<span class="marginnote"
			>The average consumer really only needs 8 or 16GB of RAM. These larger RAM
			capacities are primarily aimed at professionals and power users &mdash;
			data scientists, video editors, gamers, software developers working on
			large applications, etc. Of course, not too long ago, we would've said
			4GB, and before that, 500MB. Ideal or not, there's a steady trend of
			producing software under the assumption that because memory has increased,
			space considerations weigh less. This in turn has led to more
			memory-intensive programs. Time will tell whether the numbers in this
			margin note are edited.
		</span>
	</p>

	<p>
		To be clear, binary representation isn't some recent idea. The German
		mathematician Gottfried Wilhelm von Leibniz (the same Leibniz who
		independently discovered calculus and the esoteric monad) described binary
		notation as early as 1703. And even then, Leibniz suggested that the Chinese
		were aware of binary representation some 2,000 years earlier, citing to the
		<i>I Ching</i>. What is relatively recent, however, is using binary to
		represent things other than numbers.
	</p>

	<p>
		For example, letters. Since we can represent many numbers in binary, we can
		represent letters in binary by assigning unique sequences of numbers to
		letters. <label for="victorian" class="margin-toggle"><sup></sup></label>
		<input
			type="checkbox"
			id="victorian"
			class="margin-toggle sidenote-number"
		/>
		<span class="marginnote"
			>Using numbers to represent letters is not all that different from Morse
			code, the archetype of the telegraph. The telegraph itself has an
			interesting relationship to modern day computers. As presented in Tom
			Standage's book
			<em
				><a
					href="https://tomstandage.wordpress.com/books/the-victorian-internet/"
					target="_blank"
					>The Victorian Internet</a
				></em
			>, many internet-related phenomenon we're familiar with &mdash; hacking,
			chat rooms, scammers, heated debates, and information leaking &mdash; have
			analogues in the age of telegraphs. Indeed, there were &#8220;online
			romances&#8221; by the mid-1800s.</span
		>
		The letter A, for example, is represented by the sequence 65. Every letter
		in the English alphabet (as well as all the punctuation symbols we're
		familiar with) are assigned unique numbers. The system of these assignments
		is called ASCII ("American Standard Code for Information Interchange").
	</p>

	<figure>
		<img
			src="{% static 'images/asciiexample.svg' %}"
			alt="ASCII representation"
			loading="lazy"
			class="sixty-p"
		/>
		<figcaption>Character to ASCII to binary.</figcaption>
	</figure>

	<p>
		As an aside, there really is no rhyme to these assignments&mdash;a group of
		computer scientists simply sat down and said, "Let's use this number for
		this." There is, however, a reason. Character codes only work if computer
		manufacturers implement them. Without
		<b>standardization</b>&mdash;setting minimum requirements to be met by all
		users&mdash;it is much harder to share data across machines. A recurring
		theme in the history of computer science is setting standards. The internet,
		language libraries, character encodings, data representations, these are all
		examples of standards. And as we'll see throughout these materials, violated
		standards can wreak havoc. Internet Explorer, for example, is the bane of
		web development. Put bluntly, web developers hoping to design sophisticated
		websites that look the same on all browsers must jump through hoops to work
		with Internet Explorer. This is largely because Microsoft obtained a near
		monopoly on the browser market and decided to forgo web standards. As
		browsers like Google Chrome and Firefox obtained increased market share, web
		development grew increasily complex, reaching the Wild West landscape it is
		today.
	</p>

	<p>
		This doesn't mean, however, that standards should never be rejected. In
		ASCII, for example, the encodings are typically represented by 8 bits. Thus,
		when we send a Snapchat message "HI!", we are &mdash; roughly speaking
		&mdash; sending 24 bits of data. With 8 bits, we can represent 256 different
		characters, since each bit can either be a 0 or a 1 ($2^8 = 256$). Bits,
		however, are not a very useful unit of measurement, since they can very
		rapidly grow into large numbers (the characters H, i, and ! took up 24 bits
		alone&mdash;imagine how many bits a paragraph or a Wikipedia article takes).
		Because of this problem, we measure bits in
		<b>bytes</b>. A byte is simply 8 bits.<label
			for="bitsNibble"
			class="margin-toggle"
			><sup></sup
		></label>
		<input
			type="checkbox"
			id="bitsNibble"
			class="margin-toggle sidenote-number"
		/>
		<span class="marginnote"
			>Half a byte&mdash;a sequence of 4 bits&mdash;is called a
			<b>nybble</b>.</span
		>
	</p>

	<p>
		But a byte is extremely limiting&mdash;it only represents 256 characters,
		and human language consists of many, many more: accents over English
		characters, characters from different languages, mathematical and logical
		symbols, scientific symbols, emojis, etc. Because of ASCII's limitations,
		another standard, <b>Unicode</b> was created to assign numbers to
		characters, now used by most modern computers. This standard shift was only
		made possible because software and hardware producers decided to move on
		from ASCII.
	</p>

	<p>
		Having said all this, how does the computer know that we're referring to the
		letter A rather than the number 65? This is actually a remarkably complex
		question. For now, we will say that it simply remains &#8220;mindful&#8221;
		of what program we're executing (i.e., it has some notion of memory, and it
		can &#8220;remember&#8221; what it was doing before, and what it is doing
		currently). Using its capacity for memory, the computer will interpret 65 as
		a number only if certain conditions are true, and interpret 65 as a letter
		only if other conditions are true.
	</p>

	<p>
		<span class="topic">Representing Colors.</span> Not only are numbers
		assigned to characters, they can also be assigned to represent colors. There
		are a variety of different systems of assigning numbers to colors. In the
		<b>RGB color model</b>, colors are represented in the form
		<var>rgb(value, value, value)</var>, where each channel (indicated by
		"value") represents the color's red, green, and blue values respectively.
		This system works because every color can be made by mixing the colors red,
		green, and blue. The values in each of the channels essentially indicates
		the amount of each color to be "mixed." The values themselves are most
		commonly expressed as numbers. In an <i>8-bit per channel</i> system, for
		example, each of the channels can take a value ranging from 0 (no value) to
		255 (highest value). For example, the color
		<var>rgb(0, 0, 0)</var> represents the color white (the absence of color),
		while
		<var>rgb(255, 255, 255)</var>
		represents black (all of the channels at maximum value).
	</p>
	<p>
		Once we tell the computer what color we want, the computer takes that value,
		and displays the color on a
		<i>pixel</i> of the screen. Each pixel uses approximately 24 bits (8 bits
		per channel, since it takes 8 bits to represent numbers up to 255), or 3
		bytes. This should give us a hunch for why high resolution images are
		generally large files on a computer.
	</p>

	<p>
		<span class="topic">Representing Images.</span> With the ability to
		represent colors, we can represent images. Images on a computer are simply
		an arrangement of pixels, where each pixel is assigned a color. In fact, we
		can confirm this is the case by zooming in very closely on an image. Find a
		complex image and try it. Notice that when we zoom in as much as we can, we
		notice small squares filled with colors.
	</p>

	<p>
		<span class="topic">Representing Motion.</span> On a computer, videos are
		really just images changing rapidly, which, by implication, are just colors
		changing rapidly. By changing a pixel's color once per unit of time, when
		all of the changes (to hundreds of thousands of pixels) are viewed all at
		once, we, as the viewer, see changes in shapes and swaths of colors, which
		in turn is perceived as motion. A good way to think about this is to recall
		the flipbook animations we played with as children. On each page, there are
		slight changes in the drawing. Because of these slight changes, flipping
		through the pages creates the illusion of motion.
	</p>

	<p>
		<span class="topic">Representing Sound.</span>
		In terms of physics, what we perceive as sound is actually an
		<i>acoustic wave</i> propagating through space, reaching our eardrums and
		perceived by the brain. The greater a sound wave's <i>amplitude</i> is, the
		louder the perceived sound is, and the larger its <i>frequency</i>, the
		higher its pitch. Moreover, the longer a sound wave's <i>duration</i> is,
		the longer we perceive the sound. These scalars (amplitude, frequency, and
		duration), are present in all "notes," and are readily measurable.
		Unsurprisingly, sound can be represented by assigning numbers to these
		values.
	</p>

	<p>
		This discussion on representation reveals why there are so many different
		file extensions. Anyone who has worked with computers can easily note that
		there are hordes of different file extensions: .zip, .pdf, .jpeg, .mp4,
		.txt, .doc, .ppt, .html, .rtf, .py, .js, .java, ad nauseam. These file
		extensions indicate a <i>file format</i>&mdash;a set of rules humans have
		agreed on as to how information should be represented and organized.
	</p>

	<p>
		Now that we have a general idea of how to represent information (the inputs
		and outputs problem), we return our attention to the black box. What exactly
		happens inside this mysterious box? The black box processes all of the
		inputs we pass through to it with
		<i>algorithms</i>. An <b>algorithm</b> is a sequence of steps to solving a
		problem.
	</p>

	<p>
		Algorithms are not unique to computers. Assembling furniture from Ikea;
		calculating a tip; completing an assignment; composing an email; changing a
		flat tire&mdash;these are all problems and tasks that have an algorithm:
		steps to an outcome. The difference for algorithms in computers: There are
		no ambiguities. A recipe might say, "add a pinch of salt," but a computer
		has no way of understanding what a "pinch" is, unless we define it. This is
		because all of the information we provide a computer, and all of the
		information a computer gives back, is entirely 0s and 1s. That is all a
		computer knows&mdash;numbers.
	</p>

	<p>
		For example, consider the way we look up the word "rapscallion" in a
		dictionary. There are several ways to find the word:
	</p>

	<ol>
		<li>
			Examine each page, one at a time, until we reach "rapscallion." This
			method would obviously work, but it would take us a great deal of time.
		</li>
		<li>
			Examine every other page, going back a page if we go too far, until we
			reach "rapscallion." This would also work, but it would still take time,
			albeit less than the first approach.
		</li>
		<li>
			Split the dictionary in half; look at the first page of the two halves;
			toss the half further from the word; split the remaining half again; look
			at the first page of the two halves; toss the half further from the word;
			split; over and over until we reach "rapscallion." This is, in fact, how
			most of us would search for the word.
		</li>
	</ol>

	<p>
		The three ways above are all
		<i>algorithms</i>. More importantly, we can write them in a language the
		computer can understand. Here, we use <i>pseudocode</i>, a language that is
		code-like, but not a programming language:
	</p>

	<pre class="language-pseudo"><code>
			pick up dictionary;
			open to middle;
			look at page;
			if word is on page 
			{
				quit;
			}
			else if word is earlier in dictionary 
			{
				open to middle of left half;
				go back to line 3;
			}
			else if word is later in dictionary 
			{
				open to middle of right half;
				go back to line 3;
			}
			else 
			{
				quit
			}
		</code></pre>

	<p>
		Algorithms, however, are just one aspect of computer science. As a whole,
		computer science is an amalgamation of subjects related to computation.
		Programming&mdash;the study and practice of creating, implementing, and
		improving algorithms under software engineering principles&mdash;is just one
		such subject.
	</p>

	<p>
		Computer science is also focused on
		<b>theory</b>. Here, we ask questions about <i>computational complexity</i>,
		computability, and cryptography. How much time does it actually take for an
		algorithm to complete? Is a problem solvable via programming? How do we
		encrypt? These are all questions relating to <i>computer science theory</i>.
	</p>

	<p>
		Another field is
		<i>programming languages</i>. In this field, we ask questions about the
		semantics of a language; formal verification; compilation. And there are
		even more fields&mdash;graphics, data representation, artificial
		intelligence, systems.
	</p>
</section>

<section id="from_source_to_zero">
	<h2>From English to Bits</h2>
	<p>
		Ok, so we know that computers only understand 0s and 1s. However, for us to
		get the computer to actually do what we want it to do, we need to feed it
		instructions that look like natural language, i.e., English. So now there's
		a piece missing in the puzzle: How do we go from the pseudocode instructions
		to the 0s and 1s? To answer this question, we briefly discuss the history of
		computers.
	</p>

	<p>In the beginning, very first programs looked something like this:</p>

	<pre class="language-pseudo"><code>
		0011001 00001101 00110001
		1100011 00010011 10101111
		0000110 00111001 00110010
		0001100 00101101 01101010
	</code></pre>

	<p>
		But instead of actually typing the 1s and 0s, as displayed above,
		programmers had to punch holes into cards and feed those cards to the
		computer. As we can imagine, this was a tedious process for various
		computations (but still faster than doing the computations by quill and
		ink). With complex enough computations, however, the discipline and
		attention to detail needed for punching these holes was untenable.
	</p>

	<p>
		Eventually, we got around to using keyboards, but even then, we weren't, and
		still aren't, very good at reading and writing large sequences of 1s and 0s.
		Because of this diffculty, some very smart folks at companies like Intel and
		AMD came up with ways to define unique sequences of 0s and 1s as words,
		letters, and characters. All of these words and letters, put together, form
		a
		<b>machine language</b>.
	</p>

	<p>
		Machine languages, however, are just as diffcult to write. They're filled
		with cryptic symbols and numbers like <var>JMP</var> and <var>LDY</var>.
		Programs in machine language look like a smorgasbord of acronyms, numbers,
		and special characters:
	</p>
	<pre class="language-bash"><code>
		6      5     5     5     5      6 bits
		[  op  |  rs |  rt |  rd |shamt| funct]  R-type
		[  op  |  rs |  rt | address/immediate]  I-type
		[  op  |        target address        ]  J-type
	</code></pre>
	<p>
		Worse, machine languages vary by machine (or more precisely, by
		<i>machine architecture</i>). This made it enormously costly, in labor and
		time, to write <b>cross-platform programs</b>&mdash;programs that could run
		on different platforms like computers. Because of these difficulties, humans
		began making <b>high-level languages</b> such as Java&mdash;the language
		used in this volume. With high-level languages, programs are much more
		readable. For example, a computer program in some high-level language might
		look like:
	</p>

	<pre class="language-pseudo"><code>
		if (todayIsMyBirthday == true) 
		{
			display("Happy birthday!")
		} 
		else 
		{
			display("Sorry, not your birthday yet.")
		}
	</code></pre>

	<p>
		But how do these words and symbols in a high-level language&mdash;called
		<b>source code</b>&mdash;transform, or translate, into 1s and 0s? Through a
		process called <b>compilation</b>. Essentially, the instructions we wrote in
		the hypothetical high-level language above are sent to another program,
		called the <b>compiler</b>, and the compiler translates the instructions
		into something called <b>object code</b>. Roughly, object code consists of
		the low-level instructions the machine understands. This object code is
		contained in something called an <b>object file</b>.
	</p>
	<p>
		Now, our high-level language program might rely on source code from another
		file. That other file will also yield an object file. All these separate
		object files are then <b>linked</b> by a <b>linker</b>. The linker then
		returns a single file, called an <b>executable file</b>&mdash;containing all
		of the program's object code. This executable contains all the instructions
		the computer understands. When we double click a Word file on our computer,
		or open Safari, we are <i>running</i> or <i>executing</i> an executable
		file.
	</p>
</section>

<section id="java_preface">
	<h2>What is a computer program?</h2>
	<p>
		A <b>program</b> is a set of instructions to be carried out by a computer.
		When the computer carries out the instructions, the program is said to have
		<i>executed</i>. Like humans, computers can only carry out those
		instructions if it actually understands the them. However, unlike humans,
		computers can only understand 0s and 1s. To ensure our instructions are
		translated to 0s and 1s, we write our instructions in a
		<b>programming language</b> &mdash; a systematic set of rules used to
		describe computations in a format that we, as humans, can edit.
	</p>
	<p>
		Java is just one example of a programming language. It's a general-purpose,
		object-oriented, platform-independent, and concurrent programming language.
		That's a lot to unpack, so let's go over each term slowly.
	</p>
	<p>
		A general-purpose language is a language that's not constrained to one
		particular problem domain. By problem domain, we mean &#8220;kinds of
		problems.&#8221;
	</p>
	<p>
		There are many kinds of problems&mdash;finance problems, medical problems,
		legal problems, math problems, physics problems, language problems, etc.
		Now, some languages are better than others for certain problems. For legal
		problems, there is &#8220;legalese.&#8221; For physics, there is mathematics
		and statistics. For mathematics, there is symbolic manipulation and rigorous
		proof. And for any given problem, we want to use the appropriate language.
		When the President of the United States hopes to defend his new economic
		reform plan, he doesn't go up to the podium and explain economic theory or
		cite mathematical lemmas. He references history, appeals to emotion and
		logic, and attacks the other side&mdash;in essence, rhetoric.
	</p>
	<p>
		The same goes for programming languages. Some languages were designed to
		tackle specific problems. Matlab is a powerful programming language for
		physics-related problems, but we wouldn't use it to build websites. C++ is a
		great programming language for making operating systems, but it would be
		overkill for small things like auto-responding to emails. Java is a
		general-purpose language. We can use it for virtually any problem (granted,
		there are problems where another language might be a better fit).
	</p>
	<p>
		Next, Java is object-oriented. This is a
		<b>computer paradigm.</b> A computer paradigm is an overloaded term (i.e.,
		lots of people argue over what it means), but we can think of it as a
		philosophy of doing things, or a philosophy of solving problems. In
		object-oriented programming (&#8220;OOP&#8221;), the philosophy is roughly
		this: Real-world entities can be thought of as objects, and all objects have
		a type. We will elaborate further on this idea in later sections.
	</p>
	<p>
		Java is platform-independent. When the language was first released, its
		motto was &#8220;Write once, run anywhere.&#8221; At the time Java was
		released, most programs were machine-dependent. I.e., if we wrote a program
		on a Dell, there was no guarantee it would run on a Mac. Java was designed
		to avoid this problem: We can write programs on Macs, Dells, Acers, or
		Toshibas, and the same program could be run on a different computer. We will
		see how Java gets around this problem shortly.
	</p>
	<p>
		Finally, Java is a concurrent language. Historically, programming languages
		were <b>single-threaded</b>: Programs written in the programming language
		could only do one thing at a time. With concurrency, we now have
		<b>multi-threaded</b> languages; languages that allow their programs to
		perform more than one thing at a time. One way to think about
		single-threaded and multi-threaded: John gets off of work, arrives home, and
		realizes he needs to do laundry and cook dinner. Under single-threaded
		languages, John would have to either do the laundry first or cook dinner; he
		can't do both. Under multi-threaded languages, John could do his laundry
		while he cooks dinner. This isn't the best analogy, but we will elaborate
		further on the idea of concurrency in later sections.
	</p>
	<p>
		The instructions we write in a program are broadly referred to as
		<b>source code</b>. When we're ready to execute, we <i>compile</i> the
		program, whereupon the <i>Java compiler</i> translates our source code into
		<b>byte code</b>&mdash;code that the computer understands.
	</p>
	<p>
		There are numerous programming languages, many of which are designed with a
		particular &#8220;philosophy&#8221; or &#8220;principle.&#8221;
		<i>Procedural languages</i> are those whose programs are a series of
		commands. These languages include Pascal and C.
		<i>Functional programming languages</i> are premised on the idea that
		programs are composed of functions, mapping inputs to outputs. Examples of
		such languages include Lisp, ML, and Haskell. Then there are
		<i>object-oriented languages</i> &mdash; programs are composed of
		interacting &#8220;objects.&#8221; This family includes Smalltalk, C++, and
		Java. Finally, there are <i>logic programming languages</i>, where programs
		consist of sentences in logical form, expressing facts and rules about
		problems. This group includes languages like Prolog and Datalog.
	</p>
	<p>
		Most languages result from programmers attempting to solve a problem where
		either (a) there was no language available, or (b) an existing language was
		insufficient. For example, C is used primarily for low-level operating
		systems and devices, and C++ was the result of C not providing a means for
		object-oriented design. JavaScript was borne out of frustrations with static
		web pages.
	</p>
	<p>
		Java, the language explored in these next sections, was originally intended
		for use by embedded systems&mdash;devices like digital timers, MP3 players,
		recording devices, etc. Over time, however, it began to be used for web
		applications. If we use a very old web browser and visit very old webpages,
		we might see this historical fact in the form of Java applets (if you don't
		know what those are, that's a good thing; Java applets have been outdated
		for many, many years). Today, JavaScript has taken that mantle, but Java is
		now the language of choice for the most popular mobile operating system,
		Android OS. Moreover, along with Python, Java is a common language for
		introductory computer scince courses.
	</p>
	<p>
		For next few sections, we will place all of our Java source code inside the
		space indicated:
	</p>
	<pre class="language-java"><code>
		import java.lang.*

		class Intro {
			public static void main(String[] args) {

			/* 
			* For now, assume all of the 
			* example code 
			* is placed here
			*/

			}
		}
	</code></pre>
	<p>
		The above is the skeleton of a Java program. In
		<var>class Intro</var>, the word <var>Intro</var> is the name of a
		<i>class</i> (we will discuss this in more detail later), and it is also the
		name of the file containing our source code &mdash; <var>Intro.java</var>. A
		class name does not always have to be the same name as our file, but for
		now, pretend that such is the rule.
	</p>
	<p>
		Inside the class <var>Intro</var>, we have a <i>method</i> called
		<var>main()</var>. We will revisit methods more rigorously in later
		sections, but for now, think of it as containing a sequence of instructions.
		We call these instructions <b>statements</b>. All of our source code for the
		next few sections is placed inside the curly braces following
		<var>main()</var>. We call this method the <b>main driver</b>&mdash;it's the
		method that directs the entirety of our program.
	</p>
	<p>
		For those who have never seen programming at all, explaining the rest of the
		symbols will likely not mean much. Nevertheless, we present some exposition
		now if only for a glimpse of what lies ahead.
	</p>
	<p>
		The keywords <var>String args[]</var> indicate that <var>main()</var> takes
		a list of <i>strings</i> as input. Essentially, we can pass command-line
		arguments to the program as input. We will see an example of doing so
		shortly. The keyword <var>void</var> indicates that <var>main()</var> does
		not return anything.
	</p>
	<p>
		The keyword
		<var>public</var> is prepended to <var>main()</var> because
		<var>main()</var> must be seen by the <i>Java Virtual Machine</i>. More
		generally, the word <var>public</var> instructs Java that other programs or
		blocks of code can access the class. In Java, all programs are defined as
		public classes because some other application, such as the JVM, must be able
		to start the programs up.
	</p>
	<p>
		The line <var>import java.lang.*</var> is called an <b>import statement</b>.
		This instructs Java to look into the contents of <var>java.lang</var>, a
		<b>library package</b>, if we use words inside our program we haven't
		defined ourselves. What's a library package? It's a collection of tools
		written by other programmers that perform specific operations. For example,
		instead of writing a program that counts all the words in a file ourselves,
		we could instead import a program someone else has written to do just that.
		Import statements are what allow us to avoid reinventing the wheel.
	</p>
	<p>
		The word <var>static</var> is included because the general rule for methods
		is that we must create an instance of the class to call the method. However,
		we can get around this general rule by prepending the keyword
		<var>static</var>. This allows JVM to call <var>main()</var> without an
		instance of <var>Intro</var>.
	</p>
	<p>
		We will explore what the rest of the words mean as we continue. For now,
		let's run a simple program:
	</p>
	<pre class="language-java"><code>
		import java.lang.*

		class Intro {
			public static void main(String[] args) {
				System.out.println("Hello, world!");
			}
		}
	</code></pre>
	<pre class="language-bash"><code>
		<span class="blueText">$</span> javac Intro.java
		<span class="blueText">$</span> java Intro

		Hello, world!
	</code></pre>
	<p>
		In the demo above, the source code is indicated by the first code example,
		color coded. The dark block below the code example is the
		<i>console</i>. The console can be viewed and used through various programs.
		For example, on a Mac, it's called the <i>Terminal</i>. Lines indicated with
		a <var>$</var> sign communicate a command. Thus, to run our simple
		<var>Intro.java</var> program, we must first type
		<var>javac Intro.java</var>, hit enter, then type <var>java Intro</var> and
		hit enter. The resulting line, with no <var>$</var>, is the program
		<i>output</i>.
	</p>
	<p>
		For those with some experience in programming, the line
		<var>System.out.println()</var> indicates that there is a class called
		<var>System</var>, with an object called <var>out</var>, that has a method
		called <var>println()</var>.
	</p>
	<p>Here is another example:</p>
	<pre class="language-java"><code>
		class Demo {
			public static void main(String[] args) {
				int x = 5;
				int y = 6;
				System.out.println(x + y);
				int z = x + y + 1;
				System.out.println(z);
			}
		}
	</code></pre>
	<pre class="language-bash"><code>
		11
		12
	</code></pre>
	<p>
		This is a simple arithmetic computation in Java. As we've seen, computers
		can do simple math. Another example:
	</p>
	<pre class="language-java"><code>
		class Demo {
			public static void main(String[] args) {
				int temperature = 
				if (temperature < 0) {
					System.out.println("Ok this is cold")
				} else {
					System.out.println("Meh, typical winter")
				}
			}
		}
	</code></pre>
	<pre class="language-bash"><code>
		Line 3: error: extraneous input 'if' expecting {'boolean', 'byte', 'char', 'double', 'float', 'int', 'long', 'new', 'record', 'short', 'super', 'switch', 'this', 'void', DECIMAL_LITERAL, HEX_LITERAL, OCT_LITERAL, BINARY_LITERAL, FLOAT_LITERAL, HEX_FLOAT_LITERAL, BOOL_LITERAL, CHAR_LITERAL, STRING_LITERAL, TEXT_BLOCK_LITERAL, 'null', '(', '{', '<', '!', '~', '++', '--', '+', '-', '@', IDENTIFIER}
		if (temperature < 0) {
		^
		Line 3: error: missing ';' at '{'
		if (temperature < 0) {
								^
		Line 5: error: extraneous input 'else' expecting {'abstract', 'assert', 'boolean', 'break', 'byte', 'char', 'class', 'continue', 'do', 'double', 'final', 'float', 'for', 'if', 'import', 'int', 'interface', 'long', 'native', 'new', 'private', 'protected', 'public', 'record', 'return', 'short', 'static', 'strictfp', 'super', 'switch', 'synchronized', 'this', 'throw', 'transient', 'try', 'void', 'volatile', 'yield', 'while', DECIMAL_LITERAL, HEX_LITERAL, OCT_LITERAL, BINARY_LITERAL, FLOAT_LITERAL, HEX_FLOAT_LITERAL, BOOL_LITERAL, CHAR_LITERAL, STRING_LITERAL, TEXT_BLOCK_LITERAL, 'null', '(', '{', '}', ';', '<', '!', '~', '++', '--', '+', '-', '@', IDENTIFIER}
		} else {
		^
		3 errors
	</code></pre>
	<p>
		The code above was supposed to compute a simple conditional. But, the output
		is a large error message. This is a typical error message in Java. In this
		case, the error message is telling us we neglected to assign a value to the
		variable <var>temperature</var>. If we actually assign a value to
		<var>temperature</var>:
	</p>
	<pre class="language-java"><code>
		int temperature = 10
		if (temperature < 0) {
			System.out.println("Ok this is cold")
		} else {
			System.out.println("Meh, typical winter")
		}
	</code></pre>
	<pre class="language-bash"><code>
		Meh, typical winter
	</code></pre>
	<p>
		Now the code works. Computers are good at making simple decisions. Here is
		another example:
	</p>
	<pre class="language-java"><code>
		long i = 0;
		while (i < 1000000L) {
			i++;
		}
		System.out.println("Finished");
	</code></pre>
	<pre class="language-bash"><code>
		Finished
	</code></pre>
	<p>
		The code above incremented the value <var>0</var> by 1 a million times
		before it outputs the string <var>"Finished"</var>. Executing this code, it
		takes less than a second to output the string. Compare that to how long it
		would take a human. If you held then dropped a tennis ball, a typical modern
		computer could easily have executed over a billion instructions before the
		ball even hit the floor. Computers can perform repetitive tasks very very
		quickly.
	</p>
	<p>Computers can also communicate:</p>
	<pre class="language-java"><code>
		System.out.println("Hello, world!");
	</code></pre>
	<pre class="language-bash"><code>
		Hello, world!
	</code></pre>
	<p>Putting it all together, computers are good at four things:</p>
	<ol>
		<li>Basic arithmetic</li>
		<li>Simple decision making</li>
		<li>Repeating tasks over and over again, very fast</li>
		<li>Communicating</li>
	</ol>
	<p>
		These are all things we generally aren't very good at. We might be good at
		the fourth point, but really, when it comes to communicating
		<i>efficiently</i> and <i>clearly</i>, most of us fall short.
	</p>
	<p>
		These four points evidence an implicit value of studying computer science
		&mdash; it teaches us more about what separates humans from everything else.
		The conjecture: If a computer can do $x$, where $x$ is some activity, then
		$x$ is <span class="underlineText">not</span> a uniquely human activity.
	</p>

	<section id="programming_conventions" class="grid-item">
		<h3>Writing Programs <i>Well</i></h3>
		<p>
			Programming involves writing statements in a language. Because these
			statements are written, they inevitably are read, whether by others or our
			future selves. And where there are statements to be read, there are
			distinctions between
			<i>well-written programs</i> and <i>poorly-written programs</i>.
		</p>
		<p>Generally, a program's writing quality depends on a few factors:</p>
		<ol>
			<li><b>Correctness</b>. Does the program work as intended?</li>
			<li>
				<b>Clarity</b>. Is the program clearly written? I.e., can an unfamiliar
				reader read and understand the program?
			</li>
			<li>
				<b>Conciseness</b>. Is the program concise? I.e., does it accomplish its
				intent with the minimum amount of statements necessary, without
				sacrificing clarity?
			</li>
			<li>
				<b>Style</b>. Does the program follow the prevailing conventions for
				writing statements? I.e., capitalization, punctuation, proper use of
				words, etc.
			</li>
		</ol>
		<p>
			Considering these factors, computer science is perhaps the ultimate
			embodiment of mathematics, science, engineering, linguistics, and
			philosophy. We approach problems like mathematicians, design our solutions
			like engineers, test hypotheses and evaluate results like scientists, all
			while bearing in mind that what we write is meant to be conveyed and
			understood by both humans and non-humans, a highly linguistic issue. Later
			in these materials, when we discuss how programming languages are made and
			how our programs affect others, we quickly discover that philosophy plays
			an enormous role as well.
		</p>
	</section>
</section>

<section id="classes_and_objects">
	<h2>Object-Orientation</h2>
	<p>
		As its name suggests, object-oriented programming (OOP) is all about
		objects. We won't go into the details of what OOP is, but we'll provide a
		brief description.
	</p>
	<p>
		OOP was borne out of the need to implement large, complex solutions in a
		simple ways. The OOP approach is to model real-world entities and ideas in
		the most natural way possible. This is accomplished by adopting the
		following axiom: Everything in the world has (1)
		<i>properties</i> and (2) <i>behavior</i>. For example, a person is a
		real-world entity. The person has properties like a name, an age, likes,
		dislikes, they might be single or with a partner, they might have a job, a
		political subscription, etc. These are all properties. But the person also
		has behavior: They can eat, drink, for some, talk, walk, run, and many more.
	</p>
	<p>
		Now, there are different <i>kinds</i> of persons. We might think of them as
		<i>subsets</i> of persons. A person might be a student, in which case they
		have additional properties: The school they attend, their student ID number,
		the courses they're registered for. They also have additional behavior:
		Studying, going to the gym, socializing, running to lecture, etc. Another
		person might be a voter: They have the property of where they are registered
		to vote and the act of voting.
	</p>
	<p>
		Where OOP shines is through the notion of
		<i>classes</i>. We can think of a class as a mathematical set, containing
		two things: properties and behavior. And as we know from mathematics, a set
		can contain subsets. If a set ${student}$ is a subset of ${person,}$ and
		we're told that someone named Jane is a ${student,}$ we can deduce that Jane
		is a ${person.}$ This idea of sets and subsets is a cornerstone of
		object-oriented programming. If Jane is a student, then she has all the
		properties and behaviors of a person, as well as all the properties and
		behaviors of a student. She eats, sleeps, goes to the gym, and runs to
		lecture. If this all seems a bit mysterious and blurry, don't worry. We'll
		get a clearer picture once we get to discussing classes and inheritance. For
		now, just know that OOP is just a style of programming, and Java follows it
		strictly.
	</p>
</section>
{% endblock %}
