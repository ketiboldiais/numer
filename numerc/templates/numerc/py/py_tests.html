{% extends '../layout.html' %} {% load static %} 

{% block description %}
<meta name="description" content="Testing and debugging in Python">
{% endblock %}
{% block title %}
<title>Python: Testing & Debugging</title>
{% endblock %}

{% block content %}
<h1>Testing and Debugging</h1>
<section id="testing_and_debugging">
	<p>
		Programs rarely ever run perfectly on first attempt; bugs are a part of the
		programming experience. Their pervasiveness, however, has led to numerous
		techniques and tactics of dealing with them, i.e.,
		<span class="term">debugging</span>. In fact, there are so many approaches
		that there are entire courses dedicated to testing and debugging. In the
		next few sections, we cover some of those approaches from a Python
		perspective.
	</p>
	<p>
		Testing and debugging can be conceptualized by analogy: Suppose we are
		making a soup, but bugs keep descending from the ceiling, landing perfectly
		in our pot. Now, assuming we have no palette for insectoids, how might we
		prevent these unwanted ingredients?
	</p>
	<p>
		One way is to simply carry on making the soup, checking the soup for bugs as
		we go. Another way is to make sure the lid is closed. Or, we could simply
		evade the entire problem by cleaning our kitchen before we begin making the
		soup. Each of these three approaches corresponds to testing and debugging.
	</p>
	<p>
		<span class="topic">Testing and Validation.</span> Checking the soup for
		bugs is akin to <span class="term">testing</span>. Here, we put our code
		through various tests that reveal bugs. Here, we resolve (or pick out) the
		bugs as they appear. The first step to testing is asking: How do I break my
		program? Assuming we defensively programmed right from the get-go (which we
		should have done), we can come up with ways of breaking our program by
		checking the our comments and function specifications.
	</p>
	<p>
		<span class="topic">Defensive Programming.</span> Ensuring the lid is closed
		is akin to <span class="term">defensive programming</span>. With defensive
		programming, we write our code according to a plan that anticipates and
		prevents, or at least detects, bugs. To defensively program, we want to make
		sure we write specifications for functions. We also want to modularize our
		programs. This is such an important point. We do not want to write massive
		functions; break. it. up. This prevents possibilities of
		cross-contamination. At every piece of code taking inputs and returning
		outputs, we ought to check conditions on inputs and outputs.
	</p>
	<p>
		<span class="topic">Debugging.</span> Cleaning the kitchen is akin to
		<span class="term">debugging</span> &mdash; eliminate the root source. In
		debugging, we go right to where all the bugs are coming from. While this
		obviously solves the problem full stop, it is easier said than done. Of the
		three approaches, debugging is generally the most difficult, particularly
		with gargantuan programs. Our first approach to debugging should be to
		examine the events leading up to the error. What are the causes and the
		effects? The necessary and sufficient conditions?
	</p>
</section>

<section id="classes_of_tests">
	<h4>Classes of Tests</h4>
	<p>
		Testing and debugging is several magnitudes easier when we plan effectively
		before coding. From the very beginning, we need to ensure that our program
		easily supports testing and debugging. This is done in two ways: (1) by
		decomposing our program into smaller, separate modules; and (2) clear
		documentation.
	</p>
	<p>
		Testing and debugging is a nightmare with gargantuan programs. Programs can
		easily increase to over a thousand lines, and with every increase, the more
		difficult it is to find problems. By breaking the program into smaller
		pieces, it is much much easier to pinpoint where problems are.
	</p>
	<p>
		However, even the most modular programs can yield little to no aid if they
		are undocumented or unclearly documented. Indeed, an oft-repeated sentiment
		among programmers embarking on large open source projects is lack of
		documentation. Every program module should document two things: (a) The
		module's constraints. What do we expect the input to be? What do we expect
		the output to be? And (b), the module's assumptions. What are we assuming is
		true for the module's computation? What are we assuming is false? Does the
		module depend on another module? These are all questions that should be
		answered in documentation.
	</p>
	<p>
		With documentation, always err on the side of over-documenting rather than
		hand-waiving. What might seem obvious at the moment is not guaranteed to be
		obvious a month, six months, or two years later. And it is almost certainly
		not guaranteed to be obvious for those reading our code at first glance.
		Document everything.
	</p>
	<div class="rule">
		<p>
			<span class="topic">Proposition.</span> Let ${x}$ be documentation, ${n}$
			be the person who wrote ${x,}$ and ${m}$ be the person who reads ${x}$ in
			the future. There exists an ${m}$ such that ${m}$ has: gone mad, equipped
			himself with an axe, and learned where ${x}$ and his or her family live.
		</p>
	</div>
	<p>
		<span class="topic">Prerequisites for Testing.</span> Before we even begin
		testing, there are two things we must do. First, we should be certain that
		our code actually runs. This weeds out some of the superficial problems we
		might have &mdash; syntax errors, static semantic errors, out of bound
		errors, undefined errors, things that the interpreter will catch quickly.
	</p>
	<p>
		Second, we should come up with a set of expected results. Here, we think of
		a typical input set, and pass them into the program. Before we actually pass
		them, however, we should know what to expect. For each input in the set, we
		record, whether by pen and paper or key and screen, what we expect to see.
		Only then do we pass the inputs into program. Once we have these two
		prerequisites done, we can begin thinking about what
		<span class="italicsText">classes of tests</span> to run.
	</p>
	<p>
		<span class="topic">Unit Testing.</span> In
		<span class="italicsText">unit testing</span>, we validate each piece of the
		program, testing each module and function separately, one by one.
	</p>
	<p>
		<span class="topic">Regression Testing.</span> Once we've done unit testing,
		we should do a <span class="italicsText">regression test</span>. Often,
		while we unit test, we end up encountering bugs. We might then immediately
		respond and squash the bug with a patch. But, in doing so, we might have
		introduced new bugs or reintroduce errors that were previously patched. With
		<span class="italicsText">regression testing</span>, at every patch, we go
		back to where we started and conduct tests again.
	</p>
	<p>
		<span class="topic">Integration Testing.</span> Once we've done unit and
		regression tests, we begin
		<span class="italicsText">itegration testing</span>. Here, we answer the
		question: Does the overall program work? To answer that question, we test
		the connections between each of the modules. Are inputs and outputs flowing
		properly? Are modules receiving the inputs they need? This is the very last
		stage, and we do not go anywhere near here unless we've done unit tests
		followed by regression tests.
	</p>
</section>

<section id="testing_approaches">
	<h4>Testing Approaches</h4>
	<p>
		With the classes in mind, we now discuss the different ways to test. The
		approaches below are the most common approaches, but there are numerous
		other techniques and tactics.
	</p>
	<p>
		<span class="topic">Intuition.</span> The most straight-foward testing
		approach is using intuition. Most problems will have natural boundaries.
		When we solve such a problem with a procedure, that procedure will have
		natural partitions. It is those partitions that we want to test. For
		example, consider this docstring for some function:
	</p>
	<pre class="language-python"><code>
		'''
		Assumptions:
			x is an int
			y is an int
		Returns: 
			If y is less than x, True
			Otherwise, False
		'''
	</code></pre>
	<p>
		What are some natural partitions for this function? Well, what if
		<span class="monoText">x</span> and <span class="monoText">y</span> are data
		types other than <span class="monoText">int</span>? What if
		<span class="monoText">y</span> is greater than
		<span class="monoText">x</span>? What if <span class="monoText">y</span> is
		equal to <span class="monoText">x</span>? What if
		<span class="monoText">x</span> and <span class="monoText">y</span> are both
		negative?
	</p>
	<p>
		<span class="topic">Random Testing.</span> Sometimes, however, there are no
		natural boundaries. In those instances, we might do
		<span class="italicsText">random testing</span>, where we pass in random
		inputs. Think of this as akin to throwing whatever we can find against a
		wall and seeing whether the wall holds up. The probability of the wall being
		strong increases with more tests. But, there are better approaches.
	</p>
	<p>
		<span class="topic">Black Box Testing.</span> With
		<span class="italicsText">black box testing</span>, we explore
		<span class="underlineText">possible</span> paths through specification. An
		example should clarify the vagueness. Consider the following procedure:
	</p>
	<pre class="language-python"><code>
		def sqrt(x, epsilon):
			'''
			Assumptions:
				x is a float
				epsilon is a float
				x >= 0
				epsilon > 0

			Returns:
				[result] such that:
					x-epsilon <= result * result <= x + epsilon
			'''
	</code></pre>
	<p>
		With blackbox testing, we never actually look at the code for this function.
		All we do is look at the specification (the docstring). This is a
		particularly useful testing approach because it allows for someone other
		than the implementer to conduct the test, thereby avoiding implicit biases.
	</p>
	<p>
		From the specification, we think of all the possible test cases for the
		function (again, without looking at the code). For example, if we have a
		procedure that operates on a list, we want to test boundary conditions
		&mdash; pass empty lists, singleton lists, very large lists, lists
		containing other data structures, into the procedure. If we have function
		that deals with numbers, we want to pass 0, very small numbers, and very
		large numbers. In the function above, here are some possible cases to check:
	</p>
	<figure class="table">
		<table class="truth_table">
			<thead>
				<th>case</th>
				<th><span class="monoText">x</span></th>
				<th><span class="monoText">epsilon</span></th>
			</thead>
			<tbody>
				<tr>
					<td>boundary</td>
					<td>0</td>
					<td>0.0001</td>
				</tr>
				<tr>
					<td>perfect square</td>
					<td>25</td>
					<td>0.0001</td>
				</tr>
				<tr>
					<td>less than 1</td>
					<td>0.05</td>
					<td>0.0001</td>
				</tr>
				<tr>
					<td>irrational</td>
					<td>2</td>
					<td>0.0001</td>
				</tr>
				<tr>
					<td>extremes</td>
					<td>2</td>
					<td>1.0/2.0 ** 64.0</td>
				</tr>
				<tr>
					<td>extremes</td>
					<td>2.0 ** 64.0</td>
					<td>1.0/2.0 ** 64.0</td>
				</tr>
				<tr>
					<td>extremes</td>
					<td>1.0/2.0 ** 64.0</td>
					<td>2.0 ** 64.0</td>
				</tr>
				<tr>
					<td>extremes</td>
					<td>2.0 ** 64.0</td>
					<td>2.0 ** 64.0</td>
				</tr>
			</tbody>
		</table>
	</figure>
	<p>
		<span class="topic">Glass Box Testing.</span> In contrast,
		<span class="italicsText">glass box testing</span> explores
		<span class="underlineText">all</span> of that paths through the code
		itself. Here, we actually look inside the function and examine its code,
		using the code to guide our test designs. Ideally, we have
		<span class="underlineText">at least one</span> test case for each path in
		the code. By path, we mean the different possible branches of the code
		(e.g., conditions and their blocks). If test every possible path in the code
		at least once, then the particular module is said to be path complete.
	</p>
	<p>
		The drawback? We cannot always guarantee path completeness. Recursive
		functions, for example, can have an arbitrary amount of paths. Other
		functions might have missing paths. Nevertheless, the most common candidates
		for path testing:
	</p>
	<div class="compare">
		<div>
			<p class="subheading">Branches</p>
			<ul>
				<li>Test: execute every part of the conditional</li>
				<li>
					Test: execute each part at different times (i.e., what happens if one
					condition is true before another condition is true; remember, none of
					the conditions are executed the moment the interpreter encounters a
					true condition).
				</li>
			</ul>
		</div>
		<div>
			<p class="subheading">Loops</p>
			<ul>
				<li>Test: What happens if loop is not entered?</li>
				<li>Test: What happens if we go through the loop exactly one?</li>
				<li>Test: What happens if we go through the loop more than once?</li>
				<li>
					Test: Possible ways to exit the loop (e.g., terminating too early)
				</li>
			</ul>
		</div>
	</div>
	<p>Consider the following function:</p>
	<pre class="language-python"><code>
		def abs(x):
			'''
			Assumptions:
				x is an int
			Returns:
				if x >= 0, x
				otherwise, -x 
			'''
			if x < -1:
				return -x
			else:
				return x
	</code></pre>
	<p>
		Here, we might pass <span class="monoText">-2</span> and
		<span class="monoText">2</span>. This test will be path-complete, but it
		misses a bug: What happens when <span class="monoText">x = -1</span>? Well,
		the function will incorrectly return <span class="monoText">-1</span>. Why?
		Because our <span class="monoText">if</span> condition is
		<span class="monoText">x < -1</span>. This demonstrates the fact that, even
		if we know a test is path complete, we must still test the boundary cases.
	</p>
</section>

<section id="bugs">
	<h2>Bugs</h2>
	<p>
		Once we test and discover that our code does something we do not want it to
		do, we have discovered a <span class="term">bug</span>. This is our code
		blue, prompting us to perform three things: (1) isolate the bug; (2)
		eradicate the bug; and (3) retest until the code runs correctly. To perform
		these three steps properly, we must be able to identify different types of
		bus.
	</p>
	<p>
		<span class="topic">Overt v. Covert Bugs.</span> Bugs are either
		<span class="italicsText">overt</span> or
		<span class="italicsText">covert</span>. An
		<span class="italicsText">overt bug</span> is one that has an obvious
		manifestaton &mdash; the code crashes or hangs. A
		<span class="italicsText">covert bug</span> is one with no obvious
		manifestation &mdash; the code returns a value, but it is incorrect.
	</p>
	<p>
		Because overt bugs are obvious, we want practice good defensive programming
		to ensure as many possible bugs are overt.
	</p>
	<p>
		<span class="topic">Persistent v. Intermittent Bugs.</span> Bugs are also
		either <span class="italicsText">persistent</span>, or
		<span class="italicsText">intermittent</span>.
		<span class="italicsText">Persistent bugs</span> are those that occur every
		time the code is executed.
		<span class="italicsText">Intermittent bugs</span> are those that occur on
		and off; sometimes the code runs correctly, other times incorrectly, even on
		the same input. As we can probably tell, covert intermittent bugs are the
		most dangerous of all. Some bugs are annoying or frustrating. Covert
		intermittent bugs, however, have the potential for terror &mdash; the code
		ran incorrectly just once, but has since ran correctly without any changes.
	</p>
</section>

<section id="debugging">
	<h4>Debugging</h4>
	<p>
		Debugging has a very steep learning curve. It takes many hours of practice
		to get to a level where we are able to write large, bug-free programs.
	</p>
	<p>
		IDEs often provide debugging tools for particular languages. We should take
		the time to learn and use these tools. Otherwise, the most basic tools
		include using the <span class="monoText">print</span> statement and
		debuggers. The most critical tool of all &mdash; your brain.
	</p>
	<p>
		<span class="topic">Preliminary Questions.</span> To make a hypothesis, we
		want to ask several questions: How did I get to to this unexpected result?
		Is this related to some other problem I have solved before? Were there
		previous versions of this code that worked? Ask specific questions at this
		stage. Do not ask general questions like, what is wrong? We ask these
		preliminary questions to gather data. Once we have enough data, we want to
		come up with a debugging plan using the scientific method:
	</p>
	<ol>
		<li>Make a hypothesis for where the bug might come from.</li>
		<li>Run experiments testing that hypothesis.</li>
		<li>Make conclusions and draw further hypotheses</li>
	</ol>
	<p>
		Once we have constructed a hypothesis, we can begin running experiments with
		the tools below.
	</p>
	<p>
		<span class="topic">Trace Execution.</span> Executing tracing is where we
		carefully lay out the sequence of executions for the code. This can be
		particularly useful for when we want to have a big picture view of how the
		code works. There are tools like
		<a href="http://pythontutor.com/visualize.html#mode=edit">Python Tutor</a>
		which lay these out for us. However, a fair warning: trace execution is
		often abused by new programmers. We should come up with an understanding of
		the code ourselves before we actually use an external tool, and coming up
		with our own hypothesis for why a bug is occurring.
	</p>
	<p>
		<span class="topic"
			>The <span class="monoText">print</span> Statement.</span
		>
		The <span class="monoText">print</span> statement is one of the most
		powerful ways to test our hypotheses. For example, with functions, we
		usually want to insert <span class="monoText">print</span> statements: (a)
		when we enter the function; (b) before computations in the function; and (c)
		when we exit the function. We also want to print the function's parameters
		and results.
	</p>
	<p>
		Point (b) raises a debugging approach called the
		<span class="term">bisection method</span> &mdash; placing
		<span class="monoText">print</span> statements halfway through the code.
		This helps us determine where a bug may be depending on the values printed.
	</p>
	<p>
		<span class="topic">Understand Error Messages.</span> Error messages are
		invaluable for debugging. The most common errors in Python are the
		following:
	</p>
	<p>
		<span class="topic"><span class="monoText">IndexError</span></span> We are
		trying to access beyond the limits of a list.
	</p>
	<pre class="language-python"><code>
		test = [1, 2, 3]
		element = test[4]
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">TypeError</span></span> Two
		possibilities: (1) We are casting into a type we cannot cast into; (2) we
		are mixing data types without appropriate coercion.
	</p>
	<pre class="language-python"><code>
		# bad casting
		test = [1, 2, 3] 
		int(test)

		# bad data type mixing
		'3' / 4
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">NameError</span></span> We are
		referencing a non-existent variable.
	</p>
	<pre class="language-python"><code>
		b = a + 1
		print(b)
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">SyntaxError</span></span> We are
		making illegal statements (e.g., forgetting to close parenthesis, forgetting
		colons or commas, etc.)
	</p>
	<pre class="language-python"><code>
		a = len([1, 2, 3])
		print a
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">KeyError</span></span> We are
		referencing a non-existent key.
	</p>
	<pre class="language-python"><code>
		myDict = {'name': 'sherlock', 'job':'detective'}
		print(myDict['address'])
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">RecursionError</span></span> Our
		recursive function is going beyond the maximum recursion depth.
	</p>
	<pre class="language-python"><code>
		def fibonacci(n):
			if n == 0 or n == 1:
				return 1
			else:
				return fibonacci(n - 1) + fibonacci(n - 2)

		fibonacci(1000000000)
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">UnboundLocalError</span></span>
		We are referencing a local variable in a function or method before the
		variable has been assigned.
	</p>
	<pre class="language-python"><code>
		x = 10
		def add_two():
			x += 2
			print(x)

		add_two()
	</code></pre>
	<p>
		<span class="topic"><span class="monoText">ValueError</span></span> We are
		passing an argument into the function that is the right type, but has an
		inappropriate value.
	</p>
	<pre class="language-python"><code>
		import math

		math.sqrt(-10)
	</code></pre>
	<p>
		<span class="topic">Logic Errors.</span> We will not get error messages for
		logic errors. This is where we get back outputs, but they are not what we
		expected. These are the most difficult errors to remedy, and preventive
		solutions are worth far more than curative ones. We should always think
		carefully before we write code. If we do encounter logic errors, a helpful
		tool is diagramming what we want our code to do. Flow chart the procedure's
		steps.
	</p>
	<p>
		Better yet, <span class="italicsText">explain</span> the code out loud. In
		programming parlance, this is called
		<span class="italicsText">rubber duck debugging</span>; the programmer
		explains the code to a rubber duck or someone willing to listen.
	</p>
	<p>
		<span class="topic">Effective Workflow.</span> We can minimize bugs by
		ensuring our code is sanitary at all times. This is done by employing the
		following workflow:
	</p>
	<ol>
		<li>Write a function.</li>
		<li>Test the function.</li>
		<li>Debug the function.</li>
		<li>Write another function.</li>
		<li>Test the function.</li>
		<li>Debug the function.</li>
		<li>Integrate the functions.</li>
		<li>Do integration testing.</li>
	</ol>
	<p>
		Every group of changes we make should be followed by a
		<span class="monoText">git commit</span>. We should always have backups and
		previous versions of our code.
	</p>
	<p>If, at any point, we encounter a bug, we must do the following:</p>
	<ol>
		<li>
			Make a <span class="monoText">git commit</span> of the code right now.
		</li>
		<li>Change the code.</li>
		<li>Record the potential bug in a comment.</li>
		<li>Test the code.</li>
		<li>Compare the previous version with the current version.</li>
	</ol>
</section>

<section id="exceptions_assertions">
	<h2>Exceptions & Assertions</h2>
	<p>
		<span class="italicsText">Exceptions</span> and
		<span class="italicsText">assertions</span> in Python provide additional
		means of defensive programming.
	</p>
	<p>
		<span class="topic">Exceptions.</span> Exceptions in Python directly address
		the question: What happens when the procedure is executed and meets an
		unexpected condition? Hitting an unexpected condition is an
		<span class="term">exception</span>. When an exception occurs, we typically
		get back error messages (e.g., <span class="monoText">IndexError</span>,
		<span class="monoText">TypeError</span>,
		<span class="monoText">NameError</span>, etc.).
	</p>
	<p>
		Other common types exceptions: <span class="monoText">SyntaxError</span> -
		Python cannot parse the program. <span class="monoText">NameError</span> - a
		local or global name cannot be seen.
		<span class="monoText">AttributeError</span> - an attribute reference has
		failed. <span class="monoText">TypeError</span> - the operand does not have
		the correct type. <span class="monoText">ValueError</span> - the operand
		type is valid, but the value is illegal.
		<span class="monoText">IOError</span> - There is a problem with the IO
		system (e.g., nonexistent file or file not found).
	</p>
	<p>
		<span class="topic">What do we do with exceptions?</span> There are three
		options for handling exceptions: (1) Fail silently; (2) Return an
		&#8220;error&#8221; value; (3) stop execution and signal the condition.
	</p>
	<p>
		The first option, failing silently, is where we substitute default values or
		simply continue. This is the worst possible approach. It is essentially
		sweeping the problem under the rug and pretending it does not exist. Worse,
		it borders on deceit. The user will get no warning that something has gone
		wrong.
	</p>
	<p>
		The second option, return an error value, is an incomplete solution. Even if
		we return an error value, we still have the problem. This can also
		needlessly complicate our code. What value should we choose? How do we check
		for the special value?
	</p>
	<p>
		The third option is the one we should always go with &mdash; as soon as the
		code hits an exception, stop executing and
		<span class="italicsText">raise an exception</span>. This is done in Python
		with the following:
	</p>
	<pre class="language-python"><code>
		raise Exception("string describing error")
	</code></pre>
	<p>
		<span class="topic">Handlers.</span> Python provides symbols for handling
		exceptions. Consider the following:
	</p>
	<pre class="language-python"><code>
		try:
			a = int(input("Divisor: "))
			b = int(input("Dividend: "))
			print(a/b)
			print("Okay")
		except:
			print("Bug in user input")
		print("Outside")
	</code></pre>
	<p>
		The code above contains two new pieces of syntax:
		<span class="monoText">try</span> and <span class="monoText">except</span>.
		The code effectively provides, <span class="monoText">try</span> these
		statements below; if at any point an exception is raised, STOP, jump to the
		statement below <span class="monoText">except</span>.
	</p>
	<p>
		The <span class="monoText">try</span> and
		<span class="monoText">except</span> structure above essentially allows us
		to customize exception handling.
	</p>
	<p>
		<span class="topic">Handling Specific Exceptions.</span> Handlers can be
		extended to specific errors. For example:
	</p>
	<pre class="language-python line-number"><code>
		try:
			a = int(input("First term: "))
			b = int(input("Second term: "))
			print("a/b = ", a/b)
			print("a+b = ", a+b)
		except ValueError:
			print("Could not cast to a number.")
		except ZeroDivisionError:
			print("Can't divide by zero.")
		except:
			print("Something went wrong.")	
	</code></pre>
	<p>
		The code above provides that if the exceptions above occur, stop execution
		and go to the relevant exception. Instead of print out the usual error
		message (i.e., <span class="monoText">ValueError</span>) do this instead.
	</p>
</section>
{% endblock %}
